<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on devDosvid blog</title>
    <link>https://devdosvid.blog/posts/</link>
    <description>Recent content in Posts on devDosvid blog</description>
    <image>
      <title>devDosvid blog</title>
      <url>https://devdosvid.blog/assets/img/websitelogo.jpg</url>
      <link>https://devdosvid.blog/assets/img/websitelogo.jpg</link>
    </image>
    <generator>Hugo -- 0.143.1</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 00:06:11 +0200</lastBuildDate>
    <atom:link href="https://devdosvid.blog/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Delegate for Growth: Scaling Your Impact Through Others</title>
      <link>https://devdosvid.blog/2025/04/04/delegate-for-growth-scaling-your-impact-through-others/</link>
      <pubDate>Fri, 04 Apr 2025 00:36:23 +0200</pubDate>
      <guid>https://devdosvid.blog/2025/04/04/delegate-for-growth-scaling-your-impact-through-others/</guid>
      <description>Senior IC guide to scaling impact. Master peer influence &amp;amp; growth delegation to effectively lead without formal authority.</description>
      <content:encoded><![CDATA[<p>As senior engineers, we often hit the ceiling at some point: our individual output is high, but writing more code or spinning up one more cluster does not feel like the best way to make more impact.</p>
<p>A more significant impact comes from multiplying our efforts. But how do you do that without a team reporting to you? How do you effectively involve peers in your projects, influencing their priorities when you don&rsquo;t control their backlog or performance review?</p>
<p>I had been looking for the answers to these questions for quite a long time, and then I realized there was no definitive answer or a straightforward rule to follow. Yet my brain always needs something systemized, and for those like me, I decided to compile this write-up: synthesis of my personal experience that worked well and learnings from books and blogs on that topic.</p>
<p>The foundation of influencing peers lies in understanding their perspective. Before asking someone to take on work, especially the work you&rsquo;re <strong>proposing</strong>, you need to answer the fundamental question: <strong>What&rsquo;s in it for them?</strong></p>
<p><em>This is my very first non-technical blog. And I hope it is not the last either</em> 😄</p>
<h2 id="understanding-the-why-the-engine-of-peer-collaboration">Understanding the &ldquo;Why&rdquo;: The Engine of Peer Collaboration</h2>
<p>Why would a fellow engineer prioritize something offered by a peer like you rather than a directive from their manager?</p>
<p>It rarely comes down to just one reason. Usually, it&rsquo;s a blend of motivations deeply rooted in personal drive and effective team dynamics:</p>
<ul>
<li>
<p><strong>The Hunger for Growth &amp; Mastery:</strong> Does this task offer a chance to learn a coveted new skill, dive deeper into an interesting technology, or tackle a challenge that stretches their capabilities? Tapping into this intrinsic drive is incredibly powerful.</p>
</li>
<li>
<p><strong>The Desire for Impact &amp; Purpose:</strong> Can you clearly articulate how this work contributes to something meaningful? Whether it&rsquo;s a key product goal, squashing critical tech debt, or improving life for the whole team, connecting the task to the bigger picture gives it weight.</p>
</li>
<li>
<p><strong>The Value of Visibility &amp; Recognition:</strong> Will this work get noticed? Could it lead to a cool demo, wider acknowledgment, or even open doors for future opportunities? Sometimes, positive exposure is a significant motivator.</p>
</li>
<li>
<p><strong>The Power of Connection &amp; Collaboration:</strong> Is working closely with you part of the appeal? Offering a chance to learn directly from a respected senior peer, build rapport, and strengthen their network can be a draw in itself.</p>
</li>
<li>
<p><strong>The Relief of Reducing Future Pain:</strong> Does this task promise to automate some hard work, fix a persistent thorn in the side, or establish a pattern that saves everyone time down the line? Framing it as an investment with future payoffs can be compelling.</p>
</li>
<li>
<p><strong>The Spark of Intrinsic Interest:</strong> Sometimes, the problem itself is just plain fascinating, or it involves technology the peer genuinely enjoys working with. Don&rsquo;t underestimate the power of intellectual curiosity.</p>
</li>
<li>
<p><strong>The Clarity of Strategic Alignment:</strong> This is often crucial. If you can demonstrate a direct link between the task and an agreed-upon team OKR, a strategic technical initiative, or a critical product outcome, it elevates the request beyond personal preference. It becomes a shared priority, providing justification for them (and potentially their manager) to consider adjusting focus.</p>
</li>
<li>
<p><strong>The Pull of a Shared Technical Vision:</strong> If you&rsquo;re championing a specific technical direction or architecture that resonates with your peers, they&rsquo;ll be more inclined to pick up tasks that help realize that vision.</p>
</li>
<li>
<p><strong>The Currency of Reciprocity &amp; Trust:</strong> Have you built &ldquo;relationship capital&rdquo;? A history of helping others, providing timely code reviews, and tackling unglamorous tasks yourself makes peers more likely to reciprocate when you offer an opportunity or ask for help.</p>
</li>
<li>
<p><strong>The Strength of a Collaborative Culture:</strong> In healthy teams, there&rsquo;s an inherent understanding that helping each other and sharing interesting work benefits everyone. Your offer reinforces this positive norm.</p>
</li>
</ul>
<p>Understanding these potential &ldquo;Whys&rdquo; is your key. Now, how do you translate that understanding into effectively approaching your peers?</p>
<h2 id="crafting-the-opportunity-making-the-ask-compelling">Crafting the Opportunity: Making the Ask Compelling</h2>
<p>Knowing the potential motivators allows you to frame your request not as an ask for help but as presenting a valuable opportunity.</p>
<p><strong>Frame Based on Mutual Benefit:</strong> Tailor your pitch. Does this task primarily offer growth? Highlight the learning potential. Is it about impact? Emphasize its strategic importance. Does it align with their known interests? Point that out. Frame it as a chance for partnership or mentorship if that fits.</p>
<p><strong>Lower the Barrier to Entry:</strong> Make it easy to say &ldquo;yes&rdquo; (or at least &ldquo;tell me more&rdquo;). Do the heavy lifting: clearly define the problem, provide essential context, perhaps outline potential approaches, and have a task ready in your tracker. Reduce the initial friction and cognitive load. A well-defined, manageable scope is far less daunting than a vague, massive undertaking.</p>
<p><strong>Empower, Don&rsquo;t Micromanage:</strong> Offer challenging work that genuinely stretches capabilities. Provide clear context and constraints (the &ldquo;guardrails&rdquo;). Then – critically – give them the space to figure things out. Use check-ins and discussions about success criteria as support mechanisms, not control tactics. Explicitly state why you think this is a good opportunity for their development.</p>
<p><strong>Build and Leverage Trust:</strong> This is paramount and underpins everything else when evolved. Your technical credibility and relationship capital are essential. Peers are more likely to engage when they:</p>
<ul>
<li>
<p><strong>Trust the Problem &amp; Direction:</strong> They believe the problem is worth solving, and your proposed path (or the space you give them to find one) is sound.</p>
</li>
<li>
<p><strong>Trust Your Motives:</strong> They believe you&rsquo;re genuinely offering this for their growth and the project&rsquo;s benefit, not just offloading grunt work. Your history of collaboration, giving credit, and supporting others builds this trust.</p>
</li>
<li>
<p><strong>Trust Your Support:</strong> They believe you&rsquo;ll provide necessary context, answer questions, help unblock them, and shield them from related distractions.</p>
</li>
</ul>
<p>Of course, even the best-framed opportunity might meet a scheduling conflict. What happens when the answer is &ldquo;I&rsquo;m swamped, I can&rsquo;t&rdquo;?</p>
<h2 id="navigating-the-no-or-not-now">Navigating the &ldquo;No&rdquo; (or &ldquo;Not Now&rdquo;)</h2>
<p>Hearing &ldquo;I don&rsquo;t have bandwidth&rdquo; is common and perfectly okay. How you <strong>respond matters</strong> for the long-term relationship and potential future collaboration.</p>
<p><strong>Validate &amp; Understand First:</strong> Always start by acknowledging their situation.</p>
<p>&ldquo;<em>Okay, totally understand you&rsquo;re busy.</em>&rdquo;</p>
<p>Then, gently probe to distinguish bandwidth issues from lack of interest or alignment: &ldquo;<em>Just so I understand better, is the main challenge fitting it in time-wise alongside existing priorities, or does this opportunity maybe not feel like the right fit/priority compared to what&rsquo;s on your plate?</em>&rdquo;</p>
<p><strong>Adapt the Ask:</strong> If bandwidth is the only issue, can the scope be reduced? Is there a smaller, valuable piece they could contribute (e.g., brainstorming, reviewing a design, tackling one specific sub-task)?</p>
<p><strong>Align Priorities Collaboratively (Handle with Care):</strong> If the task is strategically important, the peer is interested, but they&rsquo;re blocked by conflicting priorities, this is where careful alignment is needed.</p>
<ul>
<li>
<p><strong>Crucially: Get Peer Buy-in First:</strong> Never go directly to their manager without discussing it with your peer first.
Doing so instantly undermines trust. Instead, frame the idea of talking to the manager together as a way to seek support for their growth and achieve important shared team/organization goals. It is also OK to talk to their manager one-on-one; just confirm that with your peer first. The same goes if your peer says they will do that. The main point is that you talked to your peer first, and you agreed to continue.</p>
</li>
<li>
<p><strong>Frame the Manager Conversation:</strong> If you do talk to the manager with your peer, focus on shared objectives.
&ldquo;<em>We identified this task as crucial for [Goal X]. [Peer Name] is interested, and it seems like a great growth opportunity. Given their current commitments, how can we best align priorities to make this feasible?</em>&rdquo; This turns it into collaborative problem-solving, not top-down pressure.</p>
</li>
</ul>
<p><strong>Respect Boundaries:</strong> If the answer remains &ldquo;no,&rdquo; accept it gracefully. Thank them for considering it. Preserving the relationship is key for future influence.</p>
<p><strong>Seek Alternatives:</strong> If it&rsquo;s not feasible, consider other peers. Can you tackle a smaller version of this task yourself? Is it worth deferring (sometimes rethinking reveals it wasn&rsquo;t as critical as initially thought)?</p>
<p>Creating specific task-based opportunities is powerful, but scaling your impact as a senior IC involves broader strategies too.</p>
<h2 id="broader-strategies-for-scaling-your-impact">Broader Strategies for Scaling Your Impact</h2>
<p>Beyond direct &ldquo;delegation-as-opportunity,&rdquo; think about these leverage points:</p>
<p><strong>Mentorship &amp; Sponsorship:</strong> Formalize the growth angle. Move beyond ad-hoc tasks to explicitly mentor someone through a larger piece of work. Actively sponsor them by highlighting their contributions and advocating for their visibility.</p>
<p><strong>Creating Leverage via Platforms, Tools, &amp; Frameworks:</strong> Build things that make many engineers more effective. A robust library, a streamlined CI/CD pipeline, and a well-designed service template – that scale your impact exponentially without direct task delegation. You&rsquo;re essentially &ldquo;delegating&rdquo; efficiency and good practices.</p>
<p><strong>Establishing Patterns and Best Practices:</strong> Defining and evangelizing clear architectural patterns, coding standards, or review processes guide the work of many, scaling your influence on quality, consistency, and maintainability. You&rsquo;re shaping how work gets done.</p>
<p><strong>Architectural Guidance and Technical Strategy:</strong> Setting a clear, well-communicated technical direction influences the choices and priorities of the entire team or organization, ensuring efforts align towards a cohesive vision.</p>
<p><strong>Effective Documentation and Knowledge Sharing:</strong> Writing clear design documents, Architecture Decision Records (ADRs), runbooks, and tutorials enable others to understand systems, contribute effectively, and operate autonomously within the technical landscape you&rsquo;ve helped shape.</p>
<h2 id="time-to-try-practical-exercises">Time to Try: Practical Exercises</h2>
<p>Two practical exercises to go and try.</p>
<h3 id="find-a-growth-opportunity">Find a Growth Opportunity</h3>
<p>Scan your current or upcoming workload. Identify one item that isn&rsquo;t just work to be done but represents a genuine development opportunity for a specific colleague. Think about why it&rsquo;s a good fit for them.</p>
<p>Then, practice framing it as an opportunity, highlighting their potential gains (learning, impact, interest). Prepare the context they&rsquo;d need, and be ready to offer mentorship, not micromanagement. Anticipate how you&rsquo;d handle a &ldquo;too busy&rdquo; response using the adaptive strategies.</p>
<h3 id="pitch-strategic-alignment">Pitch Strategic Alignment</h3>
<p>Identify a task (on your plate or the team&rsquo;s radar) that directly supports a key team or organizational goal (e.g., an OKR, a critical roadmap item, fixing a major pain point).</p>
<p>Clearly articulate why this task is strategically important – quantify its impact if possible. Mentally select a relevant peer and craft a concise pitch focusing first on the task&rsquo;s alignment with shared objectives and its broader impact, then on the technical details or learning aspects.</p>
<p>Crucially, plan how you would suggest a collaborative discussion about priority alignment (potentially involving their manager, with their consent) if they express interest but cite conflicting priorities due to the task&rsquo;s strategic value.</p>
<h2 id="afterword-influence-is-the-goal">Afterword: Influence is the Goal</h2>
<p>Scaling your impact as an individual contributor isn&rsquo;t about wielding authority you don&rsquo;t have. It&rsquo;s about building <strong>influence, trust, and shared understanding.</strong> You leverage your technical credibility, strategic thinking, and relationship capital to create opportunities that are genuinely valuable for your peers while advancing collective goals.</p>
<p>Peers engage not because they have to but because they want to – driven by growth, impact, interest, or trust in you and the mission.</p>
<p>Prioritization becomes a conversation about value and strategic alignment, sometimes requiring collaborative discussions with managers, rather than a zero-sum game.</p>
<p>Yes, this takes conscious effort. It requires empathy, clear communication, and sometimes navigating tricky conversations.</p>
<p>But &ldquo;this <strong>is</strong> the path&rdquo; because focusing on building trust, clearly articulating the &ldquo;why,&rdquo; connecting tasks to strategic goals, and genuinely investing in the growth of those around you is the essence of being a force multiplier as a senior IC.</p>
<p>Naturally, every team and individual is different, so consider these strategies a <strong>starting</strong> point or a toolkit to adapt to your unique context.</p>
<div class="attention">
    <p>Books on this topic:</p>
<ul>
<li>Will Larson&rsquo;s &ldquo;Staff Engineer&rdquo; and &ldquo;An Elegant Puzzle&rdquo;,</li>
<li>Camille Fournier&rsquo;s &ldquo;The Manager&rsquo;s Path&rdquo;,</li>
<li>&ldquo;The Software Engineer&rsquo;s Guidebook&rdquo; by Gergely Orosz,</li>
<li>&ldquo;Drive&rdquo; by Daniel Pink for concepts around influence and motivation</li>
</ul>
<p>Blogs on this and many other great things:</p>
<ul>
<li>&ldquo;A Life Engineered&rdquo; by Steve Huynh <a href="https://alifeengineered.substack.com/">https://alifeengineered.substack.com/</a></li>
<li>&ldquo;Pragmatic Engineer&rdquo; by Gergely Orosz <a href="https://newsletter.pragmaticengineer.com/about">https://newsletter.pragmaticengineer.com/about</a></li>
</ul>

</div>
]]></content:encoded>
    </item>
    <item>
      <title>Aws S3 Cost Optimization: Removing Redundancy and Implementing Intelligent Tiering</title>
      <link>https://devdosvid.blog/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/</link>
      <pubDate>Wed, 29 Jan 2025 02:48:15 +0100</pubDate>
      <guid>https://devdosvid.blog/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/</guid>
      <description>Legacy setups can hide costs, and sometimes big. By challenging this, I learned some cool stuff about S3 Intelligent-Tiering and Lifecycle Configuration.</description>
      <content:encoded><![CDATA[<p>Legacy architectural decisions often carry hidden costs. Here&rsquo;s how questioning a storage configuration saved us a hundred thousand and taught some lessons about S3.</p>
<p>This is a technical walkthrough of identifying, analyzing, and solving two specific S3 cost optimization problems I faced recently: eliminating unnecessary data and implementing intelligent storage tiering.</p>
<p><em>Note: All mentioned AWS prices are from January 2025 in the us-east-1 region. AWS pricing and features may have changed since the publication.</em></p>
<h1 id="what-was-the-cause">What was the cause</h1>
<p>Picture this: In December 2024, two S3 buckets quietly consumed about $19,500. The price is just for one month. That&rsquo;s nearly $235,000 annually, but the size of buckets slowly grows, so it&rsquo;s going to be more.
These buckets are for <a href="https://jfrog.com/artifactory/">JFrog Artifactory</a>, which supports AWS S3 as a file storage.
The first bucket contains CI/CD builds and cached third-party artifacts — essential data we need daily. The second bucket is the replica in another region. This build data is important, yet paying $120,000 a year to duplicate that data seems overkill.</p>
<p>Now the question is: WHY do we have such a setup with replication? As always happens, that was configured long ago, so no one knows by now.</p>
<p>Let&rsquo;s give this a fresh look: S3 provides 11-nines durability by design; if something gets deleted by accident, we can always re-run CI/CD and build that again. Does replication provide any value?</p>
<p>The problem statement is simple: the buckets are enormous, we pay half the price for nothing, and the amount of data might grow more.</p>
<ul>
<li>Two S3 buckets: main in us-east-1 and replica in us-west-2</li>
<li>About 340TB each</li>
<li>21+ million objects per bucket</li>
<li>Average object size: 17MB</li>
<li>7% monthly growth rate based on the last 12 months&rsquo; trend</li>
</ul>
<p>The two-fold solution to that was not that trivial, though.</p>
<h1 id="addressing-the-unpredicted-s3-bucket-growth-and-access-patterns">Addressing the unpredicted S3 bucket growth and access patterns</h1>
<p>By the design of S3 service, a client (you or your application) should specify the storage class when uploading the object to an S3 bucket; there is no thing like &ldquo;default storage class for new objects&rdquo;.</p>
<p>Surprisingly, despite a versatile configuration options for S3, JFrog Artifactory does not allow setting storage classes for the objects it stores. So, everything you store is sent to S3 with the Standard storage class.</p>
<p>On a large scale, with many teams and projects, it is pretty hard to predict the lifetime and the frequency of one or other artifact for the particular team. <a href="https://jfrog.com/help/r/artifactory-cleanup-best-practices/artifactory-cleanup-best-practices">Auto-cleanup options</a> are built into Artifactory, but they do not answer the retention questions anyway: How long? How frequent?</p>
<p>Luckily, AWS has two powerful things to address these issues:</p>
<ol>
<li><a href="https://aws.amazon.com/getting-started/hands-on/getting-started-using-amazon-s3-intelligent-tiering/">Intelligent-Tiering storage class</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html">Lifecycle Configuration</a></li>
</ol>
<h2 id="benefits-of-intelligent-tiering-storage-class">Benefits of Intelligent-Tiering Storage class</h2>
<p>As its name implies, Intelligent-Tiering automatically defines the best access tier when access patterns change. There are three basic tiers: one is optimized for frequent access, another for infrequent access, and a very low-cost tier, which is optimized for rarely accessed data.</p>
<p>For a relatively small price, which is negligible on scale, S3 does the monitoring and tier transition of the objects:</p>
<ul>
<li>Monitoring: $0.0025 per 1,000 objects/month</li>
<li>Storage for GB/month:
<ul>
<li>$0.021 — frequent tier: object stored here by default</li>
<li>$0.0125 — infrequent tier: object moved here after 30 days without access</li>
<li>$0.004 — archive tier: object moved here after 90 days without access</li>
</ul>
</li>
</ul>
<div class="attention">
    <p>The vast advantage of Intelligent-Tiering comes with the infrequent and archive tier prices on scale.</p>
<p>But note that objects smaller than 128 KB are not eligible for auto tiering.</p>

</div>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/s3-intelligent-tiering_hu_eb5862288ab23237.webp"
                 alt="S3 Intelligent-Tiering"width="800"height="370.23" />
        
    
    <figcaption>
        <p>S3 Intelligent-Tiering
            </p>
    </figcaption>
</figure>

<h2 id="lifecycle-configuration-to-move-s3-objects-between-storage-classes">Lifecycle Configuration to move S3 objects between storage classes</h2>
<p>So now the question is: how to move all the objects to Intelligent-Tiering, old and any new ones?</p>
<p>Here comes Lifecycle Configuration. S3 Lifecycle also manipulates objects, but the key difference between Intelligent-Tiering and Lifecycle Configuration is that Configuration does not have the access pattern analysis as a trigger — the only trigger for Configuration is the time (e.g., trigger in N days).</p>
<p>However, a trigger by time mark is precisely what&rsquo;s needed when your software does not support the custom storage classes — you want to move objects as soon as possible to Intelligent-Tiering using Lifecycle Configuration.</p>
<p>Here&rsquo;s how you need to configure the Lifecycle to move all the objects to Intelligent-Tiering:</p>
<ul>
<li>Apply to all objects in the bucket</li>
<li>Actions:
<ul>
<li>The 1st option — Transition current versions of objects between storage classes</li>
<li>The 2nd option — Transition noncurrent versions of objects between storage classes</li>
</ul>
</li>
<li>Specify Intelligent-Tiering for &ldquo;Transition current version&rdquo; and &ldquo;Transition noncurrent versions&rdquo;</li>
<li>Set 0 as the number of &ldquo;Days after object creation&rdquo; and &ldquo;Days after objects become noncurrent&rdquo;</li>
</ul>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/s3-lifecycle-move-to-it_hu_15e1faed58ed46f4.webp"
                 alt="S3 Lifecycle Rule: Move to Intelligent-Tiering"width="800"height="1180.04" />
        
    
    <figcaption>
        <p>S3 Lifecycle Rule: Move to Intelligent-Tiering
            </p>
    </figcaption>
</figure>

<p>A zero value here does not mean an immediate change of the storage class: by design, the transition will be executed at midnight UTC from the object upload date. For existing objects, the transition will begin at midnight UTC after the lifecycle rule is applied.</p>
<div class="attention">
    I confirmed with AWS technical support that there are no indications of throttling or limitations on object access during transitions. All objects remain accessible during the transition process.
</div>
<p>Lifecycle Configuration has a price of $0.01 per 1,000 Transition requests, which technically adds $0.00001 as the one-time cost of each object affected by the policy.</p>
<p>For example, in my case, moving 21 million objects to the Intelligent-Tiering class had a one-time cost of $210, but ROI for this is much more significant the next month.</p>
<p>The effect of applying Intelligent-Tiering comes in time. At least 60 days should pass to see the real difference: 30 days to trigger the first tiering relocation and then another 30 for the next month&rsquo;s usage so you can compare.</p>
<p>Based on Storage Lense and Storage Class Analysis statistics, I expect about 60% of the objects to remain in the archive tier, reducing the total costs of the primary S3 bucket by 48%.</p>
<h1 id="untrivial-termination-of-a-large-s3-bucket">Untrivial termination of a large S3 bucket</h1>
<p>How hard can it be to empty and delete the bucket with 21 million objects inside? (To clarify: S3 does not allow deletion of a non-empty bucket)</p>
<p>The most obvious way, at first glance, would be to use the AWS S3 web Console option called &ldquo;Empty&rdquo;, right?</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/s3-empty-bucket_hu_835a651db5a41a5f.webp"
                 alt="S3 Empty Bucket"width="800"height="420.16" />
        
    
    <figcaption>
        <p>S3 Empty Bucket
            </p>
    </figcaption>
</figure>

<p>Alas, it is not that simple.</p>
<p>When you go that way, <strong>it is your browser who removes the objects by sending API calls to AWS</strong>. There is no background job for you. It does that efficiently, sending DELETE requests in 1000-item batches, but it does that as long as your IAM session remains active (or the browser window remains open, whatever ends first).</p>
<p>If your bucket has Bucket Versioning enabled, <strong>&ldquo;Empty&rdquo; action will not remove all the object versions</strong>.</p>
<p>So then we have two other options:</p>
<ul>
<li>Either run some script that removes all object versions (including current, older, and null versions) and delete markers.</li>
<li>Or set up a couple of Lifecycle Configuration rules to purge a bucket in an unattended way.</li>
</ul>
<p>If the total number of objects is relatively small, e.g., up to few hundred thousand, it is feasible to run a script that removes all object versions and delete markers.
<div class="code-snippet">
<details>
<summary markdown="span">Click here to see the code snippet</summary>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic">#!/usr/bin/env python3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">import</span> <span style="color:#ff7b72">sys</span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">import</span> <span style="color:#ff7b72">boto3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">def</span> <span style="color:#d2a8ff;font-weight:bold">purge_bucket_interactive</span>(bucket_name: str) <span style="color:#ff7b72;font-weight:bold">-&gt;</span> <span style="color:#79c0ff">None</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">    Display the bucket ARN and region, warn the user, and prompt them to type
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">    &#39;YES&#39; in uppercase. If confirmed, permanently remove all object versions
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">    (including current, older, and null versions) and delete markers.
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># We use the S3 client to query bucket location info</span>
</span></span><span style="display:flex;"><span>    s3_client <span style="color:#ff7b72;font-weight:bold">=</span> boto3<span style="color:#ff7b72;font-weight:bold">.</span>client(<span style="color:#a5d6ff">&#34;s3&#34;</span>)
</span></span><span style="display:flex;"><span>    response <span style="color:#ff7b72;font-weight:bold">=</span> s3_client<span style="color:#ff7b72;font-weight:bold">.</span>get_bucket_location(Bucket<span style="color:#ff7b72;font-weight:bold">=</span>bucket_name)
</span></span><span style="display:flex;"><span>    region <span style="color:#ff7b72;font-weight:bold">=</span> response<span style="color:#ff7b72;font-weight:bold">.</span>get(<span style="color:#a5d6ff">&#34;LocationConstraint&#34;</span>) <span style="color:#ff7b72;font-weight:bold">or</span> <span style="color:#a5d6ff">&#34;us-east-1&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># Construct the bucket&#39;s ARN (for standard S3 buckets, the region is not typically embedded)</span>
</span></span><span style="display:flex;"><span>    bucket_arn <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#79c0ff">f</span><span style="color:#a5d6ff">&#34;arn:aws:s3:::</span><span style="color:#a5d6ff">{</span>bucket_name<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#79c0ff">f</span><span style="color:#a5d6ff">&#34;Bucket ARN   : </span><span style="color:#a5d6ff">{</span>bucket_arn<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#79c0ff">f</span><span style="color:#a5d6ff">&#34;Bucket region: </span><span style="color:#a5d6ff">{</span>region<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#a5d6ff">&#34;WARNING: This will permanently remove ALL VERSIONS of every object.&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#a5d6ff">&#34;It is NOT REVERSIBLE!!!</span><span style="color:#79c0ff">\n</span><span style="color:#a5d6ff">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    confirm <span style="color:#ff7b72;font-weight:bold">=</span> input(<span style="color:#a5d6ff">&#34;Type &#39;YES&#39; in uppercase to proceed with the permanent removal: &#34;</span>)<span style="color:#ff7b72;font-weight:bold">.</span>strip()
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">if</span> confirm <span style="color:#ff7b72;font-weight:bold">!=</span> <span style="color:#a5d6ff">&#34;YES&#34;</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#a5d6ff">&#34;Aborted. No changes made.&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#ff7b72">return</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># Proceed with deletion</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#a5d6ff">&#34;Starting purge... This might take a while.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8b949e;font-style:italic"># Use the S3 resource to delete all versions</span>
</span></span><span style="display:flex;"><span>    s3 <span style="color:#ff7b72;font-weight:bold">=</span> boto3<span style="color:#ff7b72;font-weight:bold">.</span>resource(<span style="color:#a5d6ff">&#34;s3&#34;</span>)
</span></span><span style="display:flex;"><span>    bucket <span style="color:#ff7b72;font-weight:bold">=</span> s3<span style="color:#ff7b72;font-weight:bold">.</span>Bucket(bucket_name)
</span></span><span style="display:flex;"><span>    bucket<span style="color:#ff7b72;font-weight:bold">.</span>object_versions<span style="color:#ff7b72;font-weight:bold">.</span>all()<span style="color:#ff7b72;font-weight:bold">.</span>delete()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#a5d6ff">&#34;All object versions and delete markers have been removed.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">if</span> __name__ <span style="color:#ff7b72;font-weight:bold">==</span> <span style="color:#a5d6ff">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">if</span> len(sys<span style="color:#ff7b72;font-weight:bold">.</span>argv) <span style="color:#ff7b72;font-weight:bold">&lt;</span> <span style="color:#a5d6ff">2</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#79c0ff">f</span><span style="color:#a5d6ff">&#34;Usage: </span><span style="color:#a5d6ff">{</span>sys<span style="color:#ff7b72;font-weight:bold">.</span>argv[<span style="color:#a5d6ff">0</span>]<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff"> &lt;bucket_name&gt;&#34;</span>)
</span></span><span style="display:flex;"><span>        sys<span style="color:#ff7b72;font-weight:bold">.</span>exit(<span style="color:#a5d6ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    bucket_to_purge <span style="color:#ff7b72;font-weight:bold">=</span> sys<span style="color:#ff7b72;font-weight:bold">.</span>argv[<span style="color:#a5d6ff">1</span>]
</span></span><span style="display:flex;"><span>    purge_bucket_interactive(bucket_to_purge)
</span></span></code></pre></div>
</details>
</div></p>
<div class="attention">
    But if you have millions of objects, you&rsquo;d better use Lifecycle Configuration rules to empty a version-enabled bucket.
</div>
<p>First, you need to pause the versioning. Then, create two Lifecycle Configuration rules.</p>
<p><strong>The first rule will delete all versions of the objects:</strong></p>
<ul>
<li>Apply to all objects in the bucket</li>
<li>Actions:
<ul>
<li>The 3rd option — &ldquo;Expire current versions of objects&rdquo;</li>
<li>The 4th option — &ldquo;Permanently delete previous versions of objects&rdquo;</li>
</ul>
</li>
<li>The number of days you would like the current version to expire, to do as soon as possible, enter 1 in the text box. That makes it &ldquo;1 day&rdquo;.</li>
<li>For the days after which the noncurrent versions will be permanently deleted, enter 1 in the text box. That makes it &ldquo;1 day&rdquo; of being noncurrent.</li>
</ul>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/s3-lifecycle-delete-versions_hu_7f11510da04596bc.webp"
                 alt="S3 Lifecycle Rule: Delete Versions"width="800"height="1000.66" />
        
    
    <figcaption>
        <p>S3 Lifecycle Rule: Delete Versions
            </p>
    </figcaption>
</figure>

<p>Due to how S3 versioning works, a special DELETE marker will be created for each object processed by the first rule. To handle the delete markers, you must create a new lifecycle rule, as you won’t be able to select the option to delete the &ldquo;delete markers&rdquo; in the first rule.</p>
<p><strong>For the second lifecycle rule</strong>, the steps are similar, and the only difference is that you must select the 5th and last option: &ldquo;Delete expired object delete markers or incomplete multipart uploads.&rdquo; Select both the options — &ldquo;Delete expired object delete markers&rdquo; and &ldquo;Delete incomplete multipart uploads&rdquo; — and set it to 1 day.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2025/01/29/aws-s3-cost-optimization-removing-redundancy-and-implementing-intelligent-tiering/s3-lifecycle-delete-markers_hu_376fdbd6194a89ec.webp"
                 alt="S3 Lifecycle Rule: Delete Markers"width="800"height="1057.09" />
        
    
    <figcaption>
        <p>S3 Lifecycle Rule: Delete Markers
            </p>
    </figcaption>
</figure>

<div class="attention">
    S3 Lifecycle operations are asynchronous, and it may take some time for the Lifecycle to delete the objects in your S3 bucket. However, at midnight UTC, once the S3 objects are marked for expiration, you are no longer charged for storing that objects, and S3 will do the rest.
</div>
<h1 id="implementation-results">Implementation Results</h1>
<ul>
<li>Immediate cost reduction: $120,000 baseline or $270,000 if the 7% growth rate remains</li>
<li>Projected additional cost reduction from Intelligent-Tiering: 48% — means the drop of the baseline price of the main bucket from $120,000 to roughly $63,000 a year</li>
<li>One-time transition cost: $210</li>
<li>Implementation time: 2 days</li>
<li>Storage class transition completed in 1 day</li>
</ul>
<p>The final $63,000 versus $235,000 is a nice result. Combining the data from Intelligent-Tiering with built-in Artifactory retention policies can reduce that even more. However, it would require some custom logic wrapped around.</p>
<h1 id="key-takeaways">Key Takeaways</h1>
<ul>
<li>Challenge your architecture decisions overtime.</li>
<li>Challenge redundancy — is it providing real value?</li>
<li>Regular cost reviews can be a source of quick wins.</li>
<li>Let automated solutions do the job, and do not overengineer things.</li>
<li>AWS Simple Storage Service, despite its name, might be tricky, but AWS has a bunch of tools to help you.</li>
</ul>
<p>S3 Lifecycle rules proved their worth twice: first by automating our transition to Intelligent-Tiering despite Artifactory&rsquo;s limitations and then by cleaning up millions of versioned objects without operational overhead.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Unpacking AWS Outages: System Design Lessons from Post-Event Summaries</title>
      <link>https://devdosvid.blog/2024/06/03/unpacking-aws-outages-system-design-lessons-from-post-event-summaries/</link>
      <pubDate>Mon, 03 Jun 2024 00:52:54 +0200</pubDate>
      <guid>https://devdosvid.blog/2024/06/03/unpacking-aws-outages-system-design-lessons-from-post-event-summaries/</guid>
      <description>Explore AWS outage case studies, uncovering essential strategies for building resilient systems by understanding dependencies and preventing cascading failures</description>
      <content:encoded><![CDATA[<p>In this blog post, I’m excited to share some valuable system design insights drawn from AWS’s post-event summaries on major outages.</p>
<p>System design is a topic I’m especially passionate about—it’s even my favorite interview question at Grammarly, and I love to conduct those interviews. This fascination led me to thoroughly analyze AWS’s PES in search of the most interesting cases.</p>
<p>Learning from mistakes is essential. Yet it&rsquo;s precious to learn from others&rsquo; mistakes because they come for free (for you, but not for their owners). The AWS team is doing a great job sharing their Post-Event Summaries because they not only demonstrate the open engineering culture but also help others.</p>
<p>From the sixteen reports available at the time of writing, I’ve selected the four most captivating ones. Each presents unexpected challenges and turns of events, along with valuable outcomes we can learn from. Let&rsquo;s explore these intriguing reports and uncover the key strategies for building more resilient systems.</p>
<h2 id="remirroring-storm">Remirroring Storm</h2>
<p>The April 21, 2011, Amazon EC2/EBS event<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> in the US East Region provides valuable insights into dependency management and the dangers of cascading failures.</p>
<p>A network configuration change, promoted as a part of normal scaling activity, set off a cascade of failures in the Amazon Elastic Block Store system. The intention was simple — to upgrade the capacity of the primary network. This operation involved a traffic shift between underlying networks, but it was executed incorrectly so that change caused many EBS nodes to disconnect from their replicas. When these nodes reconnected, they tried to replicate their data on other nodes, quickly overwhelming the EBS cluster’s capacity. This surge, or as AWS called it “remirroring storm,” left many EBS volumes “stuck,” unable to process read and write operations.</p>
<p><strong>Blast Radius</strong>: Initially, the issue affected only a single Availability Zone in the US East Region, and about 13% of the volumes were in this “stuck” state. However, the outage soon spread to the entire region. The EBS control plane, responsible for handling API requests, was dependent on the degraded EBS cluster. The increased traffic from the remirroring storm overwhelmed the control plane, making it intermittently unavailable and affecting users across the region.</p>
<p><strong>Affected Services and Processes</strong>:</p>
<ul>
<li>EC2: Users faced difficulties launching new EBS-backed instances and managing existing ones.</li>
<li>EBS: Many volumes became “stuck,” rendering them inaccessible and impacting EC2 instances dependent on them.</li>
<li>RDS: As a service dependent on EBS, some RDS databases, particularly single-AZ deployments, became inaccessible due to the EBS volume issues.</li>
</ul>
<p>This incident underscores the importance of building resilient systems. The EBS control plane’s dependence on a single Availability Zone and the absence of back-off mechanisms in the remirroring process were critical factors in the cascading failures.</p>
<h2 id="electrical-storm">Electrical Storm</h2>
<p>The June 29, 2012, AWS services event<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> in the US East Region exemplifies how a localized power outage can trigger a region-wide service disruption due to complex dependencies.</p>
<p>A severe electrical storm caused a power outage in a single data center, impacting a small portion of AWS resources in the US East Region — a single-digit percentage of the total resources in the region (as of the date of the incident).</p>
<p><strong>Blast Radius</strong>: The power outage was initially confined to the affected Availability Zone. However, it soon led to degrading service control planes that manage resources across the entire region. While these control planes aren&rsquo;t required for ongoing resource usage, their degradation hindered users&rsquo; ability to respond to the outage, such using the AWS console to try moving resources to other Availability Zones.</p>
<p><strong>Affected Services and Processes</strong>:</p>
<ul>
<li>EC2 and EBS: Approximately 7% of EC2 instances and a similar proportion of EBS volumes in the region were offline until power was restored and systems restarted. The control planes for both services were significantly impacted, making it difficult for users to launch new instances, create EBS volumes, or attach volumes in any Availability Zone within the region.</li>
<li>ELB: Although the direct impact was limited to ELBs within the affected data center, the service&rsquo;s inability to process new requests quickly hampered recovery for users trying to replace lost EC2 capacity in other Availability Zones.</li>
<li>RDS: Many Single-AZ databases in the affected zone became inaccessible due to their dependent EBS volumes being affected. A few Multi-AZ RDS instances, designed for redundancy, also failed to failover automatically due to a software bug triggered by the specific server shutdown sequences during the power outage.</li>
</ul>
<p>Even though we host our applications in the cloud and power outages may not be a primary concern when starting new projects, this event underscores the critical importance of designing fault-tolerant systems. It also highlights the potential for cascading failures when a small percentage of infrastructure is impacted. Dependencies on control planes and the interconnected nature of services can significantly amplify the impact of localized outages.</p>
<h2 id="simple-point-of-failure">Simple Point of Failure</h2>
<p>Another excellent example of how small can quickly become big — is the Amazon SimpleDB service disruption on June 13, 2014, in the US East Region<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. This incident demonstrates how a seemingly minor issue can escalate into a significant disruption due to dependencies on a centralized service.</p>
<p>A power outage in a single data center caused multiple storage nodes to become unavailable. This sudden failure led to a spike in load on the internal lock service, which manages node responsibility for data and metadata. And while this lock services is replicated accross multiple data centers, the load spike wat too sudden and too high.</p>
<p><strong>Blast Radius</strong>: Initially, the impact was confined to the storage nodes in the affected data center. However, the increased load on the centralized lock service, crucial for all SimpleDB operations, caused cascading failures that affected the entire service.</p>
<p><strong>Affected Services and Processes</strong>:</p>
<ul>
<li>SimpleDB: The service became unavailable for all API calls, except for a small fraction of eventually consistent read calls, because the storage and metadata nodes couldn’t renew their membership with the overloaded lock service. This unavailability prevented users from accessing and managing their data.</li>
</ul>
<p>This outage highlights the critical importance of addressing the single point of failure when designing systems. The centralized nature of the lock service, intended for coordination, became a single point of failure. A more distributed or load-balanced approach for the lock service could have mitigated the impact of the simultaneous node failures.</p>
<h2 id="scaling-for-the-better">Scaling for the better</h2>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2024/06/03/unpacking-aws-outages-system-design-lessons-from-post-event-summaries/scaling-for-the-better_hu_fc5f52324b2a6bc7.webp"
                 alt="In search of absolute"width="500"height="500" />
        
    
    <figcaption>
        <p>In search of absolute
            </p>
    </figcaption>
</figure>

<p>The Amazon Kinesis event in the US East Region on November 25, 2020<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, is a perfect example of how adding capacity can unexpectedly trigger a cascade of failures due to unforeseen dependencies and resource limitations. What could possibly go wrong by adding more nodes to the cluster? Scaling horizontally is best practice, right? Well, it depends.</p>
<p>A small capacity addition to the front-end fleet of the Kinesis service led to unexpected behavior in the front-end servers responsible for routing requests.</p>
<p>These newly added servers exceeded the maximum allowed threads due to operating system configuration: each front-end server creates operating system threads for each of the other servers in the front-end fleet — this is needed for services to learn about new servers added to the cluster. Eventually, all this caused cache construction failures and prevented servers from routing requests to the back-end clusters.</p>
<p><strong>Blast Radius</strong>: Although the initial trigger was a capacity addition intended to enhance performance, the resulting issue affected the entire Kinesis service in the US East Region. The dependency of many AWS services on Kinesis amplified the impact significantly.</p>
<p><strong>Affected Services and Processes</strong>:</p>
<ul>
<li>Kinesis: Customers experienced failures and increased latencies when putting and getting Kinesis records, rendering the service unusable for real-time data processing.</li>
<li>Cognito: As a dependent service on Kinesis, Cognito faced elevated API failures and increased latencies for user pools and identity pools. This disruption prevented external users from authenticating or obtaining temporary AWS credentials.</li>
<li>CloudWatch: Kinesis Data Streams are used by CloudWatch to process metrics and log data. The event caused increased error rates and latencies for CloudWatch APIs (PutMetricData and PutLogEvents), with alarms transitioning to an INSUFFICIENT_DATA state, hindering monitoring and alerting capabilities.</li>
<li>Auto Scaling and Lambda: These services rely on CloudWatch metrics, so they were indirectly affected, too. Reactive Auto Scaling policies experienced delays, and Lambda function invocations encountered increased error rates due to memory contention caused by backlogged CloudWatch metric data.</li>
</ul>
<p>This incident highlights the importance of thoroughly understanding dependencies, resource limitations, and potential failure points when making changes to a system, even those intended to improve capacity or performance. Robust testing and monitoring are crucial to identify and mitigate such unexpected behaviors.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>The AWS outage reports reveal a fundamental truth about system design: <strong>complexity and interdependency can be both our greatest strengths and our most significant vulnerabilities</strong>.</p>
<p>As we build and scale our systems, let&rsquo;s strive for simplicity, resilience, and a thorough understanding of our dependencies.</p>
<p>To ensure our systems are prepared for the unexpected, it&rsquo;s crucial to internalize and act upon the lessons these incidents teach us. Here are some key takeaways to guide us in this:</p>
<ol>
<li><strong>Embrace Resilience</strong>: Design systems with robust fault-tolerance mechanisms to handle unexpected failures without cascading effects.</li>
<li><strong>Understand Dependencies</strong>: Map out and regularly review your system&rsquo;s dependencies to identify and mitigate potential single points of failure.</li>
<li><strong>Continuous Learning</strong>: Analyze past incidents, both your own and industry-wide, to gain insights and improve your system design.</li>
<li><strong>Proactive Monitoring</strong>: Implement comprehensive monitoring and alerting to detect and address issues before they escalate.</li>
<li><strong>Thorough Testing</strong>: Regularly test your systems under various failure scenarios to ensure they can withstand real-world conditions.</li>
</ol>
<p>The path to reliable systems is paved with continuous learning and adaptation. Let&rsquo;s embrace these lessons and push the boundaries of what our systems can achieve, ensuring that we are always prepared for the unexpected.  🙂</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://aws.amazon.com/message/65648/">Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region, April 21, 2011</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://aws.amazon.com/message/67457/">Summary of the AWS Service Event in the US East Region, June 29, 2012</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://aws.amazon.com/message/65649/">Summary of the Amazon SimpleDB Service Disruption, June 13, 2014.</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://aws.amazon.com/message/11201/">Summary of the Amazon Kinesis Event in the Northern Virginia (US-EAST-1) Region, November 25, 2020</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>A Deep Dive Into Terraform Static Code Analysis Tools: Features and Comparisons</title>
      <link>https://devdosvid.blog/2024/04/16/a-deep-dive-into-terraform-static-code-analysis-tools-features-and-comparisons/</link>
      <pubDate>Tue, 16 Apr 2024 21:14:15 +0200</pubDate>
      <guid>https://devdosvid.blog/2024/04/16/a-deep-dive-into-terraform-static-code-analysis-tools-features-and-comparisons/</guid>
      <description>Explore key features and comparisons of top Terraform static code analysis tools to enhance security and compliance in your infrastructure management.</description>
      <content:encoded><![CDATA[<p>Many teams employ Terraform by HashiCorp to efficiently manage their infrastructure, leveraging its ability to automate the lifecycle of complex environments. Yet, integrating security scanning into Terraform pipelines often remains overlooked, exposing these environments to potential security risks and compliance issues.</p>
<p>This article explores several prominent static code analyzers that support Terraform code and focus on its security scanning. This comparison will guide teams in choosing the right tool to enhance their security measures within Terraform workflows, ensuring safer and more compliant infrastructure management.</p>
<p>Here are the tools we&rsquo;ll be reviewing: <strong>KICS</strong>, <strong>tfsec</strong>, <strong>Trivy</strong>, <strong>Terrascan</strong>, <strong>Checkov</strong>, and <strong>Semgrep OSS</strong>.</p>
<p>While many of these tools also support other platforms and technologies, <strong>this review will concentrate exclusively on their functionality with Terraform.</strong></p>
<h2 id="why-use-static-code-analysis-for-terraform">Why use Static Code Analysis for Terraform</h2>
<p>Static code analysis tools are necessary to enhance the security of Terraform-managed infrastructures. Unlike linters, these tools focus not on syntax errors or coding style but delve deeply into the code to identify security vulnerabilities and potential compliance issues without running the actual code. This proactive approach to security helps safeguard the infrastructure from potential threats before deployment.</p>
<h3 id="key-benefits">Key Benefits</h3>
<ul>
<li>Early Detection: Identifies security vulnerabilities and misconfigurations early in development, preventing them from reaching production.</li>
<li>Compliance Assurance: Ensures Terraform code complies with industry standards and internal security policies.</li>
<li>Automated Security Integration: Seamlessly integrates with CI/CD pipelines, automating security checks to maintain a continuous focus on security.</li>
<li>Actionable Insights: Delivers detailed vulnerability reports, facilitating swift and effective resolution.</li>
<li>Scalability: Effectively handles increasing project complexity and size, maintaining rigorous security standards without additional manual effort.</li>
</ul>
<h3 id="expected-features">Expected Features</h3>
<ul>
<li><strong>Policy Coverage</strong>: The tool should offer comprehensive scanning capabilities to detect security vulnerabilities specific to Infrastructure as Code.</li>
<li><strong>Customizable Security Policies</strong>: It must allow users to define and adjust security policies and severity levels to align with specific project needs or compliance requirements.</li>
<li><strong>Seamless Integration</strong>: The analyzer should integrate effortlessly with existing CI/CD tools and version control systems, facilitating a smooth workflow.</li>
<li><strong>Detailed Reporting</strong>: Clear and actionable reports are crucial. The tool should prioritize issues based on severity and provide practical steps for remediation.</li>
<li><strong>Scanning Customization</strong>: Users should be able to tailor the scanning process to focus on particular aspects of the codebase, enabling targeted and efficient security assessments.</li>
</ul>
<p>With a clear understanding of the necessary features in a static code analyzer, which tools on the market best fulfill these criteria?</p>
<p>Let&rsquo;s take a closer look at some leading options!</p>
<h2 id="meet-the-static-code-analyzers-for-terraform">Meet the Static Code Analyzers for Terraform</h2>
<p>Following on what makes a static code analyzer robust, let&rsquo;s dive into some open-source tools that exemplify these essential features.</p>
<p>I picked six tools for my review. I know there are more on the market, but I focused on <strong>open-source, free-to-use</strong> tools and those that provide at least &gt;100 out-of-the-box scanning policies for Terraform.</p>
<p><strong>KICS</strong> (stands for &ldquo;Keeping Infrastructure as Code Secure&rdquo;): <br>
Owner/Maintainer: Checkmarx<br>
Age: First released on GitHub on November 30th, 2020<br>
License: <a href="https://github.com/Checkmarx/kics/blob/master/LICENSE">Apache License 2.0</a></p>
<p><strong>tfsec</strong><br>
Owner/Maintainer: Aqua Security (acquired in 2021)<br>
Age: First released on GitHub on March 5th, 2019<br>
License: <a href="https://github.com/aquasecurity/tfsec/blob/master/LICENSE">MIT License</a>
<div class="attention">
    tfsec project is no longer actively maintained in favor of the Trivy tool. But because many people still use it and it&rsquo;s quite famous, I added tfsec to this comparison.<br>
However, I recommend against using it for new projects.
</div></p>
<p><strong>Trivy</strong><br>
Owner/Maintainer: Aqua Security<br>
Age: First released on GitHub on May 7th, 2019<br>
License: <a href="https://github.com/aquasecurity/trivy/blob/main/LICENSE">Apache License 2.0</a><br>
<em>backward-compatible with tfsec</em></p>
<p><strong>Terrascan</strong><br>
Owner/Maintainer: Tenable (acquired in 2022)<br>
Age: First release on GitHub on November 28th, 2017<br>
License: <a href="https://github.com/tenable/terrascan/blob/master/LICENSE">Apache License 2.0</a></p>
<p><strong>Checkov</strong><br>
Owner/Maintainer: Prisma Cloud by Palo Alto Networks (acquired in 2021)<br>
Age: First released on GitHub on March 31st, 2021<br>
License: <a href="https://github.com/bridgecrewio/checkov/blob/main/LICENSE">Apache License 2.0</a></p>
<p><strong>Semgrep OSS</strong><br>
Owner/Maintainer: Semgrep<br>
Age: First release on GitHub on February 6th, 2020<br>
License: <a href="https://github.com/semgrep/semgrep/blob/develop/LICENSE">GNU Lesser General Public License v2.1</a></p>
<p>These tools are essential in enhancing Terraform&rsquo;s security posture and reflect a strong collaboration between open-source communities and enterprise backing. This blend ensures that the tools are not only accessible but also robustly maintained and up-to-date.</p>
<p>Let’s explore how these tools stack up regarding features and usability.</p>
<h2 id="comparing-out-of-the-box-policies-and-terraform-providers">Comparing Out-of-the-Box Policies and Terraform Providers</h2>
<p>Understanding the number and variety of default policies each tool offers is crucial for those just beginning to explore security automation for Terraform.</p>
<p>The extent of out-of-the-box policies can significantly ease the integration process of static analysis by providing immediate and comprehensive insights into potential security and compliance issues. Similarly, the number of supported Terraform Providers also plays a critical role.</p>
<p>In this chapter, we delve into these foundational features across observed tools, helping you pinpoint which one could best satisfy your requirements for robust, ready-to-use security scanning.</p>
<table>
  <thead>
      <tr>
          <th>Tool</th>
          <th>Policies</th>
          <th>Supported Terraform Providers</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>KICS</strong></td>
          <td>663</td>
          <td>aws, azure, gcp, kubernetes, alicloud, databricks, github, nifcloud</td>
      </tr>
      <tr>
          <td><strong>tfsec</strong></td>
          <td>154</td>
          <td>aws, azure, gcp, digitalocean, kubernetes, cloudstack, github, openstack, oracle</td>
      </tr>
      <tr>
          <td><strong>Trivy</strong></td>
          <td>322</td>
          <td>aws, azure, gcp, digitalocean, cloudstack, github, oracle, openstack</td>
      </tr>
      <tr>
          <td><strong>Terrascan</strong></td>
          <td>790</td>
          <td>aws, azure, gcp, digitalocean, kubernetes, docker, github</td>
      </tr>
      <tr>
          <td><strong>Checkov</strong></td>
          <td>2110</td>
          <td>aws, azure, gcp, digitalocean, kubernetes, github, gitlab, ibm, linode, openstack, alicloud</td>
      </tr>
      <tr>
          <td><strong>Semgrep OSS</strong></td>
          <td>362</td>
          <td>aws, azure, gcp</td>
      </tr>
  </tbody>
</table>
<p>As you can see, all tools support the &ldquo;Big Three&rdquo; cloud service Terraform providers—AWS, Azure, and GCP—for managing resources on these popular platforms.</p>
<p>With over 2000 out-of-the-box policies, Checkov significantly stands out from the competition. This tool also leads in the total number of supported Terraform providers.</p>
<p>While the default policies provide a strong foundation for security scanning, the ability to tailor these policies is just as crucial. Next, we&rsquo;ll explore how each tool accommodates custom policy capabilities, allowing you to fine-tune the policies to fit your project&rsquo;s specific requirements.</p>
<h2 id="custom-policy-capabilities">Custom Policy Capabilities</h2>
<p>Default policies serve as the foundation, but the nuances of each project demand the extension of this base.</p>
<p>Here, we delve into how each tool enables you to add custom policies, thus enhancing and refining the provided defaults.</p>
<p>While all six tools support adding custom policies to their default set, they differ in terminology: &lsquo;policy&rsquo; is the common term, whereas KICS refers to them as &lsquo;queries,&rsquo; and Semgrep calls them &lsquo;rules.&rsquo;</p>
<p>Regarding policy syntax:</p>
<p><strong>OPA Rego</strong> syntax is used by <a href="https://docs.kics.io/latest/creating-queries/">KICS</a>, <a href="https://aquasecurity.github.io/trivy/v0.50/docs/scanner/misconfiguration/custom/">Trivy</a>, <a href="https://aquasecurity.github.io/tfsec/latest/guides/rego/rego/">tfsec</a>, and <a href="https://runterrascan.io/docs/policies/policies/">Terrascan</a>.  It&rsquo;s a powerful language widely adopted in the industry, though there&rsquo;s a learning curve that could pay dividends for future projects.</p>
<p><strong>YAML</strong> syntax is used by <a href="https://www.checkov.io/3.Custom%20Policies/Custom%20Policies%20Overview.html">Checkov</a> and <a href="https://semgrep.dev/docs/writing-rules/rule-syntax/">Semgrep</a>. This offers a familiar and straightforward start, with Checkov also allowing policies to be written in Python, albeit with some constraints. With YAML, the ease of use is balanced against the limitations set by the tool&rsquo;s capabilities.</p>
<p>Understanding these differences will guide you to a tool that matches your security requirements, your team&rsquo;s expertise, and the scope of your infrastructure projects.</p>
<p>To illustrate, here is an example of a KICS Rego policy checking for default RDS instance ports:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>package Cx
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>import data.generic.common as common_lib
</span></span><span style="display:flex;"><span>import data.generic.terraform as tf_lib
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CxPolicy[result] {
</span></span><span style="display:flex;"><span>	db := input.document[i].resource.aws_db_instance[name]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	enginePort := common_lib.engines[e]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	db.engine == e
</span></span><span style="display:flex;"><span>	db.port == enginePort
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	result := {
</span></span><span style="display:flex;"><span>		&#34;documentId&#34;: input.document[i].id,
</span></span><span style="display:flex;"><span>		&#34;resourceType&#34;: &#34;aws_db_instance&#34;,
</span></span><span style="display:flex;"><span>		&#34;resourceName&#34;: tf_lib.get_resource_name(db, name),
</span></span><span style="display:flex;"><span>		&#34;searchKey&#34;: sprintf(&#34;aws_db_instance[%s].port&#34;, [name]),
</span></span><span style="display:flex;"><span>		&#34;issueType&#34;: &#34;IncorrectValue&#34;,
</span></span><span style="display:flex;"><span>		&#34;keyExpectedValue&#34;: sprintf(&#34;aws_db_instance[%s].port should not be set to %d&#34;, [name, enginePort]),
</span></span><span style="display:flex;"><span>		&#34;keyActualValue&#34;: sprintf(&#34;aws_db_instance[%s].port is set to %d&#34;, [name, enginePort]),
</span></span><span style="display:flex;"><span>		&#34;searchLine&#34;: common_lib.build_search_line([&#34;resource&#34;, &#34;aws_db_instance&#34;, name, &#34;port&#34;], []),
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And an example of a Checkov YAML policy forbidding specific EC2 instance types:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ff7b72">---</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"></span><span style="color:#7ee787">metadata</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"> </span><span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;Org&#39;s compute instances should not be p5.48xlarge or p4d.24xlarge&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"> </span><span style="color:#7ee787">id</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;ACME_AWS_FORBIDDEN_EC2_TYPES&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"> </span><span style="color:#7ee787">category</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;NETWORKING&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"></span><span style="color:#7ee787">definition</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"> </span><span style="color:#7ee787">or</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"> </span>- <span style="color:#7ee787">cond_type</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;attribute&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">resource_types</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span>- <span style="color:#a5d6ff">&#34;aws_instance&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">attribute</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;instance_type&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">operator</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;not_equals&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">value</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;p5.48xlarge&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"> </span>- <span style="color:#7ee787">cond_type</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;attribute&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">resource_types</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span>- <span style="color:#a5d6ff">&#34;aws_instance&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">attribute</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;instance_type&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">operator</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;not_equals&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">   </span><span style="color:#7ee787">value</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;p4d.24xlarge&#34;</span><span style="color:#6e7681">
</span></span></span></code></pre></div><p>With the ability to tailor policies to our specific needs, we&rsquo;ll next explore each tool&rsquo;s capacity to integrate broadly, determining how well they play with the rest of our tech stack.</p>
<h2 id="integration-capabilities">Integration Capabilities</h2>
<p>Integration capabilities are the cornerstone of efficient DevOps practices.</p>
<p>This section will evaluate how each static code analyzer enhances your tech stack through seamless integration with other systems and technologies.</p>
<p>We will assess each tool against four key integration points that are vital for development workflows:</p>
<ul>
<li><strong>Docker Image</strong>: Ensures easy deployment across any container-supported environment.</li>
<li><strong>IDE Plugins</strong>: Facilitates real-time feedback and improves code quality directly within the developer&rsquo;s workspace.</li>
<li><strong>CI/CD Systems</strong>: Supports direct integration through plugins or extensions, eliminating the need for manual downloads or CLI setups.</li>
<li><strong>Pre-commit Hook</strong>: Provides an early security checkpoint by scanning code before it is committed, catching errors at the initial stages.</li>
</ul>
<table>
  <thead>
      <tr>
          <th>Tool</th>
          <th>Docker Image</th>
          <th>IDE Plugins</th>
          <th>CI/CD Systems</th>
          <th>Hook</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>KICS</strong></td>
          <td>✅</td>
          <td>VSCode</td>
          <td>Github Actions, GitLab, Terraform Cloud, Codefresh</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>tfsec</strong></td>
          <td>✅</td>
          <td>VSCode, JetBrains, Vim</td>
          <td>Github Actions</td>
          <td>❌</td>
      </tr>
      <tr>
          <td><strong>Trivy</strong></td>
          <td>✅</td>
          <td>VSCode, JetBrains, Vim</td>
          <td>Azure DevOps, GitHub Actions, Buildkite, Dagger, Semaphore, CircleCI, Concourse CI</td>
          <td>❌</td>
      </tr>
      <tr>
          <td><strong>Terrascan</strong></td>
          <td>✅</td>
          <td>VSCode</td>
          <td>GitHub Actions, Atlantis</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>Checkov</strong></td>
          <td>✅</td>
          <td>VSCode, JetBrains</td>
          <td>GitHub Actions, GitLab</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>Semgrep OSS</strong></td>
          <td>✅</td>
          <td>VSCode, JetBrains, Emacs, Vim</td>
          <td>GitLab</td>
          <td>✅</td>
      </tr>
  </tbody>
</table>
<p>In addition to the table above, here are a few noteworthy features of some tools:</p>
<ul>
<li>Checkov supports OpenAI integration to suggest remediations. But be careful because AI tends to hallucinate.</li>
<li>KICS supports applying auto-remediation for some of its out-of-the-box policies. This also applies to custom policies, where you can define remediations and apply them automatically.</li>
<li>Terrascan is the only one that provides the VSCode extension to create and test custom policies written in Rego.</li>
<li>GitLab uses KICS as its default built-in IaC scanner — available out of the box with &ldquo;<a href="https://docs.gitlab.com/ee/user/application_security/iac_scanning/">Infrastructure as Code scanning</a>&rdquo;. However, there&rsquo;s also <a href="https://gitlab.com/guided-explorations/ci-cd-plugin-extensions/checkov-iac-sast">GitLab CI Component</a> available for Checkov.</li>
</ul>
<p>Having covered the integration capabilities, let’s now focus on the output formats each tool provides.</p>
<h2 id="output-formats-provided">Output Formats Provided</h2>
<p>Output formats extend the utility of static code analysis, facilitating integration with the CI/CD feedback loop and enabling its use as an artifact in subsequent CI jobs.</p>
<p>This chapter examines the variety of formats each tool supports for this purpose.</p>
<p>Each tool offers a range of output formats tailored to different needs.</p>
<p><strong>For GitLab users</strong>: For teams leveraging GitLab&rsquo;s security scanning, KICS, Checkov, and Semgrep OSS are equipped with compatible output formats, facilitating smooth GitLab integration.</p>
<p><strong>For GitHub users</strong>: SARIF&rsquo;s adoption as an industry standard, particularly by GitHub for code scanning, makes it a must-have. All tools assessed offer SARIF support, ensuring interoperability and broad utility.</p>
<p><strong>JUnit Reports</strong>: The availability of JUnit output is crucial for capturing test results in a format recognizable by various CI systems. Trivy, Terrascan, Checkov, and Semgrep OSS support this, enabling clear visualization of test outcomes and enhancing the feedback loop within CI pipelines.</p>
<p>Beyond these, each tool supports additional formats, enriching their application and versatility. Here&rsquo;s the full breakdown of the output formats, complementing the standard CLI output:</p>
<table>
  <thead>
      <tr>
          <th>Tool</th>
          <th>Supported Output Formats</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>KICS</strong></td>
          <td>ASFF, CSV, Code Climate, CycloneDX, GItLab SAST, HTML, JSON, JUnit, PDF, SARIF, SonarQube</td>
      </tr>
      <tr>
          <td><strong>tfsec</strong></td>
          <td>Checkstyle, CSV, HTML, JSON, JUnit, Markdown, SARIF</td>
      </tr>
      <tr>
          <td><strong>Trivy</strong></td>
          <td>ASFF, Cosign, CycloneDX, JSON, SARIF, SPDX</td>
      </tr>
      <tr>
          <td><strong>Terrascan</strong></td>
          <td>JSON, JUnit, SARIF, XML, YAML</td>
      </tr>
      <tr>
          <td><strong>Checkov</strong></td>
          <td>CSV, CycloneDX, GItLab SAST, JSON, JUnit, SARIF, SPDX</td>
      </tr>
      <tr>
          <td><strong>Semgrep OSS</strong></td>
          <td>Emacs, GitLab SAST, JSON, JUnit, SARIF, Vim</td>
      </tr>
  </tbody>
</table>
<p>Moving from output formats to operational adaptability, let&rsquo;s investigate the customization options for scanner settings. This important feature allows each tool to align with varied project demands.</p>
<h2 id="customizing-scanner-settings">Customizing Scanner Settings</h2>
<p>This chapter moves beyond the default scanner settings and delves into scanner settings&rsquo; customizability, ensuring that tools can be calibrated for any development environment or security requirement.</p>
<p>I will evaluate each tool against criteria that define a tool&rsquo;s adaptability and user-friendliness:</p>
<ul>
<li><strong>Targeted Scans</strong>: Select specific directories for scanning or exclusion to focus on pertinent areas and skip irrelevant ones.</li>
<li><strong>In-Code Ignore Policies</strong>: Enable ignore directives within code to skip checks when exceptions apply selectively.</li>
<li><strong>Severity Thresholds</strong>: Set reporting to include only findings above a chosen severity level, concentrating on the most impactful issues.</li>
<li><strong>Configuration File</strong>: Employ configuration files for consistency and collaboration, enabling a &lsquo;configuration as code&rsquo; approach.</li>
<li><strong>TF Variables Interpolation</strong>: Interpret and evaluate Terraform variables for an accurate security assessment of IaC.</li>
<li><strong>Module Scanning</strong>: For complete coverage, scans should include both local and remote (public/private) Terraform modules.</li>
</ul>
<p>Based on these criteria, the following table offers a comparative view of how each tool performs, giving you a clear snapshot of their customization capabilities:</p>
<table>
  <thead>
      <tr>
          <th>Tool</th>
          <th>Targeted Scans</th>
          <th>Ignore Policies</th>
          <th>Min Severity</th>
          <th>Config File</th>
          <th>Variables Interpolation</th>
          <th>Module Scanning</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>KICS</strong></td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>⁉️️</td>
      </tr>
      <tr>
          <td><strong>tfsec</strong></td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>Trivy</strong></td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>Terrascan</strong></td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>Checkov</strong></td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
      </tr>
      <tr>
          <td><strong>Semgrep OSS</strong></td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>❌</td>
          <td>✅</td>
          <td>❌</td>
      </tr>
  </tbody>
</table>
<p>Most reviewed tools meet nearly all the criteria set for scanner setting customization, demonstrating their flexibility and advanced capabilities. However, there are notable features worth considering:</p>
<ul>
<li>KICS: Provides limited module scanning capabilities, restricted to some public modules from the Terraform registry, and does not cover local or private custom modules.</li>
<li>Terrascan &amp; Trivy: Both feature server modes that centralize vulnerability databases. This centralization facilitates a unified approach to applying policies and configurations, enhancing consistency and efficiency for teams and reducing the management overhead of diverse policies across multiple projects.</li>
<li>Semgrep: It doesn&rsquo;t support scanner configuration files; instead, it uses the &ldquo;config&rdquo; word to call the rule sets and accepts such configs. Notably, it also does not support the scanning of Terraform modules at all.</li>
</ul>
<h2 id="terraform-security-scanning-the-big-picture-and-top-pick">Terraform Security Scanning: The Big Picture and Top Pick</h2>
<p>Here&rsquo;s a comprehensive comparison summary to guide your selection of the most suitable Terraform static code analyzer:</p>
<table>
  <thead>
      <tr>
          <th>Tool</th>
          <th>Default Policies</th>
          <th>Custom Policies</th>
          <th>Integration</th>
          <th>Output Formats</th>
          <th>Customization</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>KICS</strong></td>
          <td>663</td>
          <td>OPA Rego</td>
          <td>✅Docker, ✅IDE, ✅CI/CD, ✅Git Hook</td>
          <td>ASFF, CSV, Code Climate, CycloneDX, GItLab SAST, HTML, JSON, JUnit, PDF, SARIF, SonarQube</td>
          <td>✅Targeted Scans, ✅Ignore Policies, ✅Min Severity, ✅Config File, ✅Variables Interpolation, ❌Module Scanning</td>
      </tr>
      <tr>
          <td><strong>tfsec</strong></td>
          <td>154</td>
          <td>OPA Rego</td>
          <td>✅Docker, ✅IDE, ✅CI/CD, ❌Git Hook</td>
          <td>Checkstyle, CSV, HTML, JSON, JUnit, Markdown, SARIF</td>
          <td>✅Targeted Scans, ✅Ignore Policies, ✅Min Severity, ✅Config File, ✅Variables Interpolation, ✅Module Scanning</td>
      </tr>
      <tr>
          <td><strong>Trivy</strong></td>
          <td>322</td>
          <td>OPA Rego</td>
          <td>✅Docker, ✅IDE, ✅CI/CD, ❌Git Hook</td>
          <td>ASFF, Cosign, CycloneDX, JSON, SARIF, SPDX</td>
          <td>✅Targeted Scans, ✅Ignore Policies, ✅Min Severity, ✅Config File, ✅Variables Interpolation, ✅Module Scanning</td>
      </tr>
      <tr>
          <td><strong>Terrascan</strong></td>
          <td>790</td>
          <td>OPA Rego</td>
          <td>✅Docker, ✅IDE, ✅CI/CD, ✅Git Hook</td>
          <td>JSON, JUnit, SARIF, XML, YAML</td>
          <td>✅Targeted Scans, ✅Ignore Policies, ✅Min Severity, ✅Config File, ✅Variables Interpolation, ✅Module Scanning</td>
      </tr>
      <tr>
          <td><strong>Checkov</strong></td>
          <td>2110</td>
          <td>YAML, Python</td>
          <td>✅Docker, ✅IDE, ✅CI/CD, ✅Git Hook</td>
          <td>CSV, CycloneDX, GItLab SAST, JSON, JUnit, SARIF, SPDX</td>
          <td>✅Targeted Scans, ✅Ignore Policies, ✅Min Severity, ✅Config File, ✅Variables Interpolation, ✅Module Scanning</td>
      </tr>
      <tr>
          <td><strong>Semgrep OSS</strong></td>
          <td>362</td>
          <td>YAML</td>
          <td>✅Docker, ✅IDE, ✅CI/CD, ✅Git Hook</td>
          <td>Emacs, GitLab SAST, JSON, JUnit, SARIF, Vim</td>
          <td>✅Targeted Scans, ✅Ignore Policies, ✅Min Severity, ❌Config File, ✅Variables Interpolation, ❌Module Scanning</td>
      </tr>
  </tbody>
</table>
<p>Integrating a Terraform security scanning into your development pipeline is a proven strategy to boost your security posture. These tools detect potential vulnerabilities early and enforce best practices and compliance standards, representing a proactive approach to infrastructure security.</p>
<p>For teams not yet utilizing these tools, <strong>Checkov</strong> is my top recommendation:</p>
<ul>
<li>Biggest number of default policies and supported Terraform providers for a quick start.</li>
<li>Custom policy support in YAML and Python for flexible policy creation.</li>
<li>Wide integration options with Docker, IDEs, CI/CD systems, and Git Hooks for a smooth workflow.</li>
</ul>
<p>Please share your favorite tool in the comments below! Also, let me know if I missed a cool product that should have been included in the review.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Mastering AWS API Gateway V2 HTTP and AWS Lambda With Terraform</title>
      <link>https://devdosvid.blog/2024/01/09/mastering-aws-api-gateway-v2-http-and-aws-lambda-with-terraform/</link>
      <pubDate>Tue, 09 Jan 2024 03:33:10 +0100</pubDate>
      <guid>https://devdosvid.blog/2024/01/09/mastering-aws-api-gateway-v2-http-and-aws-lambda-with-terraform/</guid>
      <description>The article provides insights into using AWS API Gateway and AWS Lambda with Terraform for efficient, cost-effective serverless solutions.</description>
      <content:encoded><![CDATA[<p>With a solid foundation in AWS API Gateway and Lambda for serverless architecture, my recent deep dive into these cloud computing services felt like uncovering new layers in familiar territory. This article aims to be a comprehensive guide for developers and DevOps professionals looking to master serverless solutions using AWS and Terraform.</p>
<p>The article provides an in-depth guide to <strong>combining AWS API Gateway V2 HTTP API</strong> (yes, this is the official name of that service 😄) <strong>and AWS Lambda</strong> services to implement a simple, robust, and cost-effective serverless back-end using Terraform.</p>
<p>The journey was enlightening and engaging, especially as I were transforming these services into Infrastructure as Code. Through this article, I aim to share those moments of insight and the practical, hands-on tips that emerged from weaving these AWS services into a seamless, serverless architecture.</p>
<h2 id="navigating-the-system-design-http-api-gateway-and-lambda-in-action">Navigating the System Design: HTTP API Gateway and Lambda in Action</h2>
<p>Beginning our journey, we examine the complexities of serverless architecture, focusing on HTTP API and Lambda. A comprehensive system diagram will guide us as we analyze each component&rsquo;s function and their collaborative roles in the larger infrastructure.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2024/01/09/mastering-aws-api-gateway-v2-http-and-aws-lambda-with-terraform/api-gateway-lambda-authorization-flow_hu_5baac0e04f3b3ca.webp"
                 alt="HTTP API Gateway and AWS Lambda flowchart"width="800"height="440.50" />
        
    
    <figcaption>
        <p>HTTP API Gateway and AWS Lambda flowchart
            </p>
    </figcaption>
</figure>

<p>In our architecture, the HTTP API delegates access control to the Lambda function called &ldquo;Authorizer&rdquo;. This function stands as the gatekeeper, ensuring that only legitimate requests pass through to the underlying business logic.</p>
<p>The HTTP API can have multiple routes (e.g., &ldquo;/calendar,&rdquo; &ldquo;/meters,&rdquo; and so on) and use different Authorizers per route or a single one for all of them. Clients that send their requests to the API must include specific identification information in their request header or query string. In this project, I go with a single authorizer to keep it simple.</p>
<p>Upon receiving a request, the API service forwards a payload to the Authorizer containing metadata about the request, such as headers and query string components. The Authorizer processes this metadata (headers, in my case) to determine the request&rsquo;s legitimacy.</p>
<p>The decision, Allow or Deny, is passed back to the API, and if allowed, the API service then forwards the original request to the back-end, which, in this case, is implemented by additional Lambda functions. Otherwise, the client gets a response with a 403 status code, and the original request is not passed to the back-end.</p>
<div class="beehiiv-subscribe-container">
    <h3>Subscribe to blog updates!</h3>
    <iframe src="https://embeds.beehiiv.com/60009a3f-3202-4ac0-85f8-0d3db1ea781b?slim=true" data-test-id="beehiiv-embed"
        height="52" frameborder="0" scrolling="no"
        style="margin: 0; border-radius: 0px !important; background-color: transparent;"></iframe>
</div>
<h2 id="behind-the-decision-why-such-a-setup">Behind The Decision: Why Such a Setup?</h2>
<p>Choosing the right architectural setup is critical in balancing simplicity, cost-efficiency, and security. In this section, we uncover why integrating AWS HTTP API Gateway with Lambda Authorizer is a compelling choice, offering a streamlined approach without compromising security.</p>
<h3 id="cost-effectiveness-balancing-performance-and-price">Cost-Effectiveness: Balancing Performance and Price</h3>
<p>The AWS HTTP API is noteworthy for its streamlined and simple design compared to other API Gateway options. That translates directly into cost savings for businesses. Its efficiency makes it an ideal choice for cost-effective serverless computing, especially for those looking to optimize their cloud infrastructure with Terraform automation. Here is a more detailed comparison of different API Gateway options — <a href="https://docs.aws.amazon.com/whitepapers/latest/best-practices-api-gateway-private-apis-integration/cost-optimization.html">Cost optimization</a>.</p>
<p>Security with Lambda Authorizer. This option means a Lambda function used for authorization, which is lean and efficient. It generally requires a bare minimum of resources. It executes quickly, particularly when configured with the ARM-based environment and 128M RAM allocation, costing $0,0000017 per second of running time, with $0.20 per 1M requests per month.</p>
<p>💰 This pricing and performance combination are well-suited for rapid, lightweight authorizations. Together with AWS Lambda as a back-end, it makes a cost-effective solution. For example, if we add a few more Lambdas to back-end and assume that our setup receives 10000 requests per month, it would cost around $0.6 per month. Here is the link to detailed calculations — <a href="https://calculator.aws/#/estimate?id=b1a8a473ab98ede32f5ca384c5e9487b967efafa">AWS Pricing Calculator</a>.</p>
<h3 id="simplicity-in-configuration-the-power-of-header-based-authorization">Simplicity in Configuration: The Power of Header-Based Authorization</h3>
<p>A header-based authentication method facilitates straightforward client-server communication, often requiring less coding and resources to implement compared to more complex schemes.</p>
<p>Although HTTP API offers stronger JWT-based authorization and mutual TLS authentication, header-based authorization remains a suitable choice for simpler applications that prioritize ease and quickness. <em>By the way, there is also an option for IAM-based authorization whose core idea is the &ldquo;private API&rdquo; or internal usage of the API (e.g., solely inside the VPC, no internet), but with &ldquo;<a href="https://docs.aws.amazon.com/rolesanywhere/latest/userguide/introduction.html">IAM Anywhere</a>,&rdquo; this can be expanded to practically anywhere.</em> 😁</p>
<p>This architecture suits applications requiring rapid development and deployment without complex authorization mechanisms. It&rsquo;s ideal for small to medium-sized serverless applications or specific use cases in larger systems where quick, cost-effective, and secure access to APIs is a priority.</p>
<p>💡 Imagine a retail company wanting to manage its inventory efficiently. By leveraging AWS API Gateway and Lambda, they can develop a system where each item&rsquo;s RFID tags are scanned and processed through an API endpoint. When a product is moved or sold, its status is updated in real-time in the database, facilitated by Lambda functions. This serverless architecture ensures high availability and scalability and significantly reduces operational costs, a crucial factor for the highly competitive retail industry. This example showcases how our serverless setup can be effectively utilized in retail for streamlined inventory tracking and management.</p>
<h2 id="exploring-aws-lambda-features-and-integration">Exploring AWS Lambda: Features and Integration</h2>
<p>Diving into AWS Lambda, this section explores its features and indispensable role within the serverless infrastructure.  We will unravel the complexities of Lambda functions and examine the practicalities of deploying and managing these functions within the project.</p>
<h3 id="aws-lambda-runtime-and-deployment-model">AWS Lambda Runtime and Deployment Model</h3>
<p>🚀 Choosing the <strong>AWS Lambda runtime arm64</strong>, combined with the OS-only runtime based on <strong>Amazon Linux 2023</strong>, strategically boosts cost efficiency and performance. This choice aligns with the best practices for serverless computing in AWS, offering an optimal solution for those seeking to leverage AWS services for scalable cloud solutions.</p>
<p>Particularly effective for Go-based functions, this runtime configuration is lean yet powerful. For applications in other languages, delving into <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html">language-specific runtimes based on AL 2023</a> can also leverage the latest efficiencies of AWS-managed operating systems.</p>
<div class="attention">
    I also welcome you to read this benchmarking analysis to get more insights about the ARM-based environment for AWS Lambda — <a href="https://aws.amazon.com/blogs/apn/comparing-aws-lambda-arm-vs-x86-performance-cost-and-analysis-2/">Comparing AWS Lambda Arm vs. x86 Performance, Cost, and Analysis</a>.
</div>
<p>The .<strong>zip deployment</strong> model is chosen for its simplicity, avoiding additional management of the image registry (ECR) and Docker images. Also, AWS automatically patches .zip functions for the latest runtime security and bug fixes.</p>
<h3 id="efficient-terraform-coding-for-aws-lambda">Efficient Terraform Coding for AWS Lambda</h3>
<p>In our architecture, AWS Lambda functions serve dual purposes — as an authentication gatekeeper and a robust back-end for business logic. Despite varying code across functions, their configurations share much of similarities.</p>
<p>By adhering to the DRY (Don&rsquo;t Repeat Yourself) principle, I have crafted a Terraform module to streamline the management of Lambda functions and their dependencies. This approach ensures maintainable and scalable infrastructure. The module&rsquo;s structure is as follows:</p>
<ul>
<li><code>aws_lambda_function</code> — to describe the core configuration of the function</li>
<li><code>aws_iam_role</code> + <code>aws_iam_role_policy</code> + <code>aws_iam_policy_document</code> — to manage the access from Lambda to other resources (e.g., SSM Parameter Store)</li>
<li><code>aws_cloudwatch_log_group</code> — to keep the execution logs</li>
<li><code>aws_ssm_parameter</code> — to store sensitive information (e.g., secrets) and other configurations that we should keep separate from the source code.</li>
</ul>
<p>This Terraform module implements a project-specific use case for Lambda functions. However, if you&rsquo;re seeking for a generic all-in-one module for AWS Lambda, I recommend checking out this one — <a href="https://registry.terraform.io/modules/terraform-aws-modules/lambda/aws/latest">Terraform AWS Lambda Module</a> by Anton Babenko.</p>
<div class="attention">
    <p>To efficiently develop Terraform code for Lambda functions, use the following techniques:</p>
<ul>
<li>Use local values, expressions, and variables to implement consistent naming across different resources logically grouped by a module or project;</li>
<li>Use function environment variables to connect the code with SSM Parameter Store parameters or Secrets Manager secrets to protect sensitive data like tokens or credentials;</li>
<li>Use <code>for_each</code> meta-argument and <code>for</code> expression to reduce the amount of code and automate the configuration for resources of the same type (e.g., <code>ssm_parameter</code>) or code blocks within a resource.</li>
</ul>
</div>
<p>Below is a practical example illustrating these Terraform strategies in action:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span>locals {  
</span></span><span style="display:flex;"><span>  full_function_name = <span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span>var.project_name<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">-</span><span style="color:#a5d6ff">${</span>var.function_name<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_lambda_function&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  function_name = local.full_function_name  
</span></span><span style="display:flex;"><span>  role          = aws_iam_role.this.arn  
</span></span><span style="display:flex;"><span>  architectures = [<span style="color:#a5d6ff">&#34;arm64&#34;</span>]  
</span></span><span style="display:flex;"><span>  filename      = var.deployment_file  
</span></span><span style="display:flex;"><span>  package_type  = <span style="color:#a5d6ff">&#34;Zip&#34;</span>  
</span></span><span style="display:flex;"><span>  runtime       = <span style="color:#a5d6ff">&#34;provided.al2023&#34;</span>  
</span></span><span style="display:flex;"><span>  handler       = <span style="color:#a5d6ff">&#34;bootstrap.handler&#34;</span>  
</span></span><span style="display:flex;"><span>  timeout       = var.function_timeout  
</span></span><span style="display:flex;"><span>  environment {  
</span></span><span style="display:flex;"><span>    variables = { <span style="color:#ff7b72">for</span> item <span style="color:#ff7b72">in</span> var.function_ssm_parameter_names <span style="color:#ff7b72;font-weight:bold">:</span> upper(replace(item, <span style="color:#a5d6ff">&#34;-&#34;</span>, <span style="color:#a5d6ff">&#34;_&#34;</span>)) =&gt; aws_ssm_parameter.function_ssm_parameters[item].name }  
</span></span><span style="display:flex;"><span>  }  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_ssm_parameter&#34;</span> <span style="color:#a5d6ff">&#34;function_ssm_parameters&#34;</span> {  
</span></span><span style="display:flex;"><span>  for_each = var.function_ssm_parameter_names  
</span></span><span style="display:flex;"><span>  name     = <span style="color:#a5d6ff">&#34;/projects/</span><span style="color:#a5d6ff">${</span>var.project_name<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/lambda/</span><span style="color:#a5d6ff">${</span>var.function_name<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/</span><span style="color:#a5d6ff">${</span>each.value<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>  
</span></span><span style="display:flex;"><span>  type     = <span style="color:#a5d6ff">&#34;SecureString&#34;</span>  
</span></span><span style="display:flex;"><span>  key_id   = data.aws_kms_alias.ssm.arn  
</span></span><span style="display:flex;"><span>  value    = <span style="color:#a5d6ff">&#34;1&#34;</span>  
</span></span><span style="display:flex;"><span>  lifecycle {  
</span></span><span style="display:flex;"><span>    ignore_changes = [  
</span></span><span style="display:flex;"><span>      value,  
</span></span><span style="display:flex;"><span>    ]  
</span></span><span style="display:flex;"><span>  }  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_cloudwatch_log_group&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  name              = <span style="color:#a5d6ff">&#34;/aws/lambda/</span><span style="color:#a5d6ff">${</span>local.full_function_name<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>  
</span></span><span style="display:flex;"><span>  log_group_class   = <span style="color:#a5d6ff">&#34;STANDARD&#34;</span>  
</span></span><span style="display:flex;"><span>  retention_in_days = <span style="color:#a5d6ff">7</span>  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><em>The complete terraform module code is available in the <a href="https://github.com/vasylenko/inkyframe/blob/main/infra/modules/lambda/main.tf">project repository</a>.</em></p>
<p>In this Terraform code, I deliberately hardcoded specific arguments for an optimal Lambda runtime configuration, ensuring efficiency and performance.</p>
<p>Then variables and local values, set only once, implement a naming convention for all resource arguments, making it easy to understand the infrastructure and change the naming and attributes later.</p>
<div class="attention">
    Lambda&rsquo;s environment variables and corresponding SSM parameters coexist effectively with the help of <code>for_each</code> and <code>for</code>. I used the <code>for_each</code> meta-argument to dynamically create SSM Parameter resources and the <code>for</code> expression to configure environment variables in AWS Lambda. This also means that if the <code>function_ssm_parameter_names</code> variable value is not provided, then Terraform does not create either SSM parameter resources or the environment code block inside the Lambda resource because the default value of that variable is an empty set.
</div>
<p>By the way, I have another blog post that explains several techniques to enhance your Terraform proficiency — <a href="/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency">check it out</a>!</p>
<h3 id="invoking-lambda-permissions-and-resource-based-policies">Invoking Lambda: Permissions and Resource-Based Policies</h3>
<p>Configured with just a few input variables, the Terraform module efficiently outputs the <code>aws_lambda_function</code> resource. This streamlined output is then adeptly used to facilitate subsequent configurations within the HTTP API.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">module</span> <span style="color:#a5d6ff">&#34;lambda_api_gw_authorizer&#34;</span> {  
</span></span><span style="display:flex;"><span>  source          = <span style="color:#a5d6ff">&#34;./modules/lambda&#34;</span>  
</span></span><span style="display:flex;"><span>  deployment_file = <span style="color:#a5d6ff">&#34;../backend/lambda-apigw-authorizer/deployment.zip&#34;</span>  
</span></span><span style="display:flex;"><span>  function_name   = <span style="color:#a5d6ff">&#34;api-gateway-authorizer&#34;</span>  
</span></span><span style="display:flex;"><span>  project_name    = local.project_name  
</span></span><span style="display:flex;"><span>  function_ssm_parameters = [  
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;authorization-token&#34;</span>  
</span></span><span style="display:flex;"><span>  ]  
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">
</span></span></span><span style="display:flex;"><span><span style="color:#ff7b72">module</span> <span style="color:#a5d6ff">&#34;lambda_calendar_backend&#34;</span> {  
</span></span><span style="display:flex;"><span>  source          = <span style="color:#a5d6ff">&#34;./modules/lambda&#34;</span>  
</span></span><span style="display:flex;"><span>  deployment_file = <span style="color:#a5d6ff">&#34;../backend/lambda-calendar-backend/deployment.zip&#34;</span>  
</span></span><span style="display:flex;"><span>  function_name   = <span style="color:#a5d6ff">&#34;calendar-backend&#34;</span>  
</span></span><span style="display:flex;"><span>  project_name    = local.project_name  
</span></span><span style="display:flex;"><span>  function_ssm_parameters = [  
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;google-api-oauth-token&#34;</span>,  
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;google-api-credentials&#34;</span>  
</span></span><span style="display:flex;"><span>  ]  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As an example of module output usage, here is the configuration of <code>aws_lambda_permissions</code> resource that I use outside the AWS Lambda module to allow the HTTP API service to invoke the function used as Authorizer:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_lambda_permission&#34;</span> <span style="color:#a5d6ff">&#34;allow_api_gw_invoke_authorizer&#34;</span> {  
</span></span><span style="display:flex;"><span>  statement_id  = <span style="color:#a5d6ff">&#34;allowInvokeFromAPIGatewayAuthorizer&#34;</span>  
</span></span><span style="display:flex;"><span>  action        = <span style="color:#a5d6ff">&#34;lambda:InvokeFunction&#34;</span>  
</span></span><span style="display:flex;"><span>  function_name = module.lambda_api_gw_authorizer.lambda.function_name  
</span></span><span style="display:flex;"><span>  principal     = <span style="color:#a5d6ff">&#34;apigateway.amazonaws.com&#34;</span>  
</span></span><span style="display:flex;"><span>  source_arn    = <span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span>aws_apigatewayv2_api.this.execution_arn<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/authorizers/</span><span style="color:#a5d6ff">${</span>aws_apigatewayv2_authorizer.header_based_authorizer.id<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="attention">
    The Lambda resource-based policy combines the trust and permission policies, and provides a simple yet efficient way to grant other AWS services or principals the ability to invoke Lambda functions. It is important to note that for an API to invoke a function, Lambda requires its <strong>execution</strong> ARN, not the resource ARN.
</div>
<p>As a side note, check out this <a href="https://docs.aws.amazon.com/lambda/latest/operatorguide/intro.html">AWS Lambda Operator Guide</a>, which offers specialized advice on developing, securing, and monitoring applications based on AWS Lambda.</p>
<p>Let&rsquo;s switch to the HTTP API part to see how it looks and learn how it integrates Lambda functions.</p>
<h2 id="deep-dive-into-http-api-gateway">Deep Dive into HTTP API Gateway</h2>
<p>Now, we focus on the HTTP API Gateway, delving into its essential concepts, seamless integration with AWS Lambda, and using Terraform efficiently for streamlined configuration.</p>
<p>But before we do that, and since we have partially covered the Terraform code already, I&rsquo;d like to illustrate the logical connection between three main components of the project&rsquo;s Terraform codebase: AWS Lambda, HTTP API, and API Routes.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2024/01/09/mastering-aws-api-gateway-v2-http-and-aws-lambda-with-terraform/terraform-aws-lambda-http-api-integration_hu_8f7095d327b0ed10.webp"
                 alt="AWS Lambda and HTTP API Terraform integration diagram"width="800"height="552.50" />
        
    
    <figcaption>
        <p>AWS Lambda and HTTP API Terraform integration diagram
            </p>
    </figcaption>
</figure>

<p>I will explain the API Route module in detail a bit later, but for now, for the broader context, here is what happens inside Terraform:
AWS HTTP API code logically represents the &ldquo;global&rdquo; (within a project) set of resources and uses the function created by the Lambda Terraform module for the Authorizer configuration. Meanwhile, the API Route Terraform module configures specific routes for the HTTP API (hence, requires some info from it) with integration to back-ends implemented by Lambdas (hence, requires some info from them, too).</p>
<p>Back to HTTP API overview. The following <strong>components of the HTTP API</strong> constitute its backbone:</p>
<ul>
<li><strong>Route</strong> — a combination of the HTTP method (e.g., GET or POST) with the API route (e.g., /meters). For example: &ldquo;POST /meters&rdquo;. Routes can optionally use <strong>Authorizers</strong> — a mechanism to control access to the HTTP API.</li>
<li><strong>Integration</strong> — the technical and logical connection between the Route and one of the supported back-end resources. For example, with AWS Lambda integration, API Gateway sends the entire request as input to a back-end Lambda function and then transforms the Lambda function output to a front-end HTTP response.</li>
<li><strong>Stage and Deployment</strong> — A stage serves as a designated reference to a deployment, essentially capturing a snapshot of the API at a certain point. It&rsquo;s employed to control and optimize a specific deployment version. For instance, stage configurations can be adjusted to tailor request throttling, set up logging, or establish stage variables to be used by API (if needed).</li>
</ul>
<h3 id="implementing-aws-api-gateway-v2-http-api-with-terraform">Implementing AWS API Gateway V2 HTTP API with Terraform</h3>
<p>Below, I detail the Terraform resources essential for implementing the HTTP API, ensuring a transparent and effective setup:</p>
<ul>
<li><code>aws_apigatewayv2_api</code> — the HTTP API itself;</li>
<li><code>aws_apigatewayv2_route</code> — the Route for the API that must specify the integration target (e.g., Lambda) and, optionally, the Authorizer;</li>
<li><code>aws_apigatewayv2_authorizer</code> — the Authorizer to use for Routes;</li>
<li><code>aws_apigatewayv2_integration</code> — the resource that specifies the back-end where the API sends the requests (e.g., AWS Lambda);</li>
<li><code>aws_lambda_permission</code> — the resource-based policy for AWS Lambda to allow the invocations from the API;</li>
<li><code>aws_apigatewayv2_stage</code> — the name of the Stage that references the Deployment.</li>
</ul>
<h3 id="applying-terraform-for-http-api-gateway-and-lambda-authorizer">Applying Terraform for HTTP API Gateway and Lambda Authorizer</h3>
<p>The HTTP API is the simplest in the API Gateway family (so far), so its Terraform resource has relatively few configuration options, most of which can be left at their default values.</p>
<p>As for the Authorizer, it can have two options for letting API know its decision: <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-lambda-authorizer.html#http-api-lambda-authorizer.payload-format-response">simple response and IAM policy</a>.</p>
<p>The <strong>simple response</strong> just returns a Boolean value to indicate whether the API should allow the request (True) or forbid it (False).</p>
<p>The IAM policy option is customizable and allows crafting custom policy statements that allow granular access to explicitly provided resources.</p>
<p>In this project, I follow the way of simplicity and use the &ldquo;simple response&rdquo;, so the response from Lambda Authorizer to HTTP API looks as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;isAuthorized&#34;</span>: <span style="color:#79c0ff">true</span><span style="color:#f85149">/</span><span style="color:#79c0ff">false</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Let&rsquo;s review the HTTP API resource along with the API Authorizer that I used for all routes:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_apigatewayv2_api&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  name          = local.project_name  
</span></span><span style="display:flex;"><span>  protocol_type = <span style="color:#a5d6ff">&#34;HTTP&#34;</span>  
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">
</span></span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_apigatewayv2_authorizer&#34;</span> <span style="color:#a5d6ff">&#34;header_based_authorizer&#34;</span> {  
</span></span><span style="display:flex;"><span>  api_id                            = aws_apigatewayv2_api.this.id  
</span></span><span style="display:flex;"><span>  authorizer_type                   = <span style="color:#a5d6ff">&#34;REQUEST&#34;</span>  
</span></span><span style="display:flex;"><span>  name                              = <span style="color:#a5d6ff">&#34;header-based-authorizer&#34;</span>  
</span></span><span style="display:flex;"><span>  authorizer_payload_format_version = <span style="color:#a5d6ff">&#34;2.0&#34;</span>  
</span></span><span style="display:flex;"><span>  authorizer_uri                    = module.lambda_api_gw_authorizer.lambda.invoke_arn  
</span></span><span style="display:flex;"><span>  enable_simple_responses           = <span style="color:#79c0ff">true</span>  
</span></span><span style="display:flex;"><span>  identity_sources                  = [<span style="color:#a5d6ff">&#34;$request.header.authorization&#34;</span>] 
</span></span><span style="display:flex;"><span>  authorizer_result_ttl_in_seconds  = <span style="color:#a5d6ff">3600</span>  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_lambda_permission&#34;</span> <span style="color:#a5d6ff">&#34;allow_api_gw_invoke_authorizer&#34;</span> {  
</span></span><span style="display:flex;"><span>  statement_id  = <span style="color:#a5d6ff">&#34;allowInvokeFromAPIGatewayAuthorizer&#34;</span>  
</span></span><span style="display:flex;"><span>  action        = <span style="color:#a5d6ff">&#34;lambda:InvokeFunction&#34;</span>  
</span></span><span style="display:flex;"><span>  function_name = module.lambda_api_gw_authorizer.lambda.function_name  
</span></span><span style="display:flex;"><span>  principal     = <span style="color:#a5d6ff">&#34;apigateway.amazonaws.com&#34;</span>  
</span></span><span style="display:flex;"><span>  source_arn    = <span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span>aws_apigatewayv2_api.this.execution_arn<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/authorizers/</span><span style="color:#a5d6ff">${</span>aws_apigatewayv2_authorizer.header_based_authorizer.id<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><em>The complete code is available in the <a href="https://github.com/vasylenko/inkyframe/blob/main/infra/apigateway.tf">project repository</a></em>.</p>
<p>Consider the following key points when Terraforming this part.</p>
<p><code>identity_sources</code> argument of the <code>aws_apigatewayv2_authorizer</code> resource: This is where I defined what exactly the Authorizer should validate. I used the header named <code>authorization</code> so the Authorizer Lambda function would check its value to decide whether to authorize the request.<br>
💡 <em>Check out other options available to use as the identity source — <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-lambda-authorizer.html#http-api-lambda-authorizer.identity-sources">Identity sources</a></em>.</p>
<p><code>authorizer_uri</code> argument of the <code>aws_apigatewayv2_authorizer</code> resource: It is the <strong>invocation</strong> ARN of the Lambda function used as Authorizer (not the Lambda&rsquo;s resource ARN).</p>
<p><code>authorizer_result_ttl_in_seconds</code> argument of the <code>aws_apigatewayv2_authorizer</code> resource: This allows to skip the Authorizer invocation for the given time if a client provided the same identity source values (e.g., authorization header).</p>
<div class="attention">
    AWS API Gateway HTTP can employ the identity sources as the cache key to preserve the authorization results for a while. Should a client provide identical parameters in identity sources within the preset TTL duration, API Gateway will retrieve the result from the cached authorizer instead of calling upon it again. This helps save a lot on AWS Lambda Authorizer invocations and works great with simple scenarios. However, it might be cumbersome if you need severral custom authorization responses per function or if you use custom IAM policies instead of the &ldquo;simple response&rdquo; option.
</div>
<p><code>source_arn</code> argument of <code>aws_lambda_permission</code>: Similar to the <code>authorizer_uri</code> argument, this one expects the <strong>execution</strong> ARN of the HTTP API followed by the Authorizer identifier.</p>
<p>Now, let&rsquo;s see how Routes are codified with Terraform.</p>
<h3 id="applying-terraform-for-http-api-routes">Applying Terraform for HTTP API Routes</h3>
<p>💡 Because an API typically has multiple routes, creating another Terraform module that implements the configurable HTTP API Gateway route is beneficial. Hence, the <code>aws_apigatewayv2_route</code>, <code>aws_apigatewayv2_integration</code>, and <code>aws_lambda_permission</code> resources would constitute such a module.</p>
<p>This Terraform module implements a specific use case for HTTP API Gateway. However, if you&rsquo;re seeking for a generic all-in-one module for API Gateway, I recommend checking out this one — <a href="https://registry.terraform.io/modules/terraform-aws-modules/apigateway-v2/aws/latest">Terraform AWS API Gateway Module</a> by Anton Babenko.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_apigatewayv2_route&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  api_id             = var.api_id  
</span></span><span style="display:flex;"><span>  route_key          = var.route_key  
</span></span><span style="display:flex;"><span>  authorization_type = <span style="color:#a5d6ff">&#34;CUSTOM&#34;</span>  
</span></span><span style="display:flex;"><span>  authorizer_id      = var.authorizer_id  
</span></span><span style="display:flex;"><span>  target             = <span style="color:#a5d6ff">&#34;integrations/</span><span style="color:#a5d6ff">${</span>aws_apigatewayv2_integration.this.id<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_apigatewayv2_integration&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  api_id                 = var.api_id  
</span></span><span style="display:flex;"><span>  integration_type       = <span style="color:#a5d6ff">&#34;AWS_PROXY&#34;</span>  
</span></span><span style="display:flex;"><span>  connection_type        = <span style="color:#a5d6ff">&#34;INTERNET&#34;</span>  
</span></span><span style="display:flex;"><span>  integration_uri        = var.lambda_invocation_arn  
</span></span><span style="display:flex;"><span>  payload_format_version = <span style="color:#a5d6ff">&#34;2.0&#34;</span>  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_lambda_permission&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  statement_id  = <span style="color:#a5d6ff">&#34;allowInvokeFromAPIGatewayRoute&#34;</span>  
</span></span><span style="display:flex;"><span>  action        = <span style="color:#a5d6ff">&#34;lambda:InvokeFunction&#34;</span>  
</span></span><span style="display:flex;"><span>  function_name = var.lambda_function_name  
</span></span><span style="display:flex;"><span>  principal     = <span style="color:#a5d6ff">&#34;apigateway.amazonaws.com&#34;</span>  
</span></span><span style="display:flex;"><span>  source_arn    = <span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span>var.api_gw_execution_arn<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/*/*/*/*&#34;</span>  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>First, I want to highlight several key aspects for understanding the resources&rsquo; arguments within that module.</p>
<p>The <code>target</code> argument of the <code>aws_apigatewayv2_route</code> resource implies that the integration ID should be prefixed with the &ldquo;<code>integrations/</code>&rdquo; keyword.</p>
<p>While the <code>connection_type</code> argument of the <code>aws_apigatewayv2_integration</code> resource specifies &ldquo;INTERNET&rdquo;, it does not mean that the Lambda function must have the publicly available URL. This value must be used unless you work with a VPC endpoint for API Gateway for internal usage.</p>
<p>For the <code>source_arn</code> argument in the <code>aws_lambda_permission</code> resource, similar to earlier, it requires the <strong>execution</strong> ARN of the API. However, this time, it is the integration of the HTTP API Route with Lambda. And the ARN format of this one is different and a bit tricky:</p>
<p><code>arn:partition:execute-api:region:account-id:api-id/stage/http-method/resource-path</code></p>
<p>The <code>arn:partition:execute-api:region:account-id:api-id</code> part constitutes the execution ARN of the HTTP API itself, so for the sake of simplicity, I decided to go with wildcards after it.<br>
<em>For your convenience, here is the <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/arn-format-reference.html">detailed specification</a> of API Gateway ARNs.</em></p>
<p>The HTTP API Route module expects several input variables:</p>
<ul>
<li><code>authorizer_id</code> — the identifier of the Authorizer to use on this route;</li>
<li><code>route_key</code> — the route key for the route, e.g., <code>GET /foo/bar</code>;</li>
<li><code>api_id</code> — the identifier of HTTP API created earlier;</li>
<li><code>lambda_invocation_arn</code> — the Invocation ARN of the Lambda function;</li>
<li><code>lambda_function_name</code> — the name of the Lambda function to integrate with the route;</li>
<li><code>api_gw_execution_arn</code> — the Execution ARN of the HTTP API that invokes a Lambda function.</li>
</ul>
<p>Let&rsquo;s take a closer look on API Gateway V2 HTTP API route.</p>
<p>A route consists of an HTTP method and a resource path with an optional variable. Based on the pre-defined convention, it uses a simplified routing configuration and methods request model (comparable to other APIs).</p>
<div class="attention">
    <p>While I was working with the HTTP API, I found this simplified approach to be great because it allows easy access to the request context from AWS Lambda functions, for example:</p>
<ul>
<li>A path variable in a route, e.g., <code>GET /calendars/{calendar-name}</code>, would be available for the integrated AWS Lambda by its name inside the pathParameter JSON field, e.g.,  <code>pathParamters.calendar-name</code>, of the event object sent by API to Lambda. In other words, you do not need to explicitly set the mapping between the path variable and its representation to the back-end.</li>
<li>A request query string is parsed into separate parameter-value pairs and available in the <code>queryStringParameters</code> field of the event object sent by API to Lambda. Again, without the explicit mapping configuration.</li>
</ul>
</div>
<p>Here, you can read more about the Route specification of HTTP API and how to transform requests and responses from the API side if you need to adjust something:</p>
<ul>
<li><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-routes.html">Working with routes for HTTP APIs</a></li>
<li><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-parameter-mapping.html">Transforming API requests and responses</a></li>
</ul>
<p>Now back to Terraform. Below is the code snippet that illustrates the call of the API Route Terraform module:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">module</span> <span style="color:#a5d6ff">&#34;route_calendars&#34;</span> {  
</span></span><span style="display:flex;"><span>  source                = <span style="color:#a5d6ff">&#34;./modules/api-gateway-route&#34;</span>  
</span></span><span style="display:flex;"><span>  api_id                = aws_apigatewayv2_api.this.id  
</span></span><span style="display:flex;"><span>  route_key             = <span style="color:#a5d6ff">&#34;GET /calendars/{calendar-name}&#34;</span>  
</span></span><span style="display:flex;"><span>  api_gw_execution_arn  = aws_apigatewayv2_api.this.execution_arn  
</span></span><span style="display:flex;"><span>  lambda_invocation_arn = module.lambda_calendar_backend.lambda.invoke_arn  
</span></span><span style="display:flex;"><span>  lambda_function_name  = module.lambda_calendar_backend.lambda.function_name  
</span></span><span style="display:flex;"><span>  authorizer_id         = aws_apigatewayv2_authorizer.header_based_authorizer.id  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This module logically relies on both the HTTP API and Lambda resources to configure their integration by implementing the Route.</p>
<h2 id="enhancing-security-and-monitoring-of-aws-api-gateway-v2-http-api">Enhancing Security and Monitoring of AWS API Gateway V2 HTTP API</h2>
<p>Several additional options are available to monitor and protect the HTTP API: logs, metrics, and throttling.</p>
<h3 id="overview-of-http-api-monitoring-and-protection-options">Overview of HTTP API monitoring and protection options</h3>
<p>Logging, metrics, and throttling are configured on the Stage level but allow configuration granularity for the Routes.</p>
<p>For logs, you can configure the CloudWatch log group, the log format (JSON, CLF, XML, CSV), and content filters. The <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-logging-variables.html">logging variables</a> allow you to customize the information that appears in logs. I will provide an example of such a configuration later in the article.</p>
<p>By default, API Gateway sends only API and stage-level metrics to CloudWatch in one-minute periods. However, you can enable <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-metrics.html">detailed metrics</a> and additionally collect the per-route metrics.</p>
<p>To safeguard your HTTP API from excessive requests, you can employ throttling settings, which allow you to set limits per individual route as well as for all routes collectively.</p>
<h3 id="configuring-monitoring-and-protection-for-http-api-with-terraform">Configuring monitoring and protection for HTTP API with Terraform</h3>
<p>Now, let&rsquo;s see how Terraform helps configure the protection and monitoring for HTTP API.</p>
<p>As mentioned earlier, API Gateway applies these configurations at the Stage level, which is why the aws_apigatewayv2_stage resource encapsulates them all.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_apigatewayv2_stage&#34;</span> <span style="color:#a5d6ff">&#34;default&#34;</span> {  
</span></span><span style="display:flex;"><span>  api_id      = aws_apigatewayv2_api.this.id  
</span></span><span style="display:flex;"><span>  name        = <span style="color:#a5d6ff">&#34;$default&#34;</span>  
</span></span><span style="display:flex;"><span>  auto_deploy = <span style="color:#79c0ff">true</span>  
</span></span><span style="display:flex;"><span>  description = <span style="color:#a5d6ff">&#34;Default stage (i.e., Production mode)&#34;</span>  
</span></span><span style="display:flex;"><span>  default_route_settings {  
</span></span><span style="display:flex;"><span>    throttling_burst_limit = <span style="color:#a5d6ff">1</span>  
</span></span><span style="display:flex;"><span>    throttling_rate_limit  = <span style="color:#a5d6ff">1</span>  
</span></span><span style="display:flex;"><span>  }  
</span></span><span style="display:flex;"><span>  access_log_settings {  
</span></span><span style="display:flex;"><span>    destination_arn = aws_cloudwatch_log_group.api_gateway_logs_inkyframe.arn  
</span></span><span style="display:flex;"><span>    format = jsonencode({  
</span></span><span style="display:flex;"><span>      authorizerError           = <span style="color:#a5d6ff">&#34;$context.authorizer.error&#34;</span>,  
</span></span><span style="display:flex;"><span>      identitySourceIP          = <span style="color:#a5d6ff">&#34;$context.identity.sourceIp&#34;</span>,  
</span></span><span style="display:flex;"><span>      integrationError          = <span style="color:#a5d6ff">&#34;$context.integration.error&#34;</span>,  
</span></span><span style="display:flex;"><span>      integrationErrorMessage   = <span style="color:#a5d6ff">&#34;$context.integration.errorMessage&#34;</span>  
</span></span><span style="display:flex;"><span>      integrationLatency        = <span style="color:#a5d6ff">&#34;$context.integration.latency&#34;</span>,  
</span></span><span style="display:flex;"><span>      integrationRequestId      = <span style="color:#a5d6ff">&#34;$context.integration.requestId&#34;</span>,  
</span></span><span style="display:flex;"><span>      integrationStatus         = <span style="color:#a5d6ff">&#34;$context.integration.integrationStatus&#34;</span>,  
</span></span><span style="display:flex;"><span>      integrationStatusCode     = <span style="color:#a5d6ff">&#34;$context.integration.status&#34;</span>,  
</span></span><span style="display:flex;"><span>      requestErrorMessage       = <span style="color:#a5d6ff">&#34;$context.error.message&#34;</span>,  
</span></span><span style="display:flex;"><span>      requestErrorMessageString = <span style="color:#a5d6ff">&#34;$context.error.messageString&#34;</span>,  
</span></span><span style="display:flex;"><span>      requestId                 = <span style="color:#a5d6ff">&#34;$context.requestId&#34;</span>,  
</span></span><span style="display:flex;"><span>      routeKey                  = <span style="color:#a5d6ff">&#34;$context.routeKey&#34;</span>,  
</span></span><span style="display:flex;"><span>    })   
</span></span><span style="display:flex;"><span>  }  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Here, I applied the default <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-throttling.html">throttling settings</a>: for my project, 1 request per second was enough at that point.</p>
<p>🤔 There is a nuance, though, that makes Terraforming API Gateway a little inconvenient — the IAM role that allows API to write logs must be defined on a region level. Therefore, if you maintain several Terraform projects for the same AWS account, you might need to have the following configuration stand separately to avoid conflicts or misunderstandings:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_api_gateway_account&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {  
</span></span><span style="display:flex;"><span>  cloudwatch_role_arn = aws_iam_role.api_gateway_cloudwatch_logs.arn  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_iam_role&#34;</span> <span style="color:#a5d6ff">&#34;api_gateway_cloudwatch_logs&#34;</span> {  
</span></span><span style="display:flex;"><span>  name = <span style="color:#a5d6ff">&#34;api-gateway-cloudwatch-logs&#34;</span>  
</span></span><span style="display:flex;"><span>  assume_role_policy = jsonencode({  
</span></span><span style="display:flex;"><span>    Version = <span style="color:#a5d6ff">&#34;2012-10-17&#34;</span>  
</span></span><span style="display:flex;"><span>    Statement = [  
</span></span><span style="display:flex;"><span>      {  
</span></span><span style="display:flex;"><span>        Effect = <span style="color:#a5d6ff">&#34;Allow&#34;</span>  
</span></span><span style="display:flex;"><span>        Principal = {  
</span></span><span style="display:flex;"><span>          Service = <span style="color:#a5d6ff">&#34;apigateway.amazonaws.com&#34;</span>  
</span></span><span style="display:flex;"><span>        }  
</span></span><span style="display:flex;"><span>        Action = <span style="color:#a5d6ff">&#34;sts:AssumeRole&#34;</span>  
</span></span><span style="display:flex;"><span>      }  
</span></span><span style="display:flex;"><span>    ]  
</span></span><span style="display:flex;"><span>  })  
</span></span><span style="display:flex;"><span>  managed_policy_arns = [<span style="color:#a5d6ff">&#34;arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs&#34;</span>]  
</span></span><span style="display:flex;"><span>}  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_cloudwatch_log_group&#34;</span> <span style="color:#a5d6ff">&#34;api_gateway_logs_inkyframe&#34;</span> {  
</span></span><span style="display:flex;"><span>  name              = <span style="color:#a5d6ff">&#34;/aws/apigateway/inkyframe&#34;</span>  
</span></span><span style="display:flex;"><span>  log_group_class   = <span style="color:#a5d6ff">&#34;STANDARD&#34;</span>  
</span></span><span style="display:flex;"><span>  retention_in_days = <span style="color:#a5d6ff">7</span>  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And one more thing about HTTP API deployments and stages. I use the special <code>$default</code> keyword to have a single stage (hence, the default one), and I also used automatic deployments: with any change made to API configuration, AWS will automatically generate a new Deployment and bound it with the Stage. If you prefer controlling deployments manually, there is a special resource exists that implements this — <code>aws_apigatewayv2_deployment</code></p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_apigatewayv2_deployment&#34;</span> <span style="color:#a5d6ff">&#34;example&#34;</span> {
</span></span><span style="display:flex;"><span>  api_id      = aws_apigatewayv2_api.example.id
</span></span><span style="display:flex;"><span>  description = <span style="color:#a5d6ff">&#34;Example deployment&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  triggers = {
</span></span><span style="display:flex;"><span>    redeployment = sha1(join(<span style="color:#a5d6ff">&#34;,&#34;</span>, tolist([
</span></span><span style="display:flex;"><span>      jsonencode(aws_apigatewayv2_integration.example),
</span></span><span style="display:flex;"><span>      jsonencode(aws_apigatewayv2_route.example),
</span></span><span style="display:flex;"><span>    ])))
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  lifecycle {
</span></span><span style="display:flex;"><span>    create_before_destroy = <span style="color:#79c0ff">true</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>In that case, the <code>aws_apigatewayv2_stage</code> resource requires the <code>deployment_id</code> argument to link itself with a particular Deployment and, therefore, represent the state of the API configuration.</p>
<p>Also, API Gateway requires at least one configured API Route before the deployment is initiated/created. However, these resources do not explicitly depend on each other via attribute references. To avoid the race condition in Terraform, you need to reference the Route resource in the <code>aws_apigatewayv2_deployment</code> resource via the <code>triggers</code> argument (as shown above) or via the <code>depends_on</code> meta-argument. Otherwise, Terraform will try to apply changes to both resources simultaneously.</p>
<h2 id="afterword-simplifying-serverless-architectures">Afterword: Simplifying Serverless Architectures</h2>
<p>In wrapping up our exploration of AWS HTTP API Gateway, AWS Lambda, and Terraform, we&rsquo;ve delved into how these powerful tools work in tandem to streamline and enhance serverless architectures. This article aimed to combine my experience with new knowledge and demystify the complexities of used services, showcasing their capabilities in creating efficient, cost-effective solutions for modern cloud-based applications.</p>
<p>We focused on practical implementation and the tangible benefits of combining these technologies. By leveraging Terraform, we&rsquo;ve seen how infrastructure management can be simplified, allowing for clearer, more maintainable code. The combination of AWS Lambda and HTTP API Gateway has demonstrated the efficiency of serverless computing, offering scalability and performance without the burden of extensive configuration and management.</p>
<p>This exploration underlines the importance of choosing the right tools and strategies in cloud computing. It reminds developers and architects that creating robust and efficient serverless systems is within reach with a thoughtful approach and the right set of tools. As the cloud landscape continues to evolve, staying informed and adaptable is key to harnessing the full potential of these technologies. 💚</p>
]]></content:encoded>
    </item>
    <item>
      <title>Hello Terraform Data; Goodbye Null Resource</title>
      <link>https://devdosvid.blog/2023/04/16/hello-terraform-data-goodbye-null-resource/</link>
      <pubDate>Sun, 16 Apr 2023 01:25:18 +0200</pubDate>
      <guid>https://devdosvid.blog/2023/04/16/hello-terraform-data-goodbye-null-resource/</guid>
      <description>Native built-in replacement for null_resource with Terraform 1.4</description>
      <content:encoded><![CDATA[<p>Terraform version 1.4 was recently released and brought a range of new features, including improved run output in Terraform Cloud, the ability to use OPA policy results in the CLI, and a built-in alternative to the null resource — terraform_data.</p>
<p>In this blog post, I want to demonstrate and explain the <strong>terraform_data</strong> resource that serves two purposes:</p>
<ul>
<li>firstly, it allows arbitrary values to be stored and used afterward to implement lifecycle triggers of other resources</li>
<li>secondly, it can be used to trigger provisioners when there isn&rsquo;t a more appropriate managed resource available.</li>
</ul>
<div class="beehiiv-subscribe-container">
    <h3>Subscribe to blog updates!</h3>
    <iframe src="https://embeds.beehiiv.com/60009a3f-3202-4ac0-85f8-0d3db1ea781b?slim=true" data-test-id="beehiiv-embed"
        height="52" frameborder="0" scrolling="no"
        style="margin: 0; border-radius: 0px !important; background-color: transparent;"></iframe>
</div>
<p>For those of you, who are familiar with the null provider, the <code>terraform_data</code> resource might look very similar. And you&rsquo;re right!<br>
Rather than being a separate provider, the terraform_data managed resource now offers the same capabilities as an integrated feature. Pretty cool! <br>
While the null provider is still available and there are no statements about its deprecation thus far (<a href="https://registry.terraform.io/providers/hashicorp/null/3.2.1/docs">as of April 2023, v3.2.1</a>), the  <code>terraform_data</code> is the native replacement of the <code>null_resource</code>, and the latter might soon become deprecated.</p>
<p>The  <code>terraform_data</code> resource has two optional arguments, <strong>input</strong> and <strong>triggers_replace</strong>, and its configuration looks as follows:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2023/04/16/hello-terraform-data-goodbye-null-resource/code-snippet-1_hu_806b63ec76a5080d.webp"
                 alt="terraform data resource arguments"width="800"height="182.16" />
        
    
    <figcaption>
        <p>terraform data resource arguments
            </p>
    </figcaption>
</figure>

<ul>
<li>The <code>input</code> (optional) stores the value that is passed to the resource</li>
<li>The <code>triggers_replace</code> (optional) is a value that triggers resource replacement when changes.</li>
</ul>
<p>There are two attributes, in addition to the arguments, which are stored in the state: <strong>id</strong> and <strong>output</strong> after the resource is created. Let&rsquo;s take a look:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2023/04/16/hello-terraform-data-goodbye-null-resource/code-snippet-2_hu_1efde4882f03327c.webp"
                 alt="terraform data resource attributes"width="800"height="271.36" />
        
    
    <figcaption>
        <p>terraform data resource attributes
            </p>
    </figcaption>
</figure>

<ul>
<li>The  <code>output</code> attribute is computed based on the value of the <code>input</code></li>
<li>The <code>id</code> is just a unique value of the resource instance in the state (as for any other resource).</li>
</ul>
<h2 id="use-case-for-terraform_data-with-replace_triggered_by">Use case for terraform_data with replace_triggered_by</h2>
<p>Let&rsquo;s take a look at the first use case for the terraform_data resource. It is the ability to trigger resource replacement based on the value of the input argument.</p>
<p>A bit of context here: the <strong>replace_triggered_by</strong> argument of the resource lifecycle meta-argument allows you to trigger resource replacement based on another referenced resource or its attribute.</p>
<div class="attention">
    If you are not yet familiar with the <code>replace_triggered_by</code>, you can check <a href="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/#trigger-resource-replacement-with-replace_triggered_by">another blog post that explains it</a>.
</div>
<p>The replace_triggered_by is a powerful feature, but here is the thing about it: only a resource or its attribute must be specified, and <strong>you cannot use a variable or a local value for replace_triggered_by</strong>.</p>
<p>But with terraform_data, you can indirectly initiate another resource replacement by using either a variable or an expression within a local value for the <code>input</code> argument.</p>
<p>Let me give you an example here. Consider the following code:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2023/04/16/hello-terraform-data-goodbye-null-resource/code-snippet-3_hu_dd3f94068f7e92dd.webp"
                 alt="trigger replacement based on input variable"width="800"height="386.00" />
        
    
    <figcaption>
        <p>trigger replacement based on input variable
            </p>
    </figcaption>
</figure>

<p>By modifying the  <code>revision</code> variable, the next Terraform plan will suggest a replacement action against aws_instance.webserver:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2023/04/16/hello-terraform-data-goodbye-null-resource/code-snippet-4_hu_42432796ae5d8ebe.webp"
                 alt="terraform_data with replace_triggered_by"width="800"height="341.59" />
        
    
    <figcaption>
        <p>terraform_data with replace_triggered_by
            </p>
    </figcaption>
</figure>

<h2 id="use-case-for-terraform_data-with-provisioner">Use case for terraform_data with provisioner</h2>
<p>Before we start: HashiCorp suggests (and I also support that) avoiding provisioner usage unless you have no other options left. One of the reasons — additional, implicit, and unobvious dependency that appears in the codebase — the binary, which is called inside the provisioner block, must be present on the machine. <br>
But let&rsquo;s be real, the provisioner feature is still kicking, and there&rsquo;s always that one unique project that needs it.</p>
<p>Here is the code snippet that demonstrates the usage of the provisioner within the terraform_data resource:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2023/04/16/hello-terraform-data-goodbye-null-resource/code-snippet-5_hu_6590af059b34b4c5.webp"
                 alt="terraform_data with provisioner"width="800"height="409.00" />
        
    
    <figcaption>
        <p>terraform_data with provisioner
            </p>
    </figcaption>
</figure>

<p>In this example, the following happens:</p>
<ul>
<li>When resources are created the first time, the provisioner inside <code>terraform_data</code> runs</li>
<li>Sequential plan/apply will trigger another execution of the provisioner only when the private IP of the instance (aws_instance.webserver.private_ip) changes because that will trigger <code>terraform_data</code> recreation. At the same time, no changes to the internal IP mean no provisioner execution.</li>
</ul>
<hr>
<p>With its ability to store and use values for lifecycle triggers and provisioners, <strong>terraform_data</strong> is a powerful tool that can enhance your Terraform configuration.</p>
<p>Although the null provider still has its place in the Terraform ecosystem, terraform_data is its evolution, and its integration as a feature is certainly something to be excited about.</p>
<p>Why not give it a try in your next project and see how it can simplify your infrastructure as code workflows? Keep on coding! 🙌</p>
]]></content:encoded>
    </item>
    <item>
      <title>Five Practical Ways To Get The Verified EC2 AMI</title>
      <link>https://devdosvid.blog/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/</link>
      <pubDate>Sun, 24 Jul 2022 15:21:05 +0200</pubDate>
      <guid>https://devdosvid.blog/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/</guid>
      <description>How to find the AMI you cat trust among thousands available in AWS</description>
      <content:encoded><![CDATA[<p>EC2 AMI catalog consists of more than 160k public AMIs — a mix of shared AMIs created by users, published by vendors, and provided by AWS.</p>
<p>So how to ensure that an AMI comes from the verified vendor or that is an official AMI published by AWS?</p>
<p>How to find the trusted AMI among them all when you&rsquo;re about to launch an EC2 Instance?</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/who-is-ami-owner_hu_dc5ad19a324177d8.webp"
                 alt="Find the Waldo verified AMI owner"width="800"height="400.00" />
        
    
    <figcaption>
        <p>Find the <del>Waldo</del> verified AMI owner
            </p>
    </figcaption>
</figure>

<p>On AWS, it&rsquo;s typical that something can be made or done in several ways — that&rsquo;s awesome. Some of them work better than others, some methods are official, and some you can use just for fun (<a href="https://www.lastweekinaws.com/blog/the-17-ways-to-run-containers-on-aws/">check</a> <a href="https://www.lastweekinaws.com/blog/17-more-ways-to-run-containers-on-aws/">that</a>).</p>
<p>In this article, I will describe five ways of getting the official and verified AMI for your next EC2 Instance launch.</p>
<h2 id="use-ec2-launch-wizard-and-ami-catalog-to-get-the-official-ami">Use EC2 Launch Wizard and AMI Catalog to get the official AMI</h2>
<p>When launching an EC2 Instance from a Management Console, you can apply the &ldquo;Verified Provider&rdquo; filter for the Community AMIs tab to ensure you get an AMI from a verified provider. The &ldquo;Verified provider&rdquo; label means an AMI is owned by an Amazon verified account.</p>
<p>In the following example, I want to make sure that the Ubuntu 20.04 AMI comes from the verified source:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/verified-ami-in-ami-catalog_hu_64e5f9af9a1aedbe.webp"
                 alt="Verified AMI in the AMI Catalog"width="800"height="413.65" />
        
    
    <figcaption>
        <p>Verified AMI in the AMI Catalog
            </p>
    </figcaption>
</figure>

<p>In the past, you had to compare the AMI Owner ID with the publicly shared list of verified Owner IDs for every region. Not rocket science, but it takes time. So now it&rsquo;s much more straightforward, thanks to the &ldquo;Verified Provider&rdquo; label.</p>
<p>This feature also works great when you are creating a Launch Template. The Launch Template creation wizard seamlessly guides you from itself to the AMI Catalog (where you can search and pick the AMI) and back again.</p>
<h2 id="look-for-verified-amis-on-the-ami-page">Look for verified AMIs on the AMI page</h2>
<p>Another interface in the Management Console acts as the AMI browser. It does not have any fancy name except for the &ldquo;AMIs page&rdquo;, but you probably already know about it: it looks like a list of AMIs, and you can see it when you click on the &ldquo;AMIs&rdquo; menu item on the left side of the EC2 page menu.</p>
<p>The AMI page allows you to leverage the API filters to narrow down the search, and the &ldquo;Owner alias&rdquo; filter is the one you need to ensure that an AMI comes from a trusted owner.</p>
<p>Here is how it looks for my search of the official Amazon Linux 2 AMI:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/verified-amazon-linux-2-ami-in-ami-browser-ec2-console_hu_54f45a0d3c1b79b6.webp"
                 alt="Official Amazon Linux 2 AMI"width="800"height="400.00" />
        
    
    <figcaption>
        <p>Official Amazon Linux 2 AMI
            </p>
    </figcaption>
</figure>

<p>AMIs shared by verified sources have <code>amazon</code> (for AWS) or <code>aws-marketplace</code> (for AWS partners) as the value for the Owner alias filter.</p>
<h2 id="find-the-ec2-ami-with-terraform">Find the EC2 AMI with Terraform</h2>
<p>Finding the official AMI with Terraform is also simple — the <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ami">aws_ami data source</a> does the job.</p>
<p>For example, here is how you can find the same Amazon Linux 2 AMI by specifying the <code>amazon</code> as the value for the <code>owner</code> argument of the data source:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/verified-official-amazon-linux-2-ami-terraform-datasource_hu_6774d3b845821711.webp"
                 alt="Finding the official Amazon Linux 2 AMI with Terraform"width="800"height="580.24" />
        
    
    <figcaption>
        <p>Finding the official Amazon Linux 2 AMI with Terraform
            </p>
    </figcaption>
</figure>

<p>Compare that with the filters on the AMI page — it looks similar, right? This is because of how Terraform works: it translates your code into API calls and sends them to AWS API endpoints.</p>
<p>If you&rsquo;re very new to Terraform, I suggest reading this article to understand the basic concepts of Terraform and Infrastructure as Code: <a href="https://devdosvid.blog/2020/05/02/terraform-explained-in-english/">Terraform explained in English</a></p>
<h2 id="find-the-official-aws-ami-using-describe-images-cli">Find the official AWS AMI using Describe Images CLI</h2>
<p>Sometimes you might need to get the AMI from CLI to pass it along as an argument downstream of the pipeline.</p>
<p>This can be done with the <strong>ec2 describe-images</strong> command of the AWS CLI
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/verified-official-amazon-linux-2-ami-in-aws-cli_hu_6401c7369239a157.webp"
                 alt="Find the verified AMI with AWS CLI"width="800"height="486.75" />
        
    
    <figcaption>
        <p>Find the verified AMI with AWS CLI
            </p>
    </figcaption>
</figure>
</p>
<p>The API filters I mentioned before also work here — use them to narrow your search.</p>
<h2 id="find-the-trusted-aws-ami-with-ssm">Find the trusted AWS AMI with SSM</h2>
<p>Another way that involves AWS CLI is the <strong>ssm get-parameter</strong> command:
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/07/24/five-practical-ways-to-get-the-verified-ec2-ami/verified-official-amazon-eks-optimized-ami-aws-cli_hu_813043eab0171df6.webp"
                 alt="Get the latest EKS optimized AMI from SSM"width="800"height="213.69" />
        
    
    <figcaption>
        <p>Get the latest EKS optimized AMI from SSM
            </p>
    </figcaption>
</figure>
</p>
<p>It reveals one helpful feature of the Systems Manager — the Public parameters.</p>
<p>Systems Manager Public parameters are how AWS distributes some widely used artifacts related to their services.</p>
<p>For example, you can find official AMIs for many distributives there: Amazon Linux, Windows, macOS, Bottlerocket, Ubuntu, Debian, and FreeBSD.</p>
<p>Read more at the <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-finding-public-parameters.html">Finding public parameters</a> documentation page if you want to know more.</p>
<h2 id="are-all-verified-amis-good">Are all verified AMIs good?</h2>
<p>The &ldquo;Verified provider&rdquo; badge can be earned by a third party only when an AMI developer is registered as a Seller on the AWS Marketplace.</p>
<p>Becoming a Seller there is not trivial and requires some <a href="https://docs.aws.amazon.com/marketplace/latest/userguide/user-guide-for-sellers.html#seller-requirements-for-publishing-free-products">conditions</a> to be met, and the <a href="https://docs.aws.amazon.com/marketplace/latest/userguide/seller-registration-process.html">registration process</a> itself also implies submitting the tax and banking information.</p>
<p>Additionally, there are <a href="https://docs.aws.amazon.com/marketplace/latest/userguide/product-and-ami-policies.html">specific policies and review processes</a> apply to all AMIs submitted to the Marketplace.</p>
<p>So it is okay to trust the third-party vendors with the &ldquo;Verified&rdquo; badge on a certain level. However, it is also always good to have additional scans and validation of the software you use. 🪲 😉</p>
]]></content:encoded>
    </item>
    <item>
      <title>Golden Image Pipelines With HCP Packer</title>
      <link>https://devdosvid.blog/2022/06/26/golden-image-pipelines-with-hcp-packer/</link>
      <pubDate>Sun, 26 Jun 2022 15:13:12 +0200</pubDate>
      <guid>https://devdosvid.blog/2022/06/26/golden-image-pipelines-with-hcp-packer/</guid>
      <description>How to create an end-to-end golden image workflow with the HCP Packer image registry</description>
      <content:encoded><![CDATA[<p>Many of us know and use Packer to build golden images for cloud providers. But did you know that Packer is not just a CLI tool?</p>
<p>There is an HCP (<em>stands for <strong>H</strong>ashiCorp <strong>C</strong>loud <strong>P</strong>latform</em>) Packer that acts as the image registry that stores the image metadata, allows you to organize images in distribution channels, and perform other management actions.</p>
<p>In this blog, I would like to showcase some features of the HCP Packer and explain how you can use it to set up an image factory for the organization (or for your own fun 🙃) to maintain the Golden Images.</p>
<p>I will be using AWS AMI as the OS image appliance for examples in this blog, but Packer supports many other formats and clouds through its <a href="https://www.packer.io/plugins">plugins</a>.</p>
<h2 id="hcp-packer-registry">HCP Packer Registry</h2>
<p>HCP Packer is the image metadata registry that stores the information (not an image file) about OS images you create using the Packer CLI tool.</p>
<p>It solves the challenge of the Golden Image pipeline maintenance by acting as a hub that organizes and streamlines the processes of OS image creation, usage, and continuity.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/hcp-packer-how-it-works_hu_1cd5f51dfd010a7f.webp"
                 alt="OS Image lifecycle with HCP Packer"width="800"height="400" />
        
    
    <figcaption>
        <p>OS Image lifecycle with HCP Packer
            </p>
    </figcaption>
</figure>

<p>HCP Packer introduces several new concepts that compose the registry: Image Buckets, Iterations, and Channels. Further in this blog, I will explain them, but let&rsquo;s start with security first.</p>
<h2 id="security-first--creating-service-principals">Security First — Creating Service Principals</h2>
<p>Before launching the builds, you need to create a Service Principal to allow your local Packer CLI to communicate with the HCP.</p>
<p>I recommend creating at least two principals: the one with the &ldquo;contributor&rdquo; role — used by Packer CLI to store the image metadata in HCP; and another one with the &ldquo;viewer&rdquo; role — used by Terraform (as it requires only read-level access for Packer HCP).</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/hcp-packer-service-principals_hu_62f05120dd22409f.webp"
                 alt="Service Principals for HCP"width="800"height="237.88" />
        
    
    <figcaption>
        <p>Service Principals for HCP
            </p>
    </figcaption>
</figure>

<p>Once you have created a principal, you can generate a key for authentication. The key consists of an ID and a secret.</p>
<div class="attention">
    <p>Both the Packer CLI and the Packer Terraform provider support environment variables for the principal client ID and client secret for authentication:</p>
<p><code>HCP_CLIENT_ID</code> and <code>HCP_CLIENT_SECRET</code></p>

</div>
<h2 id="image-buckets-to-store-image-metadata">Image Buckets to Store Image Metadata</h2>
<p>The central entity in HCP Packer is the Image Buckets.</p>
<p><strong>Image Bucket</strong> is a repository where the metadata from a Packer template is stored once image(s) creation is completed.</p>
<p>Image Bucket can contain a single image or several images if you define several sources for the <code>build</code> block in the Packet template.</p>
<p>For example, a bucket can span several custom AMIs based on Ubuntu AMI provided by Amazon and built and distributed within several regions.</p>
<p>You cannot create buckets manually from the web interface (at least as of June 2022), but I will show you how they are defined as code inside a Packer template file just a bit later.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/image-buckets_hu_20a0ff5c89d190c9.webp"
                 alt="HCP Packer Image Buckets"width="800"height="278.87" />
        
    
    <figcaption>
        <p>HCP Packer Image Buckets
            </p>
    </figcaption>
</figure>

<h2 id="iterations-of-image-creation">Iterations of Image Creation</h2>
<p>Every execution of the  <code>build</code> action made by Packer CLI (if used in conjunction with HCP) is recorded specially and called <strong>Iteration</strong>.</p>
<p>Each Iteration has a unique fingerprint — an SHA value of the head reference in the Git repository that contains your Packer template.</p>
<div class="attention">
    Tip: you can override that with the <code>HCP_PACKER_BUILD_FINGERPRINT</code> env variable if you want to set the Iteration ID manually.
</div>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/packer-iterations_hu_e22ab709d54ce86b.webp"
                 alt="HCP Packer Iterations"width="800"height="278.87" />
        
    
    <figcaption>
        <p>HCP Packer Iterations
            </p>
    </figcaption>
</figure>

<p>Every Iteration consists of at least one Build — another special record that contains image metadata produced by Packer CLI.</p>
<p>The Builds inside Iteration are represented by the number of sources specified in your Packer template&rsquo;s <code>build</code>  section.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/packer-iteration-builds_hu_8880a34533eaaa00.webp"
                 alt="HCP Packer Iteration Builds"width="800"height="574.57" />
        
    
    <figcaption>
        <p>HCP Packer Iteration Builds
            </p>
    </figcaption>
</figure>

<h2 id="packer-template-configuration-for-hcp">Packer Template Configuration for HCP</h2>
<p>Let&rsquo;s now review a code example to understand how all this combines.</p>
<p>Here is a <code>build</code> block from Packer template file.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/packer-template-example_hu_7e314e0bc97f6173.webp"
                 alt="HCP Packer registry usage in a Packer template"width="800"height="554.00" />
        
    
    <figcaption>
        <p>HCP Packer registry usage in a Packer template
            </p>
    </figcaption>
</figure>

<p>Look at the <code>hcp_packer_registry</code> block: it defines the Bucket where Packer will store image information and custom labels for the Bucket and the image.</p>
<p>The <code>bucket_name</code> defines my Image Bucket: Packer will either use the existing Bucket with that name or create a new one if it does not exist.</p>
<p>The <code>bucket_labels</code> map defines custom labels you specify for an Image Bucket. In my example, I set the Bucket owner and the OS name.</p>
<p>The <code>build_labels</code> map defines custom labels for the Builds within the Iteration inside a bucket.</p>
<p>And because I define two <code>sources</code> here, my Iteration will have two Builds inside it.</p>
<h2 id="using-channels">Using Channels</h2>
<p>Although all Iterations have unique identifiers, giving a familiar name to some of them would be more convenient.</p>
<p><strong>Channel</strong> is a way to assign a specific Iteration to a friendly name that you can use later:</p>
<ul>
<li>in other Packer templates, if you want to use your custom image as the base for other images</li>
<li>in Terraform code (we will review this further) to reference the image by the channel name, avoiding the hard code of the image ID.</li>
</ul>
<p>Channels are created through the web interface or using the API. And I hope HashiCorp will add HCP Packer resources to the HCP Terraform provider in the future so channel creation can be described as code.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/hcp-packer-image-channel_hu_bf77fa8f190e358b.webp"
                 alt="HCP Packer Image Channel"width="800"height="338.15" />
        
    
    <figcaption>
        <p>HCP Packer Image Channel
            </p>
    </figcaption>
</figure>

<p>You can manually promote an Iteration to a channel with a web interface.</p>
<p>But before promoting an Iteration to a channel, you might want to perform the following:</p>
<ul>
<li>
<p>test and validate the newly created image before its promotion to a channel: create a temporary virtual machine using Terraform and ensure it successfully boots from the image.</p>
</li>
<li>
<p>assess that VM with some vulnerability scanning service. For example, if you&rsquo;re an AWS customer, then <a href="https://docs.aws.amazon.com/inspector/latest/user/what-is-inspector.html">Amazon Inspector</a> might work for you in such a case.</p>
</li>
</ul>
<p>Once an image from the Iteration is validated and passed the security assessment, it&rsquo;s safe to promote that Iteration to a channel.</p>
<p>HCP Packer provides a rich <a href="https://cloud.hashicorp.com/api-docs/packer">API</a> that you can leverage to automate that process.</p>
<p>When a <code>packer build</code> successfully finishes its execution, it returns the Iteration ID (ULID) that you can use later for an API call with a request to promote the new Iteration to a channel.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/packer-build-output_hu_3bdb0eed72308703.webp"
                 alt="Packer build output with Iteration ULID"width="800"height="218.00" />
        
    
    <figcaption>
        <p>Packer build output with Iteration ULID
            </p>
    </figcaption>
</figure>

<p>The &ldquo;Update Channel&rdquo; PATCH API method is needed to assign the Iteration to a channel.</p>
<p>First, you need to obtain the access token as described in <a href="https://support.hashicorp.com/hc/en-us/articles/6676505991699-HCP-API-Authentication-with-Curl">this guide</a>.</p>
<p>Then, the following cURL request can be used to update the channel with a new Iteration ULID (please expand the code snippet below):</p>
<div class="code-snippet">
<details>
<summary markdown="span">Click here to see the code snippet</summary>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#79c0ff">HCP_ACCESS_TOKEN</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;your token here&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#79c0ff">HCP_ORG_ID</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;your org id here&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#79c0ff">HCP_PROJECT_ID</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;your project id here&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#79c0ff">HCP_BUCKET_NAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;amazon-linux2&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#79c0ff">HCP_CHANNEL_NAME</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;stable&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#79c0ff">HCP_BASE_URL</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;https://api.cloud.hashicorp.com/packer/2021-04-30&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -X PATCH <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>--header <span style="color:#a5d6ff">&#34;Authorization: Bearer </span><span style="color:#79c0ff">$HCP_ACCESS_TOKEN</span><span style="color:#a5d6ff">&#34;</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>--data <span style="color:#a5d6ff">&#39;{
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">&#34;incremental_version&#34;:&#34;3&#34;,
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">&#34;iteration_id&#34;:&#34;01H8V7WBDWRBCMZDZ2HG3MKSDL&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#a5d6ff">}&#39;</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span><span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">HCP_BASE_URL</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/organizations/</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">HCP_ORG_ID</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/projects/</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">HCP_PROJECT_ID</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/images/</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">HCP_BUCKET_NAME</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/channels/</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">HCP_CHANNEL_NAME</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>
</span></span></code></pre></div>
</details>
</div>
<h2 id="using-hcp-packer-with-terraform">Using HCP Packer with Terraform</h2>
<p>Having a streamlined golden image creation process is good. Still, it would be even better to have an easy way to always use the latest validated image without hardcoding or some other duck taping.</p>
<p>With the help of the <a href="https://registry.terraform.io/providers/hashicorp/hcp">HCP Terraform provider</a>, you can reference the image channel in your Terraform code and have a completed end-to-end workflow.</p>
<p>Here is an example of the Terraform configuration that uses the HCP Packer registry as the source of AMI ID for an AWS instance:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/terraform-hcp-packer_hu_5dfebcfe48defd17.webp"
                 alt="Using HCP Packer registry with Terraform"width="800"height="529.00" />
        
    
    <figcaption>
        <p>Using HCP Packer registry with Terraform
            </p>
    </figcaption>
</figure>

<p>Two data sources do all the magic here.</p>
<p>The  <code>hcp_packer_iteration</code>  data source gets the most recent Iteration assigned to the specified Channel (i.e., latest). We need that because the Iteration (not the Channel) holds the image information.</p>
<p>Then the <code>hcp_packer_image</code> gets the cloud image ID (AWS AMI ID in my example) from that Iteration so you can use it later in your code.</p>
<p>The configuration of the <code>hcp</code> provider in this example is empty on purpose: this provider supports <code>HCP_CLIENT_ID</code> and <code>HCP_CLIENT_SECRET</code> env variables to use their values for the <a href="https://registry.terraform.io/providers/hashicorp/hcp/latest/docs/guides/auth">authentication</a> and avoid hard coding. Alternatively, you can use the <code>client_id</code> and <code>client_secret</code> options to configure the provider.</p>
<h2 id="image-revocation">Image revocation</h2>
<p>It is possible to revoke a specific Iteration, and therefore all Images in it, to alert the users about the Image decommission. For example, your SecOps team can revoke it due to the new CVE announced.</p>
<p>Revoked Images are treated differently by Packer CLI and Terraform CLI.</p>
<h3 id="packer-cli-and-revoked-image">Packer CLI and Revoked Image</h3>
<p>When you reference the Image in a Packer template to use it as a source for another image, its revocation makes further Packer builds to fail.</p>
<p>In other words, Packer won&rsquo;t let you build a new Image on top of the revoked Image.</p>
<h3 id="terraform-cli-and-revoked-image">Terraform CLI and Revoked Image</h3>
<p>On the contrary, Terraform CLI does not prevent the usage of the revoked Image by default, although its Cloud version does it if used with the &ldquo;Run tasks&rdquo; feature.</p>
<p>Although you can get the Image ID, when the Iteration is revoked, the <code>hcp_packer_image</code> data source returns a non-empty <code>revoke_at</code> attribute with the value set to the revocation timestamp.</p>
<p>Therefore, you can use the <code>precondition</code> (available in <a href="https://devdosvid.blog/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/#precondition-and-postcondition">Terraform CLI v1.2.0</a> and higher) to validate the Image with Terraform CLI and make sure it was not revoked</p>
<p>Here is the code example that illustrates that:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/06/26/golden-image-pipelines-with-hcp-packer/logic-for-revoked-iteration_hu_c462e6f7ad252bfb.webp"
                 alt="Work with revoked HCP Packer image in Terraform"width="800"height="501.24" />
        
    
    <figcaption>
        <p>Work with revoked HCP Packer image in Terraform
            </p>
    </figcaption>
</figure>

<h2 id="why-hcp-packer">Why HCP Packer?</h2>
<p>So what makes the HCP Packer a good fit and worth a try?</p>
<p>1️⃣ A centralized place to view and manage the OS images throughout an organization. And as for me, it is good to have a neat web panel to look at things.</p>
<p>2️⃣ Image Channels that help with logical organization and control.</p>
<p>3️⃣ Ability to revoke an image to prevent its usage.</p>
<p>4️⃣ API and Terraform provider as additional tools that enrich the user experience.</p>
<p>When dealing with multiple golden images or with various cloud providers, the <a href="https://cloud.hashicorp.com/products/packer">HCP Packer</a> can be a good fit for your image pipeline.</p>
<p>As a registry, it enables the end-to-end workflow for golden image usage: create, validate, use and decommission the images in a centralized way.</p>
<p>And no more hard-coded IDs, manual variable settings, or other duck tape and glue in your Terraform.</p>
<p>If you want to learn more about HCP Packer and have some practice, I suggest starting from the <a href="https://learn.hashicorp.com/collections/packer/hcp">tutorial at HashiCorp Learn portal</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>New Lifecycle Options and Refactoring Capabilities in Terraform 1.1 and 1.2</title>
      <link>https://devdosvid.blog/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/</link>
      <pubDate>Wed, 04 May 2022 22:27:47 +0200</pubDate>
      <guid>https://devdosvid.blog/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/</guid>
      <description>Terraform code refactoring and resource lifecycle conditions, and triggers — now natively available</description>
      <content:encoded><![CDATA[<p>In this blog, I would like to tell you about new cool features that Terraform 1.1 and 1.2 bring. It feels like Terraform has doubled its speed of delivering the new features after they released the 1.0. 🤩</p>
<p>It&rsquo;s been only a few months since Terraform 1.1 was released with the <code>moved</code> block that empowers the code refactoring.</p>
<p>Now Terraform 1.2 is almost <a href="*https://github.com/hashicorp/terraform/releases/tag/v1.2.0-rc1*">ready</a> (as I am writing this blog in early May 2022) to bring three new efficient controls to the resource lifecycle.<br>
These are three new expressions: <code>precondition</code>, <code>postcondition</code>, and <code>replace_triggered_by</code>.</p>
<div class="beehiiv-subscribe-container">
    <h3>Subscribe to blog updates!</h3>
    <iframe src="https://embeds.beehiiv.com/60009a3f-3202-4ac0-85f8-0d3db1ea781b?slim=true" data-test-id="beehiiv-embed"
        height="52" frameborder="0" scrolling="no"
        style="margin: 0; border-radius: 0px !important; background-color: transparent;"></iframe>
</div>
<h2 id="terraform-code-refactoring-with-the-moved-block">Terraform Code Refactoring With the Moved Block</h2>
<p>Starting from the 1.1 version, Terraform users can use the <code>moved</code> block to describe the changes in resource or module addresses (or resources inside a module) in the form of code. <br>
Once that is described, Terraform performs the movement of the resource within the state during the first apply.</p>
<p>In other words, what this feature gives you, is the ability to document your <code>terraform state mv</code> actions, so you and other project or module users don&rsquo;t need to perform them manually.</p>
<p>As your code evolves, a resource or module can have several <code>moved</code> blocks associated with it, and Terraform will thoroughly reproduce the whole history of its movement within a state (i.e., renaming).</p>
<p>Let&rsquo;s review some examples that illustrate how it works.</p>
<h3 id="move-or-rename-a-resource">Move or rename a resource</h3>
<p>In a module, I have a bucket policy that has a generic, meaningless name. It is used in a module that creates a CloudFront distribution with an S3 bucket.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-1_hu_4aa1960a5552dd5c.webp"
                 alt="An example resource"width="800"height="150" />
        
    
    <figcaption>
        <p>An example resource
            </p>
    </figcaption>
</figure>

<p>It&rsquo;s pretty OK to name a resource like that if you have only a single instance of that kind in your code.</p>
<p>Later, when I need to add another policy to the module, I don&rsquo;t want to name it &ldquo;that&rdquo;. Instead, I want my policies to have meaningful names now.<br>
For example, I could rename the old policy with the <code>terraform state mv</code> command, but other users of my module would not know about that.</p>
<p>That is where the <code>moved</code> block turns out to be helpful!</p>
<div class="attention">
    The <code>moved</code> block allows you to document how you rename or move an object in Terraform so that other code users can have the same changes afterward.
</div>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-2_hu_eb13c021cec2d80e.webp"
                 alt="Resource address update with the Moved block"width="800"height="270" />
        
    
    <figcaption>
        <p>Resource address update with the Moved block
            </p>
    </figcaption>
</figure>

<p>Terraform follows the instructions inside the <code>module</code> block to plan and apply changes. Although the resource address update is not counted as a change in the Plan output, Terraform will perform that update during apply.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-3_hu_53497fff0a5193d7.webp"
                 alt="Terraform plan output"width="800"height="318" />
        
    
    <figcaption>
        <p>Terraform plan output
            </p>
    </figcaption>
</figure>

<h3 id="move-or-rename-a-module">Move or rename a module</h3>
<p>The same approach can be applied to a module — you can move or rename it as a code too.</p>
<p>Here, I use two modules to create static hosting for a website with a custom TLS certificate.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-4_hu_713b305a5f3ee68f.webp"
                 alt="Two modules with generic names"width="800"height="437" />
        
    
    <figcaption>
        <p>Two modules with generic names
            </p>
    </figcaption>
</figure>

<p>Again, if I need to add another couple of the CDN+Certificate modules, I would like to have meaningful names in my code so clearly distinguish one from another.</p>
<p>Therefore, I would add two <code>moved</code> blocks — one per module call.</p>
<p>And by the way, since I renamed the module (from <code>cert</code> to <code>example_com_cert</code>), I need to update all references to that module&rsquo;s outputs in the code too.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-5_hu_f3c218ea084353c8.webp"
                 alt="Two modules renamed"width="800"height="629" />
        
    
    <figcaption>
        <p>Two modules renamed
            </p>
    </figcaption>
</figure>

<p>However, there is one nuance: when you rename a module and declare that in the <code>moved</code> block, you need to run the <code>terraform init</code> before applying the change because Terraform must initialize the module with the new name first.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-6_hu_179dc9d8bd340e9b.webp"
                 alt="Terraform error: module not installed"width="800"height="246" />
        
    
    <figcaption>
        <p>Terraform error: module not installed
            </p>
    </figcaption>
</figure>

<p>There are some more advanced actions you can make with the <code>moved</code> block:</p>
<ul>
<li>Implement count and for_each meta-arguments to resources and modules</li>
<li>Break one module into multiple
Check the following detailed guide from HashiCorp that explains how to do that — <a href="https://www.terraform.io/language/modules/develop/refactoring">Refactoring</a></li>
</ul>
<p>Introducing the <code>moved</code> blocks into your codebase defacto starts the refactoring process for your module users. But the finale of that refactoring happens when you ultimately remove these blocks.</p>
<p>Therefore, here is some advice on how to manage that:</p>
<div class="attention">
    <ul>
<li>
<p>Keep the <code>moved</code> blocks in your code for long. For example, when removing a <code>moved</code> block from the code, Terraform does not treat the new object name as a renaming anymore. Instead, Terraform will plan to delete the resource or module with the old name instead of renaming it.</p>
</li>
<li>
<p>Keep the complete chains of object renaming (sequence of moves). The whole history of object movement ensures that users with different module versions will get a consistent and predictable behavior of the refactoring.</p>
</li>
</ul>

</div>
<h2 id="lifecycle-expressions-conditions-and-replacement-trigger">Lifecycle expressions: conditions and replacement trigger</h2>
<p>Terraform 1.2 fundamentally improves the <code>lifecycle</code> meta-argument by adding three new configuration options with rich capabilities.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-7_hu_b3e66acb6aee8109.webp"
                 alt="New configuration options for the lifecycle meta-argument"width="800"height="365" />
        
    
    <figcaption>
        <p>New configuration options for the lifecycle meta-argument
            </p>
    </figcaption>
</figure>

<h3 id="precondition-and-postcondition">Precondition and Postcondition</h3>
<p>When you need to make sure that specific condition is met before or after you create a resource, you can use <code>postcondition</code> and <code>precondition</code> blocks.</p>
<p>The <em>condition</em> here — is some data or information about a resource you need to confirm to apply the code.</p>
<p>Here are a few examples of such conditions:</p>
<ul>
<li>Validate some attributes of the Data Source that you cannot check using filters or other available arguments;</li>
<li>Confirm the Resource argument that can compound several variables (e.g., list);</li>
</ul>
<div class="attention">
    <p><strong>Precondition</strong> works as an expectation or a guess about some external (but within a module) value that a resource depends on.</p>
<p><strong>Postcondition</strong> works as the assurance that a resource fulfills a specific condition so other resources may rely on that. If postcondition fails for a resource, this prevents changes to all other resources that depend on it.</p>

</div>
<p>Let&rsquo;s review this new feature with an example of <code>postcondition</code> usage.</p>
<p>Consider the following case: our module receives AMI ID as the input variable, and that AMI should be used in the Launch Template then; we also have the requirement for the EC2 instance created from that Launch Template — its root EBS size must be equal or bigger than 600 GB.</p>
<p>We cannot validate the EBS size using the variable that accepts the AMI ID. But we can write a <strong>postcondition</strong> for the Data Source that gets the information about the AMI and reference that Data Source in the Launch Template resource afterward.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-8_hu_cbfcb6852bb42cf5.webp"
                 alt="Data Source Postcondition"width="800"height="446" />
        
    
    <figcaption>
        <p>Data Source Postcondition
            </p>
    </figcaption>
</figure>

<p>The <code>condition</code> argument within the block accepts any of Terraform&rsquo;s built-in functions or language operators.</p>
<p>The special <code>self</code> object is available only for the <code>postcondition</code> block because it assumes that validation can be performed after the object is created and its attributes are known.</p>
<p>Later, if a module user specifies the AMI with an EBS size lesser than 600 GB, Terraform will fail to create the Launch Template because it depends on the Data Source that did not pass the postcondition check.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-9_hu_230cb5568eef55fa.webp"
                 alt="Resource postcondition error"width="800"height="240" />
        
    
    <figcaption>
        <p>Resource postcondition error
            </p>
    </figcaption>
</figure>

<p>Terraform tries to evaluate the condition expressions as soonest: sometimes Terraform can check the value during the planning phase, but sometimes that can be done only after the resource is created if the value is unknown.</p>
<h3 id="validate-module-output-with-precondition">Validate module output with precondition</h3>
<p>The <code>precondition</code> block is also available for the module outputs.</p>
<p>Just like the variable validation block assures that module input meets certain expectations, the <code>precondition</code> is intended to ensure that a module produces the valid output.</p>
<p>Here is an example: a module that creates an ACM certificate must prevent the usage of a specific domain name in the certificate&rsquo;s Common Name or its SANs.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-10_hu_5fdb543d84bfe964.webp"
                 alt="Module output precondition"width="800"height="342" />
        
    
    <figcaption>
        <p>Module output precondition
            </p>
    </figcaption>
</figure>

<p>In this case, instead of validating several input variables, we can write the validation only once for the output.</p>
<div class="attention">
    Validation of the module output helps with standardization and control of the data passed between Terraform modules.
</div>
<h3 id="trigger-resource-replacement-with-replace_triggered_by">Trigger resource replacement with replace_triggered_by</h3>
<p>Sometimes it&rsquo;s needed to specify the dependency in the way that recreates a resource when another resource or its attribute changes.</p>
<p>This is useful when two (or more) resources do not have any explicit dependency.</p>
<p>Consider the following case: you have two EC2 instances, A and B, and need to recreate the B instance if the private IP of instance A is changed.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/05/04/new-lifecycle-options-and-refactoring-capabilities-in-terraform-1-1-and-1-2/figure-11_hu_a4a183f76653d174.webp"
                 alt="replace_triggered_by example"width="800"height="342" />
        
    
    <figcaption>
        <p>replace_triggered_by example
            </p>
    </figcaption>
</figure>

<p>This is extremely useful when you&rsquo;re dealing with logical abstractions over the set of resources.</p>
<div class="attention">
    <p>Resource replacement is triggered when:</p>
<ul>
<li>any of the resources referenced in <code>replace_triggered_by</code> are updated</li>
<li>any value is set to the resource attribute that is referenced in <code>replace_triggered_by</code></li>
</ul>
</div>
<h2 id="getting-started-with-terraform-11-and-12">Getting started with Terraform 1.1 and 1.2</h2>
<p>If you&rsquo;re still using older Terraform versions, these new features might be a good motivation for you to upgrade!</p>
<p>Before upgrading, be sure to read the upgrade notes for the specific version at the <a href="https://github.com/hashicorp/terraform/releases">releases page</a>.</p>
<p>Also, an excellent tool can help with fast switching between different Terraform versions while you&rsquo;re experimenting — <a href="https://tfswitch.warrensbox.com/">tfswitch</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Monterey Shortcuts for Easy and Fast Image Processing</title>
      <link>https://devdosvid.blog/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/</link>
      <pubDate>Mon, 31 Jan 2022 23:46:04 +0200</pubDate>
      <guid>https://devdosvid.blog/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/</guid>
      <description>Some handy automation for image processing with Apple Shortcuts on your Mac</description>
      <content:encoded><![CDATA[<p>Here I want to share two Apple Shortcuts that I created for myself and use to process images for this blog:</p>
<p><a href="#optimization">Image Optimization</a></p>
<p>and</p>
<p><a href="#resize">Image Resize</a></p>
<p>About a year ago, I posted the blog about the Automator quick action &ldquo;Using TinyPNG Image Compression From MacOS Finder Contextual Menu&rdquo;) to optimize PNG and JPEG images with TinyPNG service and save the processed images next to the original ones.</p>
<p>While that Automator-based solution still works, macOS Monterey now supports Shortcuts — a new automating tool that seems to substitute the old fellow Automator.</p>
<p>So I decided to create a couple of automation with Shortcuts: one for image optimization (reduce file size but not the size in pixels), and one for image scaling (change its size in pixels).</p>
<p>I have used them for several months to prepare images for this blog, and I really like how they work!</p>
<h2 id="optimization">Image Optimization with Monterey Shortcuts</h2>
<p>This Shortcut replicates the functionality of the Automator quick action and also uses TinyPNG service as a back-end. There are tons of other similar services, but I like TinyPNG for its simplicity: it just does one thing, and it does it well.</p>
<p>So first, you need to get yourself an <a href="https://tinypng.com/developers" title="TinyPNG Developers API">API key</a> for TinyPNG.</p>
<p>The simplest way to reuse my Shortcut is to import it from iCloud using the following URL:</p>
<p><a href="https://www.icloud.com/shortcuts/0a44de1596c745eaaad8181e61289248" title="Click here to import the Image Optimization Shortcut">➡️ <strong>Click here to import the Image Optimization Shortcut</strong> ⬅️</a></p>
<p>The import will work only when the link is opened in <strong>Safari</strong>.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/shortcut-import-optimized_hu_743ac03b99a90c9b.webp"
                 alt="Shortcut Import Dialog"width="800"height="595.00" />
        
    
    <figcaption>
        <p>Shortcut Import Dialog
            </p>
    </figcaption>
</figure>

<p>To make the Shortcut work from the context menu of the Finder, set the options on the Details panel of the Shortcut setting as displayed on the screenshot:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/shortcut-settings-optimized_hu_a36059c717f68633.webp"
                 alt="Shortcut Settings"width="800"height="666.00" />
        
    
    <figcaption>
        <p>Shortcut Settings
            </p>
    </figcaption>
</figure>

<p>Here is what this Image Optimization Shortcut does:</p>
<blockquote>
<p><em>The Shortcut receives image files. Then, for every image file received, the Shotcut does the following:</em></p>
<ul>
<li><em>Gets the file&rsquo;s name and parent directory</em></li>
<li><em>Sends the original file to TinyPNG</em></li>
<li><em>Process the response with URL to download the optimized image</em></li>
<li><em>Downloads the optimized image using the URL from the response and replaces the original image with the optimized</em></li>
</ul></blockquote>
<p>And here is how this Shortcuts looks if you want to create it from scratch:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/image-optimization-shortcut_hu_de1928fc0522d3e4.webp"
                 alt="Image Optimization Shortcut"width="800"height="1954.66" />
        
    
    <figcaption>
        <p>Image Optimization Shortcut
            </p>
    </figcaption>
</figure>

<p><em>Unfortunately, this Shortcut won&rsquo;t work on iOS or watchOS because they do not support the &ldquo;File Storage&rdquo; actions used in the Shortcut.</em></p>
<p>🌟 <strong>Demo</strong> 🌟
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/shortcut-demo_hu_75a730acec428998.webp"
                 alt="Shortcut Demo"width="800"height="620.00" />
        
    
    <figcaption>
        <p>Shortcut Demo
            </p>
    </figcaption>
</figure>
</p>
<h2 id="resize">Image Resize with Monterey Shortcuts</h2>
<p>Another Shortcut I actively use is the image resizer. Most of the images on my blog are 1600px width fitted into an 800px frame to look sharp on the high-res displays (e.g., Retina).</p>
<p>And when I have many images in my folder, I want to make them all be 1600px width at once or don&rsquo;t change their own size if they were created smaller intentionally (no upscale, in other words).</p>
<p>Here is the link to Shortcut import (again, the import will work only when the link is opened in <strong>Safari</strong>):</p>
<p><a href="https://www.icloud.com/shortcuts/0af8005cc9ac4207a380be445601d541" title="Click here to import the Image Resize Shortcut">➡️ <strong>Click here to import the Image Resize Shortcut</strong> ⬅️</a></p>
<p>Here is how the Image Resize Shortcut looks if you want to create it from scratch:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/31/monterey-shortcuts-for-easy-and-fast-image-processing/image-resize-shortcut-optimized_hu_e53a60e7d3b3c179.webp"
                 alt="Image Resizing Shortcut"width="800"height="1176.98" />
        
    
    <figcaption>
        <p>Image Resizing Shortcut
            </p>
    </figcaption>
</figure>

<h2 id="fun-with-shortcuts">Fun with Shortcuts</h2>
<p>I love the way Apple works on routine automation. This Shortcuts app, ported from iOS, brings a lot of cool and fun possibilities to Mac.</p>
<p>Do you use Shortcuts? What is your favorite? I would love to know!</p>
]]></content:encoded>
    </item>
    <item>
      <title>Some Techniques to Enhance Your Terraform Proficiency</title>
      <link>https://devdosvid.blog/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/</link>
      <pubDate>Sun, 16 Jan 2022 01:59:51 +0200</pubDate>
      <guid>https://devdosvid.blog/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/</guid>
      <description>Learn what cool things Terraform can do with its built-in functionality</description>
      <content:encoded><![CDATA[<p>Terraform built-in functionality is very feature-rich: functions, expressions,  and meta-arguments provide many ways to shape the code and fit it to a particular use case. I want to share a few valuable practices to boost your Terraform expertise in this blog.</p>
<div class="attention">
    Some code examples in this article will work with Terraform version 0.15 and onwards. But if you&rsquo;re still using 0.14 or lower, here&rsquo;s another motivation for you to upgrade.
</div>
<h2 id="conditional-resource-creation-or-how-to-implement-the-if-else-statement-in-terraform">Conditional resource creation or how to implement the &ldquo;if else&rdquo; statement in Terraform</h2>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/condiitonal-resource-creation_hu_40881a6a31d15011.webp"width="400"height="400.00" />
        
    
</figure>

<p>With Terraform, you can have a conditional module or a resource creation by implementing the ternary operator — so-called Conditional Expressions.</p>
<p>Let&rsquo;s start from the most popular one: whether to create a resource depending on some fact, e.g., the value of a variable.</p>
<p>Terraform meta-argument <code>count</code> helps to describe that kind of resource creation logic.</p>
<p>Here is how it may look like:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">data</span> <span style="color:#a5d6ff">&#34;aws_ssm_parameter&#34;</span> <span style="color:#a5d6ff">&#34;ami_id&#34;</span> {
</span></span><span style="display:flex;"><span>  count    = var.ami_channel =<span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;&#34;</span> <span style="color:#ff7b72;font-weight:bold">?</span> <span style="color:#a5d6ff">0</span> <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  name     = local.ami_channels[var.ami_channel]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The notation <code>var.ami_channel == &quot;&quot; ? 0 : 1</code> is called <em>conditional expression</em> and means the following: if my variable is empty (<code>var.ami_channel == &quot;&quot;</code> — hence, true) then set the count to 0, otherwise set to 1.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>condition ? true_val : false_val
</span></span></code></pre></div><p>In this illustration, I want to get the AMI ID from the SSM Parameter only if the AMI channel (e.g., beta or alpha) is specified. Otherwise, providing that the <code>ami_channel</code> variable is an empty string by default (&quot;&quot;), the data source should not be created.</p>
<p>When following this method, keep in mind that the resource address will contain the index identifier. So when I need to use the value of the SSM parameter from our example, I need to reference it the following way:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span>ami_id = data.aws_ssm_parameter.ami_id[<span style="color:#a5d6ff">0</span>].value
</span></span></code></pre></div><p>The <code>count</code> meta-argument can also be used when you need to conditionally create a Terraform module.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">module</span> <span style="color:#a5d6ff">&#34;bucket&#34;</span> {
</span></span><span style="display:flex;"><span>  count             = var.create_bucket =<span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#79c0ff">true</span> <span style="color:#ff7b72;font-weight:bold">?</span> <span style="color:#a5d6ff">1</span> <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">0</span>
</span></span><span style="display:flex;"><span>  source            = <span style="color:#a5d6ff">&#34;./modules/s3_bucket&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  name              = <span style="color:#a5d6ff">&#34;my-unique-bucket&#34;</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>var.create_bucket == true ? 1 : 0</code>  expression can be written even shorter: <code>var.create_bucket ? 1 : 0</code>  because the <code>create_bucket</code> variable has boolean type, apparently.</p>
<p>But what if you need to produce more than one instance of a resource or module? And still be able to avoid their creation.</p>
<p>Another meta-argument — <code>for_each</code> — will do the trick.</p>
<p>For example, this is how the <code>for_each</code> argument works for the conditional module creation:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">module</span> <span style="color:#a5d6ff">&#34;bucket&#34;</span> {
</span></span><span style="display:flex;"><span>  for_each          = var.bucket_names =<span style="color:#ff7b72;font-weight:bold">=</span> [] <span style="color:#ff7b72;font-weight:bold">?</span> [] <span style="color:#ff7b72;font-weight:bold">:</span> var.bucket_names
</span></span><span style="display:flex;"><span>  source            = <span style="color:#a5d6ff">&#34;./modules/s3_bucket&#34;</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  name              = <span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span>each.key<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">&#34;</span>
</span></span><span style="display:flex;"><span>  enable_encryption = <span style="color:#79c0ff">true</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>In this illustration, I also used a conditional expression that makes Terraform iterate through the set of values of <code>var.bucket_names</code> if it&rsquo;s not empty and create several modules. Otherwise, do not iterate at all and do not create anything.</p>
<p>The same can be done for the resources. For example, when you need to create an arbitrary number of security group rules, e.g., to allowlist some IPs for your bastion host:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_security_group_rule&#34;</span> <span style="color:#a5d6ff">&#34;allowlist&#34;</span> {
</span></span><span style="display:flex;"><span>  for_each           = var.cidr_blocks =<span style="color:#ff7b72;font-weight:bold">=</span> [] <span style="color:#ff7b72;font-weight:bold">?</span> [] <span style="color:#ff7b72;font-weight:bold">:</span> var.cidr_blocks
</span></span><span style="display:flex;"><span>  type               = <span style="color:#a5d6ff">&#34;ingress&#34;</span>
</span></span><span style="display:flex;"><span>  from_port          = <span style="color:#a5d6ff">22</span>
</span></span><span style="display:flex;"><span>  to_port            = <span style="color:#a5d6ff">22</span>
</span></span><span style="display:flex;"><span>  protocol           = <span style="color:#a5d6ff">&#34;tcp&#34;</span>
</span></span><span style="display:flex;"><span>  cidr_blocks        = [each.value]
</span></span><span style="display:flex;"><span>  security_group_id  = aws_security_group.bastion.id
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And just like with the <code>count</code> meta-argument, with the <code>for_each</code>, resource addresses will have the identifier named by the values provided to <code>for_each</code>.</p>
<p>For example, here is how I would reference a resource created in the module with <code>for_each</code> described earlier:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span>bucket_name = module.bucket[<span style="color:#a5d6ff">&#34;photos&#34;</span>].name
</span></span></code></pre></div><div class="beehiiv-subscribe-container">
    <h3>Subscribe to blog updates!</h3>
    <iframe src="https://embeds.beehiiv.com/60009a3f-3202-4ac0-85f8-0d3db1ea781b?slim=true" data-test-id="beehiiv-embed"
        height="52" frameborder="0" scrolling="no"
        style="margin: 0; border-radius: 0px !important; background-color: transparent;"></iframe>
</div>
<h2 id="conditional-resource-arguments-attributes-setting">Conditional resource arguments (attributes) setting</h2>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/conditional-resource-argument_hu_800103069fc576.webp"width="400"height="400.00" />
        
    
</figure>

<p>Now let&rsquo;s go deeper and see how resource arguments can be conditionally set (or not).</p>
<p>First, let&rsquo;s review the conditional argument value setting with the <code>null</code> data type:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_launch_template&#34;</span> <span style="color:#a5d6ff">&#34;this&#34;</span> {
</span></span><span style="display:flex;"><span>  name     = <span style="color:#a5d6ff">&#34;my-launch-template&#34;</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  key_name = var.use_default_keypair <span style="color:#ff7b72;font-weight:bold">?</span> var.keypair_name <span style="color:#ff7b72;font-weight:bold">:</span> null
</span></span><span style="display:flex;"><span>  ...
</span></span></code></pre></div><p>Here I want to skip the usage of the EC2 Key Pair for the Launch Template in some instances and Terraform allows me to write the conditional expression that will set the <code>null</code> value for the argument. It means the <em>absence</em> or <em>omission</em> and Terraform would behave the same as if you did not specify the argument at all.</p>
<p>Dynamic blocks are another case where conditional creation suits best. Take a look at the following piece of CloudFront resource code where I want to either describe the configuration for the custom error response or omit that completely:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_cloudfront_distribution&#34;</span> <span style="color:#a5d6ff">&#34;cdn&#34;</span> {
</span></span><span style="display:flex;"><span>  enabled = <span style="color:#79c0ff">true</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  dynamic <span style="color:#a5d6ff">&#34;custom_error_response&#34;</span> {
</span></span><span style="display:flex;"><span>    for_each = var.custom_error_response =<span style="color:#ff7b72;font-weight:bold">=</span> null <span style="color:#ff7b72;font-weight:bold">?</span> [] <span style="color:#ff7b72;font-weight:bold">:</span> [var.custom_error_response]
</span></span><span style="display:flex;"><span>    iterator = cer
</span></span><span style="display:flex;"><span>    content {
</span></span><span style="display:flex;"><span>      error_code            = lookup(cer.value, <span style="color:#a5d6ff">&#34;error_code&#34;</span>, null)
</span></span><span style="display:flex;"><span>      error_caching_min_ttl = lookup(cer.value, <span style="color:#a5d6ff">&#34;error_caching_min_ttl&#34;</span>, null)
</span></span><span style="display:flex;"><span>      response_code         = lookup(cer.value, <span style="color:#a5d6ff">&#34;response_code&#34;</span>, null)
</span></span><span style="display:flex;"><span>      response_page_path    = lookup(cer.value, <span style="color:#a5d6ff">&#34;response_page_path&#34;</span>, null)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>custom_error_response</code> variable is <code>null</code> by default, but it has the <code>object</code> type, and users can assign the variable with the required nested specifications if needed. And when they do it, Terraform will add the <code>custom_error_response</code> block to the resource configuration. Otherwise, it will be omitted entirely.</p>
<h2 id="convert-types-in-terraform-with-ease">Convert types in Terraform with ease</h2>
<p><figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/types-converstion_hu_e3e70aec17c92843.webp"width="400"height="400.00" />
        
    
</figure>

Ok, let&rsquo;s move to the less conditional things now 😅</p>
<p>Terraform has several type conversion functions: <code>tobool()</code>, <code>tolist()</code>,<code>tomap()</code>, <code>tonumber()</code>, <code>toset()</code>, and <code>tostring()</code>. Their purpose is to convert the input values to the compatible types.</p>
<p>For example, suppose I need to pass the set to the <code>for_each</code> (it accepts only sets and maps types of value), but I got the list as an input; let&rsquo;s say I got it as an output from another module. In such a case, I would do something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span>for_each = toset(var.remote_access_ports)
</span></span></code></pre></div><p>However, I can make my code cleaner and avoid the explicit conversion — I just need to define the value type in the configuration block of the <code>my_list</code> variable. Terraform will do the conversion automatically when the value is assigned.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">variable</span> <span style="color:#a5d6ff">&#34;remote_access_ports&#34;</span> {
</span></span><span style="display:flex;"><span>  description = <span style="color:#a5d6ff">&#34;Ports for remote access&#34;</span>
</span></span><span style="display:flex;"><span>  type        = set(string)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>While Terraform can do a lot of implicit conversions for you, explicit type conversions are practical during values normalization or when you need to calculate some complex value for a variable. For example, the Local Values, known as <code>locals</code>, are the most suitable place for doing that.</p>
<p>By the way, although there is a <code>tolist()</code> function, there is no such thing as the <code>tostring()</code> function. But what if you need to convert the list to string in Terraform?</p>
<p>The <code>one()</code> function can help here: it takes a list, set, or tuple value with either zero or one element and returns either <code>null</code> or that one element in the form of string.</p>
<p>It&rsquo;s useful in cases when a resource created using conditional expression is represented as either a zero- or one-element list, and you need to get a single value which may be either <code>null</code> or <code>string</code>, for example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_kms_key&#34;</span> <span style="color:#a5d6ff">&#34;main&#34;</span> {
</span></span><span style="display:flex;"><span>  count               = var.ebs_encrypted <span style="color:#ff7b72;font-weight:bold">?</span> <span style="color:#a5d6ff">1</span> <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  enable_key_rotation = <span style="color:#79c0ff">true</span>
</span></span><span style="display:flex;"><span>  tags                = var.tags
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">
</span></span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_kms_alias&#34;</span> <span style="color:#a5d6ff">&#34;main&#34;</span> {
</span></span><span style="display:flex;"><span>  count         = var.ebs_encrypted <span style="color:#ff7b72;font-weight:bold">?</span> <span style="color:#a5d6ff">1</span> <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  name          = <span style="color:#a5d6ff">&#34;alias/encrypt-ebs&#34;</span>
</span></span><span style="display:flex;"><span>  target_key_id = one(aws_kms_key.main[<span style="color:#ff7b72;font-weight:bold">*</span>]key_id)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="write-yaml-or-json-as-terraform-code-hcl">Write YAML or JSON as Terraform code (HCL)</h2>
<p><figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/write-yaml-json-as-terraform-code_hu_fceb6d283c60b5ff.webp"width="400"height="400.00" />
        
    
</figure>

Sometimes you need to supply JSON or YAML files to the services you manage with Terraform. For example, if you want to create something with CloudFormation using Terraform (and I am not kidding). Sometimes the AWS Terraform provider does not support the needed resource, and you want to maintain the whole infrastructure code using only one tool.</p>
<p>Instead of maintaining another file in JSON or YAML format, you can embed JSON or YAML code management into HCL by taking benefit of the  <code>jsonencode()</code> or <code>yamlencode()</code>  functions.</p>
<p>The attractiveness of this approach is that you can reference other Terraform resources or their attributes right in the code of your object, and you have more freedom in terms of the code syntax and its formatting comparable to native JSON or YAML.</p>
<p>Here is how it looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span>locals {
</span></span><span style="display:flex;"><span>	some_string = <span style="color:#a5d6ff">&#34;ult&#34;</span>
</span></span><span style="display:flex;"><span>  myjson_object = jsonencode({
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;Hashicorp Products&#34;</span><span style="color:#ff7b72;font-weight:bold">:</span> {
</span></span><span style="display:flex;"><span>      Terra<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#34;form&#34;</span>
</span></span><span style="display:flex;"><span>      Con<span style="color:#ff7b72;font-weight:bold">:</span>   <span style="color:#a5d6ff">&#34;sul&#34;</span>
</span></span><span style="display:flex;"><span>      Vag<span style="color:#ff7b72;font-weight:bold">:</span>   <span style="color:#a5d6ff">&#34;rant&#34;</span>
</span></span><span style="display:flex;"><span>      Va<span style="color:#ff7b72;font-weight:bold">:</span>    local.some_string
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  })
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The value of the <code>myjson_object</code> local variable would look like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;Hashicorp Products&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;Con&#34;</span>: <span style="color:#a5d6ff">&#34;sul&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;Terra&#34;</span>: <span style="color:#a5d6ff">&#34;form&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;Va&#34;</span>: <span style="color:#a5d6ff">&#34;ult&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;Vag&#34;</span>: <span style="color:#a5d6ff">&#34;rant&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And here is a piece of real-world example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span>locals {
</span></span><span style="display:flex;"><span>  cf_template_body = jsonencode({
</span></span><span style="display:flex;"><span>    Resources <span style="color:#ff7b72;font-weight:bold">:</span> {
</span></span><span style="display:flex;"><span>      DedicatedHostGroup <span style="color:#ff7b72;font-weight:bold">:</span> {
</span></span><span style="display:flex;"><span>        Type <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#34;AWS::ResourceGroups::Group&#34;</span>
</span></span><span style="display:flex;"><span>        Properties <span style="color:#ff7b72;font-weight:bold">:</span> {
</span></span><span style="display:flex;"><span>          Name <span style="color:#ff7b72;font-weight:bold">:</span> var.service_name
</span></span><span style="display:flex;"><span>          Configuration <span style="color:#ff7b72;font-weight:bold">:</span> [
</span></span><span style="display:flex;"><span>            {
</span></span><span style="display:flex;"><span>              Type <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#34;AWS::EC2::HostManagement&#34;</span>
</span></span><span style="display:flex;"><span>              Parameters <span style="color:#ff7b72;font-weight:bold">:</span> [
</span></span><span style="display:flex;"><span>                {
</span></span><span style="display:flex;"><span>                  Name <span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#34;auto-allocate-host&#34;</span>
</span></span><span style="display:flex;"><span>                  Values <span style="color:#ff7b72;font-weight:bold">:</span> [var.auto_allocate_host]
</span></span><span style="display:flex;"><span>                },
</span></span><span style="display:flex;"><span>			...
</span></span><span style="display:flex;"><span>			...
</span></span></code></pre></div><h2 id="create-custom-file-templates-in-terraform">Create custom file templates in Terraform</h2>
<p><figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2022/01/16/some-techniques-to-enhance-your-terraform-proficiency/templatize-stuff_hu_7ee38532b37a40f5.webp"width="400"height="400.00" />
        
    
</figure>

The last case in this blog but not the least by its efficacy — render source file content as a template in Terraform.</p>
<p>Let&rsquo;s review the following scenario: you launch an EC2 instance and want to supply it with a bash script (via the user-data parameter) for some additional configuration at launch.</p>
<p>Suppose we have the following bash script <code>instance-init.sh</code> that sets the hostname and registers our instance in a monitoring system:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#8b949e;font-weight:bold;font-style:italic">#!/bin/bash
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-weight:bold;font-style:italic"></span>
</span></span><span style="display:flex;"><span>hostname example.com
</span></span><span style="display:flex;"><span>bash /opt/system-init/register-monitoring.sh
</span></span></code></pre></div><p>But what if you want to set a different hostname per instance, and some instances should not be registered in the monitoring system?</p>
<p>In such a case, here is how the script file content will look:</p>
<pre tabindex="0"><code class="language-gotemplate" data-lang="gotemplate">#!/bin/bash

hostname ${system_hostname}
%{ if register_monitoring }
bash /opt/system-init/register-monitoring.sh
%{endif}
</code></pre><p>And when you supply this file as an argument for the EC2 instance resource in Terraform, you will use the <code>templatefile()</code> function to make the magic happen:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-terraform" data-lang="terraform"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_instance&#34;</span> <span style="color:#a5d6ff">&#34;web&#34;</span> {
</span></span><span style="display:flex;"><span>  ami           = var.my_ami_id
</span></span><span style="display:flex;"><span>  instance_type = var.instance_type
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  user_data = templatefile(<span style="color:#a5d6ff">&#34;</span><span style="color:#a5d6ff">${</span>path.module<span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/instance-init.tftpl&#34;</span>, {
</span></span><span style="display:flex;"><span>    system_hostname     = var.system_hostname
</span></span><span style="display:flex;"><span>    register_monitoring = var.add_to_monitoring
</span></span><span style="display:flex;"><span>  })
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And of course, you can create a template from any file type. The only requirement here is that the template file must exist on the disk at the beginning of the Terraform execution.</p>
<h2 id="key-takeaways">Key takeaways</h2>
<p>Terraform is far beyond the standard resource management operations. With the power of built-in functions, you can write more versatile code and reusable Terraform modules.</p>
<p>✅ Use <a href="https://www.terraform.io/language/expressions/conditionals">conditional expressions</a> with <a href="https://www.terraform.io/language/meta-arguments/count">count</a> and <a href="https://www.terraform.io/language/meta-arguments/for_each">for_each</a> meta-arguments, when the creation of a resource depends on some context or user input.</p>
<p>✅ Take advantage of <a href="https://www.terraform.io/language/expressions/types#type-conversion">implicit type conversion</a> when working with input variables and their values to keep your code cleaner.</p>
<p>✅ Embed YAML and JSON-based objects right into your Terraform code using built-in <a href="https://www.terraform.io/language/functions/jsonencode">encoding</a> <a href="https://www.terraform.io/language/functions/yamlencode">functions</a>.</p>
<p>✅ And when you need to pass some files to the managed service, you can treat them as <a href="https://www.terraform.io/language/functions/templatefile">templates</a> and make them multipurpose.</p>
<p>Thank you for reading down to this point! 🤗</p>
<p>If you have some favorite Terraform tricks — I would love to know!</p>
]]></content:encoded>
    </item>
    <item>
      <title>Guide to Using Terraform in CI/CD</title>
      <link>https://devdosvid.blog/2021/11/24/guide-to-using-terraform-in-ci/cd/</link>
      <pubDate>Wed, 24 Nov 2021 22:20:45 +0200</pubDate>
      <guid>https://devdosvid.blog/2021/11/24/guide-to-using-terraform-in-ci/cd/</guid>
      <description>How to configure, how to run, and what to mind for when using Terraform in CI/CD</description>
      <content:encoded><![CDATA[<p>Terraform by itself automates a lot of things: it creates, changes, and versions your cloud resources. Although many teams run Terraform locally (sometimes with wrapper scripts), running Terraform in CI/CD can boost the organization&rsquo;s performance and ensure consistent deployments.</p>
<p>In this article, I would like to review different approaches to integrating Terraform into generic deployment pipelines.</p>
<h1 id="where-to-store-the-terraform-code">Where to store the Terraform code</h1>
<p>Storing Terraform code in the same repository as the application code or maintaining a separate repository for the infrastructure?</p>
<p>This question has no strict and clear answer, but here are some insights that may help you decide:</p>
<ul>
<li>The Terraform and application code coupled together represent one unit, so it&rsquo;s simple to maintain by one team;</li>
<li>Conversely, if you have a dedicated team that manages infrastructure (e.g., platform team), a separate repository for infrastructure is more convenient because it&rsquo;s a standalone project in that case.</li>
<li>When infrastructure code is stored with the application, sometimes you have to deal with additional rules for the pipeline to separate triggers for these code parts. But sometimes (e.g., serverless apps) changes to either part (app/infra) should trigger the deployment.</li>
</ul>
<div class="attention">
    There is no right or wrong approach, but whichever you choose, remember to follow the <strong>Don’t Repeat Yourself (DRY)</strong> principle: make the infrastructure code modular by logically grouping resources into higher abstractions and reusing these modules.
</div>
<h1 id="preparing-terraform-execution-environment">Preparing Terraform execution environment</h1>
<p>Running Terraform locally generally means that all dependencies are already in-place: you have the binary installed and present in the user&rsquo;s <code>PATH</code> and perhaps even some providers already stored in the <code>.terraform</code> directory.</p>
<p>But when you shift Terraform runs from your local machine to stateless pipelines, this is not the case. However, you can still have a pre-built environment — this will speed up the pipeline execution and provide control over the process.</p>
<p>Docker image with a Terraform binary is one of the popular solutions that address this. Once created, you can execute Terraform within a container context with configuration files mounted as a Docker volume.</p>
<p>You can use the official <a href="https://hub.docker.com/r/hashicorp/terraform/">image from Hashicorp</a>, but sometimes it makes sense to maintain your own Docker images with additional tools you may need. For instance, you can bake the <code>tfsec</code> tool into the image to use it for security inspection and have it ready inside the Docker container without the need to install it every time.</p>
<p>Here is an example of a Dockerfile that builds an image with a custom Terraform version (you can override it as a build argument) and a <code>tfsec</code> tool. This example also shows how to verify the installed Terraform binary to make sure it&rsquo;s signed by HashiCorp before we run it.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-dockerfile" data-lang="dockerfile"><span style="display:flex;"><span><span style="color:#ff7b72">FROM</span><span style="color:#a5d6ff"> alpine:3.14</span><span style="color:#f85149">
</span></span></span><span style="display:flex;"><span><span style="color:#f85149"></span><span style="color:#ff7b72">ARG</span> <span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">1</span>.0.11<span style="color:#f85149">
</span></span></span><span style="display:flex;"><span><span style="color:#f85149"></span><span style="color:#ff7b72">ARG</span> <span style="color:#79c0ff">TFSEC_VERSION</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">0</span>.59.0<span style="color:#f85149">
</span></span></span><span style="display:flex;"><span><span style="color:#f85149"></span><span style="color:#ff7b72">RUN</span> apk add --no-cache --virtual .sig-check gnupg<span style="color:#f85149">
</span></span></span><span style="display:flex;"><span><span style="color:#f85149"></span><span style="color:#ff7b72">RUN</span> wget -O /usr/bin/tfsec https://github.com/aquasecurity/tfsec/releases/download/v<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TFSEC_VERSION</span><span style="color:#a5d6ff">}</span>/tfsec-linux-amd64 <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> chmod +x /usr/bin/tfsec<span style="color:#f85149">
</span></span></span><span style="display:flex;"><span><span style="color:#f85149"></span><span style="color:#ff7b72">RUN</span> cd /tmp <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> wget <span style="color:#a5d6ff">&#34;https://releases.hashicorp.com/terraform/</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">/terraform_</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">_linux_amd64.zip&#34;</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> wget https://keybase.io/hashicorp/pgp_keys.asc <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> gpg --import pgp_keys.asc <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> gpg --fingerprint --list-signatures <span style="color:#a5d6ff">&#34;HashiCorp Security&#34;</span> | grep -q <span style="color:#a5d6ff">&#34;C874 011F 0AB4 0511 0D02  1055 3436 5D94 72D7 468F&#34;</span> <span style="color:#ff7b72;font-weight:bold">||</span> exit <span style="color:#a5d6ff">1</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> gpg --fingerprint --list-signatures <span style="color:#a5d6ff">&#34;HashiCorp Security&#34;</span> | grep -q <span style="color:#a5d6ff">&#34;34365D9472D7468F&#34;</span> <span style="color:#ff7b72;font-weight:bold">||</span> exit <span style="color:#a5d6ff">1</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> wget https://releases.hashicorp.com/terraform/<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>/terraform_<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>_SHA256SUMS <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> wget https://releases.hashicorp.com/terraform/<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>/terraform_<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>_SHA256SUMS.sig <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> gpg --verify terraform_<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>_SHA256SUMS.sig terraform_<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>_SHA256SUMS <span style="color:#ff7b72;font-weight:bold">||</span> exit <span style="color:#a5d6ff">1</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> sha256sum -c terraform_<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>_SHA256SUMS 2&gt;&amp;<span style="color:#a5d6ff">1</span> | grep -q <span style="color:#a5d6ff">&#34;terraform_</span><span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span><span style="color:#a5d6ff">_linux_amd64.zip: OK&#34;</span> <span style="color:#ff7b72;font-weight:bold">||</span> exit <span style="color:#a5d6ff">1</span> <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> unzip terraform_<span style="color:#a5d6ff">${</span><span style="color:#79c0ff">TERRAFORM_VERSION</span><span style="color:#a5d6ff">}</span>_linux_amd64.zip -d /bin <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>    <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> rm -rf /tmp/* <span style="color:#ff7b72;font-weight:bold">&amp;&amp;</span> apk del .sig-check<span style="color:#f85149">
</span></span></span></code></pre></div><p>But the main functionality of Terraform is delivered by provider plugins. It takes time to download the provider: for example, the AWS provider is about 250MB, and in a large scale, with hundreds of Terraform runs per day, this makes a difference.</p>
<p>There are two common ways to deal with it: either use a shared cache available to your pipeline workloads or bake provider binaries into the runtime environment (i.e., Docker image).</p>
<p>The critical element for both approaches is the configuration of the plugin cache directory path. By default, Terraform looks for plugins and downloads them in the <code>.terraform</code> directory, which is local to the main project directory. But you can override this, and you can leverage the <code>TF_PLUGIN_CACHE_DIR</code> environment variable to do that.</p>
<p>If supported by your CI/CD tool, the shared cache can significantly reduce the operational burden because all your pipeline runtime environments can use it to get the needed provider versions.</p>
<p>So all you have to do is to maintain the provider versions in the shared cache and instruct Terraform to use it:</p>
<ul>
<li>Mount the cache directory to the pipeline runtime (i.e., docker container) and specify its internal path</li>
<li>Set the value of the <code>TF_PLUGIN_CACHE_DIR</code> environment variable accordingly</li>
</ul>
<p>On the other hand, you can bake the provider binaries into the Docker image and inject the value for the <code>TF_PLUGIN_CACHE_DIR</code> environment variable right into the Dockerfile.</p>
<div class="attention">
    This approach takes more operational effort <strong>but makes the Terraform environment self-sufficient and stateless</strong>. It also allows you to set strict boundaries around permitted provider versions as a security measure.
</div>
<h1 id="planning-and-applying-changes">Planning and Applying changes</h1>
<p>Now let&rsquo;s review the ways to automate planning and applying of changes. Although <code>terraform apply</code> can do both, it&rsquo;s sometimes useful to separate these actions.</p>
<h2 id="initialization">Initialization</h2>
<p>CI/CD pipelines generally run in stateless environments. Thus, every subsequent run of Terraform looks like a fresh start, so the project needs to be initialized before other actions can be performed.</p>
<p>The usage of the <code>init</code> command in CI/CD slightly differs from its common local usage:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; terraform init -input<span style="color:#ff7b72;font-weight:bold">=</span>false
</span></span></code></pre></div><p>The <code>-input=false</code> option prevents Terraform CLI from asking for user actions (it will throw an error if the input was required).</p>
<p><em>Also, there is <code>-no-color</code> option that prevents the usage of color codes in a shell, so the output will look much cleaner if your CI/CD logging system cannot render the terminal formatting.</em></p>
<p>Another option of the init command that is useful in CI — is the <code>-backend-config</code>. That option allows you to override the backend configuration in your code or define it if you prefer to use partial configuration, thus creating more uniform pipelines.</p>
<p>For example, here is how you can use the same code with different roles in different environments on AWS:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; terraform init -input<span style="color:#ff7b72;font-weight:bold">=</span>false <span style="color:#79c0ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#79c0ff"></span>-backend-config<span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;role_arn=arn:aws:iam::012345678901:role/QADeploymentAutomation&#34;</span>
</span></span></code></pre></div><p>Terraform <code>init</code> produces two artifacts:</p>
<ul>
<li><code>.terraform</code> directory, which Terraform uses to manage cached provider plugins and modules, and record backend information</li>
<li><code>.terraform.lock.hcl</code> file, which Terraform uses to track provider dependencies</li>
</ul>
<p>They both must be present in the project directory to successfully run the subsequent plan and apply commands.</p>
<p>However, I suggest checking in <code>.terraform.lock.hcl</code> to your repository as suggested by HashiCorp (<a href="https://www.terraform.io/docs/language/dependency-lock.html">Dependency Lock File</a>): this way you will be able to control dependencies more thoroughly, and you will not worry about transferring this file between build stages.</p>
<h2 id="plan">Plan</h2>
<p>The  <code>terraform plan</code> command helps you validate the changes manually. However, there are ways to use it in automation as well.</p>
<p>By default, Terraform prints the plan output in a human-friendly format but also supports machine-readable JSON. With additional command-line options, you can extend your CI experience.</p>
<p>For example, you can use your validation conditions to decide whether to apply the changes automatically; or you can parse the plan details and integrate the summary into a Pull Request description. Let’s review a simple example that illustrates it.</p>
<p>First, you need to save the plan output to the file:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; terraform plan -input<span style="color:#ff7b72;font-weight:bold">=</span>false -compact-warnings -out<span style="color:#ff7b72;font-weight:bold">=</span>plan.file
</span></span></code></pre></div><p>The main point here is the <code>-out</code> option — it tells Terraform to save its output into a binary plan file, and we will talk about it in the next paragraph.</p>
<p>The <code>-compact-warnings</code> option suppresses the warning-level messages produced by Terraform.</p>
<p>Also, the <code>plan</code> command has the <code>-detailed-exitcode</code> option that returns detailed exit codes when the command exits. For example, you can leverage this in a script that wraps Terraform and adds more conditional logic to its execution, because CIs will generally fail the pipeline on a command’s non-zero exit code. However, that may add complexity to the pipeline logic.</p>
<p>So if you need to get detailed info about the plan, I suggest parsing the plan output.</p>
<p>When you have a plan file, you can read it in JSON format and parse it. Here is a code snippet that illustrates that:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; terraform show -json plan.file| jq -r <span style="color:#a5d6ff">&#39;([.resource_changes[]?.change.actions?]|flatten)|{&#34;create&#34;:(map(select(.==&#34;create&#34;))|length),&#34;update&#34;:(map(select(.==&#34;update&#34;))|length),&#34;delete&#34;:(map(select(.==&#34;delete&#34;))|length)}&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72;font-weight:bold">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;create&#34;</span>: 1,
</span></span><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;update&#34;</span>: 0,
</span></span><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;delete&#34;</span>: <span style="color:#a5d6ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72;font-weight:bold">}</span>
</span></span></code></pre></div><p>Another way to see the information about changes, is to run the <code>plan</code> command with <code>-json</code> option and parse its output to stdout (available starting from Terraform 1.0.5):</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; terraform plan -json|jq <span style="color:#a5d6ff">&#39;select( .type == &#34;change_summary&#34;)|.&#34;@message&#34;&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#a5d6ff">&#34;Plan: 1 to add, 0 to change, 0 to destroy.&#34;</span>
</span></span></code></pre></div><p><div class="attention">
    This technique can make your Pull Request messages more informative and improve your collaboration with teammates.
</div>
You can write a custom script/function that sends a Pull Request comment to VCS using its API. Or you can try the existing features of your VCS: with GitHub Actions, you can use the <a href="https://github.com/marketplace/actions/terraform-pr-commenter">Terraform PR Commenter</a> or similar action to achieve that; for GitLab, there is a built-in functionality that integrates plan results into the Merge Request — <a href="https://docs.gitlab.com/ee/user/infrastructure/iac/mr_integration.html">Terraform integration in Merge Requests</a>.</p>
<p>You can find more information about the specification of the JSON output here — <a href="https://www.terraform.io/docs/internals/json-format.html">Terraform JSON Output Format</a>.</p>
<h2 id="apply">Apply</h2>
<p>When the plan file is ready, and the proposed changes are expected and approved, it&rsquo;s time to <code>apply</code> them.</p>
<p>Here is how the <code>apply</code> command may look like in automation:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>terraform apply -input<span style="color:#ff7b72;font-weight:bold">=</span>false -compact-warnings plan.file
</span></span></code></pre></div><p>Here, the <code>plan.file</code> is the file we got from the previous plan step.</p>
<p>Alternatively, you might want to omit the planning phase at all. In that case, the following command will apply the configuration immediately, without the need for a plan:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>terraform apply -input<span style="color:#ff7b72;font-weight:bold">=</span>false -compact-warnings -auto-approve
</span></span></code></pre></div><p>Here, the <code>-auto-approve</code> option tells Terraform to create the plan implicitly and skip the interactive approval of that plan before applying.</p>
<p>Whichever way you choose, keep in mind the destructive nature of the apply command. Hence, the fully automated apply of configuration generally works well with environments that tolerate unexpected downtimes, such as development or testing. Whereas plan review is recommended for production-grade environments, and in that case, the <code>apply</code> job is configured for a manual trigger.</p>
<h1 id="dealing-with-stateless-environments">Dealing with stateless environments</h1>
<p>If you run <code>init</code>, <code>plan</code>, and <code>apply</code> commands in different environments, you need to care for some artifacts produced by Terraform:</p>
<ul>
<li>The <code>.terraform</code> directory with information about modules, providers, and the state file (even in the case of remote state).</li>
<li>The <code>.terraform.lock.hcl</code> file — the dependency lock file which Terraform uses to check the integrity of provider versions used for the project. If your VCS does not track it, you&rsquo;ll need to pass that file to the <code>plan</code> and <code>apply</code> commands to make them work after <code>init</code>.</li>
<li>The output file of the <code>plan</code> command is essential for the <code>apply</code> command, so treat it as a vital artifact. This file includes a full copy of the project configuration, the state, and variables passed to the <code>plan</code> command (if any). Therefore, mind the security precautions because sensitive information may be present there.</li>
</ul>
<p>There is one shortcut, though. You can execute the <code>init</code> and <code>plan</code> commands within the same step/stage and transfer the artifacts only once — to the <code>apply</code> execution.</p>
<h1 id="using-the-command-line-and-environments-variables">Using the command-line and environments variables</h1>
<p>Last but not least, a few words about ways to maximize the advantage of variables when running Terraform in CI.</p>
<p>There are two common ways how you can pass values for the variables used in the configuration:</p>
<ol>
<li>Using a <code>-var-file</code> option with the variable definitions file — a filename ending in <code>.tfvars</code> or <code>.tfvars.json</code>. For example:
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>terraform apply -var-file<span style="color:#ff7b72;font-weight:bold">=</span>development.tfvars -input<span style="color:#ff7b72;font-weight:bold">=</span>false -no-color -compact-warnings -auto-approve
</span></span></code></pre></div>Also, Terraform can automatically load the variables from files named exactly <code>terraform.tfvars</code> or <code>terraform.tfvars.json</code>: with that approach, you don’t need to specify the tfvar file as a command option explicitly.</li>
<li>Using environment variables with the prefix <code>TF_VAR_</code>. Implicitly, Terraform always looks for the environment variables (within its process context) with that prefix, so the same &ldquo;instance_type&rdquo; variables from the example above can be passed as follows:
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>export <span style="color:#79c0ff">TF_VAR_instance_type</span><span style="color:#ff7b72;font-weight:bold">=</span>t3.nano
</span></span><span style="display:flex;"><span>terraform -input<span style="color:#ff7b72;font-weight:bold">=</span>false -no-color -compact-warnings -auto-approve
</span></span></code></pre></div></li>
</ol>
<p>The latter method is widely used in CI because modern CI/CD tools support the management of the environment variables for automation jobs.</p>
<p>Please refer to the following official documentation if you want to know more about variables — <a href="https://www.terraform.io/docs/language/values/variables.html">Terraform Input Variables</a>.</p>
<p>Along with that, Terraform supports several configuration parameters in the form of environment variables. These parameters are optional; however, they can simplify the automation management and streamline its code.</p>
<ul>
<li><code>TF_INPUT</code> — when set to &ldquo;false&rdquo; or &ldquo;0&rdquo;, this tells Terraform to behave the same way as with the <code>-input=false</code> flag;</li>
<li><code>TF_CLI_ARGS</code> — can contain a set of command-line options that will be passed to one or another Terraform command. Therefore, the following notation can simplify the execution of <code>apply</code> and <code>plan</code> commands by unifying their options for CI:
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>export <span style="color:#79c0ff">TF_CLI_ARGS</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;-input=false -no-color -compact-warnings&#34;</span>
</span></span><span style="display:flex;"><span>terraform plan ...
</span></span><span style="display:flex;"><span>terraform apply ...
</span></span></code></pre></div>You can advantage this even more when using this variable as the environment configuration of stages or jobs in a CI/CD tool.</li>
<li><code>TF_IN_AUTOMATION</code>  — when set to any non-empty value (e.g., &ldquo;true&rdquo;), Terraform stops suggesting commands run after the one you execute, hence producing less output.</li>
</ul>
<h1 id="key-takeaways">Key takeaways</h1>
<p>There are two primary outcomes from automating Terraform executions: consistent results and integrating with the code or project management solutions. Although the exact implementation of Terraform in CI may vary per project or team, try to aim the following goals when working on it:</p>
<ul>
<li>Ease of code management</li>
<li>A secure and controlled execution environment</li>
<li>Coherent runs of init, plan, apply phases</li>
<li>Leveraging of built-in Terraform capabilities</li>
</ul>
<h5 id="i-originally-wrote-this-article-for-the-spaceliftio-technical-blog-but-i-decided-to-keep-it-here-as-well-for-the-history-the-canonical-link-to-their-blog-has-been-set-accordingly">I originally wrote this article for the Spacelift.io technical blog. But I decided to keep it here as well, for the history. The canonical link to their blog has been set accordingly.</h5>
]]></content:encoded>
    </item>
    <item>
      <title>Apply Cloudfront Security Headers With Terraform</title>
      <link>https://devdosvid.blog/2021/11/05/apply-cloudfront-security-headers-with-terraform/</link>
      <pubDate>Fri, 05 Nov 2021 14:20:58 +0200</pubDate>
      <guid>https://devdosvid.blog/2021/11/05/apply-cloudfront-security-headers-with-terraform/</guid>
      <description>How to use Response Headers Policy and Terraform to configure security headers for CloudFront Distribution</description>
      <content:encoded><![CDATA[<p>In November 2021, AWS announced Response Headers Policies — native support of response headers in CloudFront. You can read the full announcement here: <a href="https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-cloudfront-introduces-response-headers-policies/">Amazon CloudFront introduces Response Headers Policies</a></p>
<p>I said &ldquo;native&rdquo; because previously you could set response headers either using <a href="/2021/05/21/configure-http-security-headers-with-cloudfront-functions.html">CloudFront Functions</a> or <a href="https://aws.amazon.com/blogs/networking-and-content-delivery/adding-http-security-headers-using-lambdaedge-and-amazon-cloudfront/">Lambda@Edge</a>.</p>
<p>And one of the common use cases for that was to set security headers. Now you don&rsquo;t need to add intermediate requests processing to modify the headers: CloudFront does that for you <strong>with no additional fee</strong>.</p>
<h2 id="manage-security-headers-as-code">Manage Security Headers as Code</h2>
<p>Starting from the <a href="https://github.com/hashicorp/terraform-provider-aws/blob/main/CHANGELOG.md#3640-november-04-2021">3.64.0</a> version of Terraform AWS provider, you can create the security headers policies and apply them for your distribution.</p>
<p>Let&rsquo;s see how that looks!</p>
<p>First, you need to describe the <code>aws_cloudfront_response_headers_policy</code> resource:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-hcl" data-lang="hcl"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_cloudfront_response_headers_policy&#34; &#34;security_headers_policy&#34;</span> {
</span></span><span style="display:flex;"><span>  name <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;my-security-headers-policy&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ff7b72">security_headers_config</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">content_type_options</span> {
</span></span><span style="display:flex;"><span>      override <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">frame_options</span> {
</span></span><span style="display:flex;"><span>      frame_option <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;DENY&#34;</span>
</span></span><span style="display:flex;"><span>      override     <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">referrer_policy</span> {
</span></span><span style="display:flex;"><span>      referrer_policy <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;same-origin&#34;</span>
</span></span><span style="display:flex;"><span>      override        <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">xss_protection</span> {
</span></span><span style="display:flex;"><span>      mode_block <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>      protection <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>      override   <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">strict_transport_security</span> {
</span></span><span style="display:flex;"><span>      access_control_max_age_sec <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;63072000&#34;</span>
</span></span><span style="display:flex;"><span>      include_subdomains         <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>      preload                    <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>      override                   <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#ff7b72">content_security_policy</span> {
</span></span><span style="display:flex;"><span>      content_security_policy <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;frame-ancestors &#39;none&#39;; default-src &#39;none&#39;; img-src &#39;self&#39;; script-src &#39;self&#39;; style-src &#39;self&#39;; object-src &#39;none&#39;&#34;</span>
</span></span><span style="display:flex;"><span>      override                <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>List of security headers used:</p>
<ul>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#x-content-type-options">X-Content-Type-Options</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#x-frame-options">X-Frame-Options</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#referrer-policy">Referrer Policy</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#x-xss-protection">X-XSS-Protection</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#http-strict-transport-security">Strict Transport Security</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#content-security-policy">Content Security Policy</a></li>
</ul>
<p>The values for the security headers can be different, of course. However, the provided ones cover the majority of cases. And you can always get the up to date info about these headers and possible values here: <a href="https://infosec.mozilla.org/guidelines/web_security">Mozilla web Security Guidelines</a></p>
<p>Also, you could notice that provided example uses the <code>override</code> argument a lot. The <code>override</code> argument tells CloudFront to set these values for specified headers despite the values received from the origin. This way, you can enforce your security headers configuration.</p>
<p>Once you have the <code>aws_cloudfront_response_headers_policy</code> resource, you can refer to it in the code of <code>aws_cloudfront_distribution</code> resource inside cache behavior block (default or ordered). For example, in your <code>default_cache_behavior</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-hcl" data-lang="hcl"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_cloudfront_distribution&#34; &#34;test&#34;</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#ff7b72">default_cache_behavior</span> {
</span></span><span style="display:flex;"><span>    target_origin_id           <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">aws_s3_bucket</span>.<span style="color:#ff7b72">my_origin</span>.<span style="color:#ff7b72">id</span>
</span></span><span style="display:flex;"><span>    allowed_methods            <span style="color:#ff7b72;font-weight:bold">=</span> [<span style="color:#a5d6ff">&#34;GET&#34;, &#34;HEAD&#34;, &#34;OPTIONS&#34;</span>]
</span></span><span style="display:flex;"><span>    cached_methods             <span style="color:#ff7b72;font-weight:bold">=</span> [<span style="color:#a5d6ff">&#34;GET&#34;, &#34;HEAD&#34;</span>]
</span></span><span style="display:flex;"><span>    viewer_protocol_policy     <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;redirect-to-https&#34;</span><span style="color:#8b949e;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic">    # some arguments skipped from listing for the sake of simplicity
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"></span>    
</span></span><span style="display:flex;"><span>    response_headers_policy_id <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">aws_cloudfront_response_headers_policy</span>.<span style="color:#ff7b72">security_headers_policy</span>.<span style="color:#ff7b72">id</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>  }<span style="color:#8b949e;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic">  # some arguments skipped from listing for the sake of simplicity
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"></span>}
</span></span></code></pre></div><h3 id="security-scan-results">Security Scan Results</h3>
<p>Here is what Mozilla Observatory reports about my test CF distribution where I enabled the policy described above:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/11/05/apply-cloudfront-security-headers-with-terraform/observatory-results_hu_3765cf1f524e3500.webp"
                 alt="Scan summary for CloudFront distribution with security headers policy"width="800"height="903.43" />
        
    
    <figcaption>
        <p>Scan summary for CloudFront distribution with security headers policy
            </p>
    </figcaption>
</figure>

<p>So with just minimum effort, you can greatly boost your web application security posture.</p>
<h3 id="more-to-read">More to read:</h3>
<ul>
<li><a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_response_headers_policy">Terraform Resource: aws_cloudfront_response_headers_policy</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/creating-response-headers-policies.html">Creating response headers policies - Amazon CloudFront</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-response-headers-policies.html">Using the managed response headers policies - Amazon CloudFront</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/understanding-response-headers-policies.html">Understanding response headers policies - Amazon CloudFront</a></li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Auto Scaling Group for your macOS EC2 Instances fleet</title>
      <link>https://devdosvid.blog/2021/10/24/auto-scaling-group-for-your-macos-ec2-instances-fleet/</link>
      <pubDate>Sun, 24 Oct 2021 02:00:31 +0300</pubDate>
      <guid>https://devdosvid.blog/2021/10/24/auto-scaling-group-for-your-macos-ec2-instances-fleet/</guid>
      <description>Scale macOS EC2 Instances fleet with the Licence Manager and ASG services</description>
      <content:encoded><![CDATA[<p>It’s been almost a year since I started using macOS EC2 instances on AWS: there were <a href="/2021/01/19/mac1-metal-EC2-Instance-user-experience.html">ups and downs in service offerings</a> and a lot of discoveries with <a href="/2021/02/01/customizing-mac1-metal-ec2-ami.html">macOS AMI build</a> automation.</p>
<p>And I like this small but so helpful update to the offerings list of the EC2 service: with mac1.metal instances, seamless integration of Apple-oriented CI/CD with other AWS infrastructure could finally happen.</p>
<p>But while management of a single mac1.metal node (or a tiny number of ones) is not a big deal (especially when <a href="/2021/01/20/terraforming-mac1-metal-at-AWS.html">Dedicated Host support</a> was added to Terraform provider), governing the fleet of instances is still complicated.</p>
<p>Or it has been complicated until recent days.</p>
<p>With a growing number of instances, the following challenges arise:</p>
<ul>
<li>Scale mac1.metal instances horizontally</li>
<li>Automatically allocate and release Dedicated Hosts needed for instances</li>
<li>Automatically replace unhealthy instances</li>
</ul>
<p>If you have worked with AWS before, you know that Auto Scaling Group service can solve such things.</p>
<h2 id="auto-scaling-for-macos-ec2-instances">Auto Scaling for macOS EC2 Instances</h2>
<p>So how does all that work?</p>
<p>Let’s review the diagram that illustrates the interconnection between involved services:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/10/24/auto-scaling-group-for-your-macos-ec2-instances-fleet/general-scheme_compressed_hu_2521ced38117a711.webp"
                 alt="Services logical interconnection"width="800"height="639" />
        
    
    <figcaption>
        <p>Services logical interconnection
            </p>
    </figcaption>
</figure>

<p>With the help of Licence Manager service and Launch Templates, you can set up EC2 Auto Scaling Group for mac1.metal and leave the automated instance provisioning to the service.</p>
<h3 id="license-configuration">License Configuration</h3>
<p>First, you need to create a License Configuration so that the Host resource group can allocate the hots.</p>
<p>Go to AWS License Manager -&gt; Customer managed licenses -&gt; Create customer-managed license.</p>
<p>Specify <strong>Sockets</strong> as the Licence type. You may skip setting the Number of Sockets. However, the actual limit of mac1.metal instances per account is regulated by Service Quota. The default number of mac instances allowed per account is 3. Therefore, consider <a href="https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html">increasing</a> this to a more significant number.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/10/24/auto-scaling-group-for-your-macos-ec2-instances-fleet/license-configuration_compressed_hu_822897f09b0f6299.webp"
                 alt="Licence configuration values"width="800"height="807" />
        
    
    <figcaption>
        <p>Licence configuration values
            </p>
    </figcaption>
</figure>

<h3 id="host-resource-group">Host resource group</h3>
<p>Second, create the Host resource group: AWS License Manager -&gt; Host resource groups -&gt; Create host resource group.</p>
<p>When creating the Host resource group, check “<strong>Allocate hosts automatically</strong>” and “<strong>Release hosts automatically</strong>” but leave “Recover hosts automatically” unchecked. Dedicated Host does <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-recovery.html#dedicated-hosts-recovery-instances">not support host recovery</a> for mac1.metal.
However, Auto Scaling Group will maintain the desired number of instances if one fails the health check (which assumes the case of host failure as well).</p>
<p>Also, I recommend specifying “mac1” as an allowed Instance family for the sake of transparent resource management: only this instance type is permitted to allocate hosts in the group.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/10/24/auto-scaling-group-for-your-macos-ec2-instances-fleet/host-resource-group_compressed_hu_ede5f8d90e504b9.webp"
                 alt="Host resource group configuration values"width="800"height="902" />
        
    
    <figcaption>
        <p>Host resource group configuration values
            </p>
    </figcaption>
</figure>

<p>Optionally, you may specify the license association here (the Host group will pick any compatible license) or select the license you created on step one.</p>
<h3 id="launch-template">Launch Template</h3>
<p>Create Launch Template: EC2 -&gt; Launch templates -&gt; Create launch template.</p>
<p>I will skip the description of all Launch Template parameters (but here is a nice <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html">tutorial</a>), if you don’t mind, and keep focus only on the items relevant to the current case.</p>
<p>Specify mac1.metal as the Instance type. Later, in Advanced details: find the <strong>Tenancy</strong> parameter and set it to “Dedicated host”; for <strong>Target host by</strong> select “Host resource group”, and once selected the new parameter <strong>Tenancy host resource group</strong> will appear where you should choose your host group; select your license in <strong>License configurations</strong> parameter.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/10/24/auto-scaling-group-for-your-macos-ec2-instances-fleet/launch-template_compressed_hu_9fe034ef0cdd519d.webp"
                 alt="Launch Template configuration values"width="800"height="741" />
        
    
    <figcaption>
        <p>Launch Template configuration values
            </p>
    </figcaption>
</figure>

<h3 id="auto-scaling-group">Auto Scaling Group</h3>
<p>Finally, create the Auto Scaling Group: EC2 -&gt; Auto Scaling groups -&gt; Create Auto Scaling group.</p>
<p>The vital thing to note here — is the availability of the mac1.metal instance in particular AZ.</p>
<p>Mac instances are available in us-east-1 and <a href="https://aws.amazon.com/about-aws/whats-new/2021/10/amazon-ec2-mac-instances-additional-regions/">7 more regions</a>, but not every Availability Zone in the region supports it. So you must figure out which AZ supports the needed instance type.</p>
<p>There is no documentation for that, but there is an AWS CLI command that can answer this question: <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-instance-type-offerings.html">describe-instance-type-offerings — AWS CLI 2.3.0 Command Reference</a></p>
<p>Here is an example for the us-east-1 region:
<div class="code-snippet">
<details>
<summary markdown="span">Click here to see the code snippet</summary>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; aws ec2 describe-instance-type-offerings --location-type availability-zone-id --filters <span style="color:#79c0ff">Name</span><span style="color:#ff7b72;font-weight:bold">=</span>instance-type,Values<span style="color:#ff7b72;font-weight:bold">=</span>mac1.metal --region us-east-1 --output text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>INSTANCETYPEOFFERINGS	mac1.metal	use1-az6	availability-zone-id
</span></span><span style="display:flex;"><span>INSTANCETYPEOFFERINGS	mac1.metal	use1-az4	availability-zone-id
</span></span></code></pre></div>
</details>
</div></p>
<p>Keep that nuance in mind when selecting a subnet for the mac1.metal instances.</p>
<p>When you know the AZ, specify the respective Subnet in the Auto Scaling Group settings, and you&rsquo;re ready to go!</p>
<h2 id="bring-infrastructure-as-code-here">Bring Infrastructure as Code here</h2>
<p>I suggest describing all that as a code. I prefer Terraform, and its AWS provider supports the needed resources. Except one.</p>
<p>As of October 2021, resources supported :</p>
<ul>
<li><a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/servicequotas_service_quota">aws_servicequotas_service_quota</a></li>
<li><a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/licensemanager_license_configuration">aws_licensemanager_license_configuration</a></li>
<li><a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/launch_template">aws_launch_template</a></li>
<li><a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group">aws_autoscaling_group</a></li>
</ul>
<p>The Host resource group is not yet supported by the provider, unfortunately. However, we can use CloudFormation in Terraform to overcome that: describe the Host resource group as <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudformation_stack">aws_cloudformation_stack</a> Terraform resource using CloudFormation template from a file.</p>
<p>Here is how it looks like:
<div class="code-snippet">
<details>
<summary markdown="span">Click here to see the code snippet</summary>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-hcl" data-lang="hcl"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_licensemanager_license_configuration&#34; &#34;this&#34;</span> {
</span></span><span style="display:flex;"><span>  name                     <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">local</span>.<span style="color:#ff7b72">full_name</span>
</span></span><span style="display:flex;"><span>  license_counting_type    <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;Socket&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_cloudformation_stack&#34; &#34;this&#34;</span> {
</span></span><span style="display:flex;"><span>  name          <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">local</span>.<span style="color:#ff7b72">full_name</span><span style="color:#8b949e;font-style:italic"> # the name of CloudFormation stack
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"></span>  template_body <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">file</span>(<span style="color:#a5d6ff">&#34;${path.module}/resource-group-cf-stack-template.json&#34;</span>)
</span></span><span style="display:flex;"><span>  parameters <span style="color:#ff7b72;font-weight:bold">=</span> {
</span></span><span style="display:flex;"><span>    GroupName <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">local</span>.<span style="color:#ff7b72">full_name</span><span style="color:#8b949e;font-style:italic"> # the name for the Host group, passed to CloudFormation template
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"></span>  }
</span></span><span style="display:flex;"><span>  on_failure <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;DELETE&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
</details>
</div></p>
<p>And the next code snippet explains the CloudFromation template (which is the <code>resource-group-cf-stack-template.json</code> file in the code snippet above)
<div class="code-snippet">
<details>
<summary markdown="span">Click here to see the code snippet</summary>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;Parameters&#34;</span> : {
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;GroupName&#34;</span> : {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;Type&#34;</span> : <span style="color:#a5d6ff">&#34;String&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;Description&#34;</span> : <span style="color:#a5d6ff">&#34;The name of Host Group&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;Resources&#34;</span> : {
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;DedicatedHostGroup&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;Type&#34;</span>: <span style="color:#a5d6ff">&#34;AWS::ResourceGroups::Group&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;Properties&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#7ee787">&#34;Name&#34;</span>: { <span style="color:#7ee787">&#34;Ref&#34;</span>: <span style="color:#a5d6ff">&#34;GroupName&#34;</span> },
</span></span><span style="display:flex;"><span>        <span style="color:#7ee787">&#34;Configuration&#34;</span>: [
</span></span><span style="display:flex;"><span>          {
</span></span><span style="display:flex;"><span>            <span style="color:#7ee787">&#34;Type&#34;</span>: <span style="color:#a5d6ff">&#34;AWS::ResourceGroups::Generic&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#7ee787">&#34;Parameters&#34;</span>: [
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Name&#34;</span>: <span style="color:#a5d6ff">&#34;allowed-resource-types&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Values&#34;</span>: [<span style="color:#a5d6ff">&#34;AWS::EC2::Host&#34;</span>]
</span></span><span style="display:flex;"><span>              },
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Name&#34;</span>: <span style="color:#a5d6ff">&#34;deletion-protection&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Values&#34;</span>: [<span style="color:#a5d6ff">&#34;UNLESS_EMPTY&#34;</span>]
</span></span><span style="display:flex;"><span>              }
</span></span><span style="display:flex;"><span>            ]
</span></span><span style="display:flex;"><span>          },
</span></span><span style="display:flex;"><span>          {
</span></span><span style="display:flex;"><span>            <span style="color:#7ee787">&#34;Type&#34;</span>: <span style="color:#a5d6ff">&#34;AWS::EC2::HostManagement&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#7ee787">&#34;Parameters&#34;</span>: [
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Name&#34;</span>: <span style="color:#a5d6ff">&#34;allowed-host-families&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Values&#34;</span>: [<span style="color:#a5d6ff">&#34;mac1&#34;</span>]
</span></span><span style="display:flex;"><span>              },
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Name&#34;</span>: <span style="color:#a5d6ff">&#34;auto-allocate-host&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Values&#34;</span>: [<span style="color:#a5d6ff">&#34;true&#34;</span>]
</span></span><span style="display:flex;"><span>              },
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Name&#34;</span>: <span style="color:#a5d6ff">&#34;auto-release-host&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Values&#34;</span>: [<span style="color:#a5d6ff">&#34;true&#34;</span>]
</span></span><span style="display:flex;"><span>              },
</span></span><span style="display:flex;"><span>              {
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Name&#34;</span>: <span style="color:#a5d6ff">&#34;any-host-based-license-configuration&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#7ee787">&#34;Values&#34;</span>: [<span style="color:#a5d6ff">&#34;true&#34;</span>]
</span></span><span style="display:flex;"><span>              }
</span></span><span style="display:flex;"><span>            ]
</span></span><span style="display:flex;"><span>          }
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;Outputs&#34;</span> : {
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;ResourceGroupARN&#34;</span> : {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;Description&#34;</span>: <span style="color:#a5d6ff">&#34;ResourceGroupARN&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;Value&#34;</span> : { <span style="color:#7ee787">&#34;Fn::GetAtt&#34;</span> : [<span style="color:#a5d6ff">&#34;DedicatedHostGroup&#34;</span>, <span style="color:#a5d6ff">&#34;Arn&#34;</span>] }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
</details>
</div></p>
<p>The <code>aws_cloudformation_stack</code> resource will export the <code>DedicatedHostGroup</code> attribute (see the code of CloudFromation template), which you will use later in the Launch Template resource.</p>
<div class="attention">
    <p>If you manage an AWS Organization, I have good news: Host groups and Licenses are supported by <a href="https://docs.aws.amazon.com/ram/latest/userguide/shareable.html">Resource Access Manager</a> service.</p>
<p>Hence, you can host all mac instances in one account and share them with other accounts — it might be helpful for costs allocation, for example. Also, check out <a href="/2021/09/25/aws-resource-access-manager-multi-account-resource-governance/">my blog about AWS RAM</a> if you are very new to this service.</p>
<p><br>
And you can leverage the <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ec2_instance_type_offerings">aws_ec2_instance_type_offerings</a> and <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/subnet_ids">aws_subnet_ids</a> data sources to solve the “which AZ supports mac metal” puzzle.</p>

</div>
<h2 id="costs-considerations">Costs considerations</h2>
<p>License Manager is a <a href="https://aws.amazon.com/license-manager/pricing/">free of charge service</a>, as well as <a href="https://aws.amazon.com/autoscaling/pricing/">Auto Scaling</a>, and <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-launch-templates-for-amazon-ec2-instances/">Launch Template</a>.</p>
<p>So it’s all about the price for mac1.metal Dedicated Host which is <a href="https://aws.amazon.com/ec2/dedicated-hosts/pricing/">$1.083 per hour</a> as of October 2021. However, <a href="https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html">Saving Plans</a> can be applied.</p>
<p>Please note that the minimum allocation time for that type of host is 24 hours. Maybe someday AWS will change that to 1-hour minimum someday (fingers crossed).</p>
<h2 id="oh-so-asg">Oh. So. ASG.</h2>
<p>The Auto Scaling for mac1.metal opens new possibilities for CI/CD: you can integrate that to your favorite tool (GitLab, Jenkins, whatsoever) using AWS Lambda and provision new instances when your development/testing environments need that.</p>
<p>Or you can use other cool ASG stuff, such as Lifecycle hooks, to create even more custom scenarios.</p>
<p>Also, I want to say thanks (thanks, pal!) to <a href="https://github.com/hashicorp/terraform/issues/28531">OliverKoo</a>, who started digging into that back in April'21.</p>
]]></content:encoded>
    </item>
    <item>
      <title>AWS Resource Access Manager — Multi Account Resource Governance</title>
      <link>https://devdosvid.blog/2021/09/25/aws-resource-access-manager-multi-account-resource-governance/</link>
      <pubDate>Sat, 25 Sep 2021 00:54:23 +0300</pubDate>
      <guid>https://devdosvid.blog/2021/09/25/aws-resource-access-manager-multi-account-resource-governance/</guid>
      <description>Provision and manage resources within the AWS Organization with ease</description>
      <content:encoded><![CDATA[<p>With a multi-account approach of building the infrastructure, there is always a challenge of provision and governance of the resources to subordinate accounts within the Organization. Provision resources, keep them up to date, and decommission them properly — that&rsquo;s only a part of them.</p>
<p>AWS has numerous solutions that help make this process reliable and secure, and the Resource Access Manager (RAM) is one of them.
In a nutshell, the RAM service allows you to share the AWS resources you create in one AWS account with other AWS accounts. They can be your organizations&rsquo; accounts, organizational units (OU), or even third-party accounts.</p>
<p>So let&rsquo;s see what the RAM is and review some of its usage examples.</p>
<h2 id="why-using-ram">Why using RAM</h2>
<p>There are several benefits of using the RAM service:</p>
<ol>
<li>
<p><strong>Reduced operational overhead</strong>: eliminate the need of provisioning the same kind of resource multiple times — RAM does that for you</p>
</li>
<li>
<p><strong>Simplified security management</strong>: AWS RAM-managed permissions (at least one per resource type) define the actions that principals with access to the resources (i.e., resource users) can perform on those resources.</p>
</li>
<li>
<p><strong>Consistent experience</strong>: you share the resource in its state and with its security configuration with an arbitrary number of accounts.</p>
<p>That plays incredibly well in the case of organization-wide sharing: new accounts get the resources automatically. And the shared resource itself looks like a native resource in the account that accepts your sharing.</p>
</li>
<li>
<p><strong>Audit and visibility</strong>: RAM integrates with the CloudWatch and CloudTrail.</p>
</li>
</ol>
<h2 id="how-to-share-a-resource">How to share a resource</h2>
<p>When you share a resource, the AWS account that owns that resource retains full ownership of the resource.</p>
<p>Sharing of the resource doesn&rsquo;t change any permissions or quotas that apply to that resource. Also, you can share the resource only if you own it.</p>
<p>Availability of the shared resources scopes to the Region: the users of your shared resources can access these resources only in the same Region where resources belong.</p>
<p>Creation of resource share consists of three steps:
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/09/25/aws-resource-access-manager-multi-account-resource-governance/ram-diagram-800_hu_61c844392dd27e46.webp"width="800"height="533" />
        
    
</figure>
</p>
<ol>
<li>
<p>Specify the share name and the resource(s) you want to share. It can be either one resource type or several. You can also skip the resources selection and do that later.</p>
<p>It&rsquo;s possible to modify the resource share later (e.g., you want to add some resources to the share).</p>
</li>
<li>
<p>Associate permissions with resource types you share. Some resources can have only one managed permission (will be attached automatically), and some can have multiple.</p>
<p>You can check the Permissions Library in the AWS RAM Console to see what managed permissions are available.</p>
</li>
<li>
<p>Select who can use the resources you share: either external or Organization account or IAM role/user. If you share the resource with third parties, they will have to accept the sharing explicitly.</p>
<p>Organization-wide resource share is accepted implicitly if resource sharing is enabled for the Organization.</p>
</li>
</ol>
<p>Finally, review the summary page of the resource share and create it.</p>
<p>Only specific actions are available to the users of shared resources. These actions mostly have the &ldquo;read-only&rdquo; nature and <a href="https://docs.aws.amazon.com/ram/latest/userguide/shareable.html">vary by resource type</a>.</p>
<p>Also, the RAM service is <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ram_resource_share">supported by Terraform</a>, so the resource sharing configuration may look like that, for example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-hcl" data-lang="hcl"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_ram_resource_share&#34; &#34;example&#34;</span> {
</span></span><span style="display:flex;"><span>  name                      <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;example&#34;</span>
</span></span><span style="display:flex;"><span>  allow_external_principals <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  tags <span style="color:#ff7b72;font-weight:bold">=</span> {
</span></span><span style="display:flex;"><span>    Environment <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;Production&#34;</span>
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_ram_resource_association&#34; &#34;example&#34;</span> {
</span></span><span style="display:flex;"><span>  resource_arn       <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">aws_subnet</span>.<span style="color:#ff7b72">example</span>.<span style="color:#ff7b72">arn</span>
</span></span><span style="display:flex;"><span>  resource_share_arn <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">aws_ram_resource_share</span>.<span style="color:#ff7b72">example</span>.<span style="color:#ff7b72">arn</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="example-use-cases">Example use cases</h2>
<p>One of the trivial but valuable examples of RAM service usage is sharing a Manged Prefix List.
Suppose you have some service user across your Organization, a self-hosted VPN server, for example. And you have a static set of IPs for that VPN: you trust these IPs and would like them to be allow-listed in your other services.
How to report these IPs to all organization accounts/users? And if the IP set changes, how to announce that change, and what should be done to reflect that change in services that depend on it, for example, Security Groups?</p>
<p>The answer is a shared <a href="https://docs.aws.amazon.com/vpc/latest/userguide/managed-prefix-lists.html#managed-prefix-lists-concepts">Managed Prefix List</a>. You create the list once in the account and share it across your Organization. Other accounts automatically get access to that list and can reference the list in their Security Groups. And when the list entry is changed, they do not need to perform any actions: their Security Groups will get the updated IPs implicitly.</p>
<p>Another everyday use case of RAM is the VPC sharing that can form the foundation of the <a href="https://aws.amazon.com/blogs/networking-and-content-delivery/vpc-sharing-a-new-approach-to-multiple-accounts-and-vpc-management/">multi-account AWS architectures</a>.</p>
<hr>
<p>Of course, the RAM service is not the only way to organize and centralize resource management in AWS. There are Service Catalog, Control Tower, Systems Manager, Config, and others. However, the RAM is relatively simple to adopt but is capable of providing worthy outcomes.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Run Ansible playbook on Mac EC2 Instances fleet with AWS Systems Manager</title>
      <link>https://devdosvid.blog/2021/05/27/run-ansible-playbook-on-mac-ec2-instances-fleet-with-aws-systems-manager/</link>
      <pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
      <guid>https://devdosvid.blog/2021/05/27/run-ansible-playbook-on-mac-ec2-instances-fleet-with-aws-systems-manager/</guid>
      <description>Configuration management for mac1.metal and mac2.metal AWS Instances</description>
      <content:encoded><![CDATA[<p>In days of containers and serverless applications, Ansible looks not such a trendy thing.</p>
<p>But still, there are cases when it helps, and there are cases when it combines very well with brand new product offerings, such as EC2 Mac instances.</p>
<p>The <a href="/2021/02/01/customizing-mac1-metal-ec2-ami.html">more I use mac1.metal</a> in AWS, the more I see that Ansible becomes a bedrock of software customization in my case.</p>
<p>And when you have a large instances fleet, the AWS Systems Manager becomes your best friend (the sooner you get along together, the better).</p>
<p>So is it possible to use Ansible playbooks for mac1.metal on a big scale, with the help of AWS Systems Manager?</p>
<h2 id="not-available-out-of-the-box">(Not) Available out of the box</h2>
<p>AWS Systems Manager (SSM hereafter) has a pre-defined, shared Document that allows running Ansible playbooks.</p>
<p>It’s called “AWS-RunAnsiblePlaybook,” and you can find it in AWS SSM → Documents → Owned by Amazon.</p>
<p>However, this Document is not quite “friendly” to macOS. When the SSM agent calls Ansible on the Mac EC2 instance, it does not recognize the Ansible installed with Homebrew (de-facto most used macOS package manager).</p>
<p>So if you try to run a command on the mac1.metal instance using this Document, you will get the following error:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>Ansible is not installed. Please install Ansible and rerun the command.
</span></span></code></pre></div><p>The root cause is trivial: the path to Ansible binary is not present on the list of paths available to the SSM agent by default.</p>
<p>There are several ways to solve that, but I believe that the most convenient one would be to create your custom Document — a slightly adjusted version of the default one provided by AWS.</p>
<h2 id="creating-own-ssm-document-for-ansible-installed-with-homebrew">Creating own SSM Document for Ansible installed with Homebrew</h2>
<p>All you need to do is clone the Document provided by AWS and change its code a little — replace the callouts of <code>ansible</code> with the full path to the binary.</p>
<p>Navigate to AWS SSM → Documents → Owned by Amazon and type <code>AWS-RunAnsiblePlaybook</code> in the search field.</p>
<p>Select the Document by pressing the circle on its top-right corner and then click Actions → Clone document.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/27/run-ansible-playbook-on-mac-ec2-instances-fleet-with-aws-systems-manager/aws_ssm_document_clone_hu_839ae658a5a61deb.webp"width="800"height="476.68" />
        
    
</figure>

<p>Give the new SSM Document a name, e.g., <code>macos-arbitrary-ansible-playbook</code>, and change the <code>ansible</code> callouts (at the end of the code) with the full path to the ansible symlink made by Homebrew which is <code>/usr/local/bin/ansible</code></p>
<p>Here is the complete source code of the Document with adjusted Ansible path:</p>
<div class="code-snippet">
<details>
<summary markdown="span">Click here to see the code snippet</summary>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;schemaVersion&#34;</span>: <span style="color:#a5d6ff">&#34;2.0&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;description&#34;</span>: <span style="color:#a5d6ff">&#34;Use this document to run arbitrary Ansible playbooks on macOS EC2 instances. Specify either YAML text or URL. If you specify both, the URL parameter will be used. Use the extravar parameter to send runtime variables to the Ansible execution. Use the check parameter to perform a dry run of the Ansible execution. The output of the dry run shows the changes that will be made when the playbook is executed.&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;parameters&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;playbook&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;type&#34;</span>: <span style="color:#a5d6ff">&#34;String&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;description&#34;</span>: <span style="color:#a5d6ff">&#34;(Optional) If you don&#39;t specify a URL, then you must specify playbook YAML in this field.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;default&#34;</span>: <span style="color:#a5d6ff">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;displayType&#34;</span>: <span style="color:#a5d6ff">&#34;textarea&#34;</span>
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;playbookurl&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;type&#34;</span>: <span style="color:#a5d6ff">&#34;String&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;description&#34;</span>: <span style="color:#a5d6ff">&#34;(Optional) If you don&#39;t specify playbook YAML, then you must specify a URL where the playbook is stored. You can specify the URL in the following formats: http://example.com/playbook.yml  or s3://examplebucket/plabook.url. For security reasons, you can&#39;t specify a URL with quotes.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;default&#34;</span>: <span style="color:#a5d6ff">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;allowedPattern&#34;</span>: <span style="color:#a5d6ff">&#34;^\\s*$|^(http|https|s3)://[^&#39;]*$&#34;</span>
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;extravars&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;type&#34;</span>: <span style="color:#a5d6ff">&#34;String&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;description&#34;</span>: <span style="color:#a5d6ff">&#34;(Optional) Additional variables to pass to Ansible at runtime. Enter a space separated list of key/value pairs. For example: color=red or fruits=[apples,pears]&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;default&#34;</span>: <span style="color:#a5d6ff">&#34;foo=bar&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;displayType&#34;</span>: <span style="color:#a5d6ff">&#34;textarea&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;allowedPattern&#34;</span>: <span style="color:#a5d6ff">&#34;^((^|\\s)\\w+=(\\S+|&#39;.*&#39;))*$&#34;</span>
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;check&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;type&#34;</span>: <span style="color:#a5d6ff">&#34;String&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;description&#34;</span>: <span style="color:#a5d6ff">&#34; (Optional) Use the check parameter to perform a dry run of the Ansible execution.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;allowedValues&#34;</span>: [
</span></span><span style="display:flex;"><span>        <span style="color:#a5d6ff">&#34;True&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#a5d6ff">&#34;False&#34;</span>
</span></span><span style="display:flex;"><span>      ],
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;default&#34;</span>: <span style="color:#a5d6ff">&#34;False&#34;</span>
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>    <span style="color:#7ee787">&#34;timeoutSeconds&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;type&#34;</span>: <span style="color:#a5d6ff">&#34;String&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;description&#34;</span>: <span style="color:#a5d6ff">&#34;(Optional) The time in seconds for a command to be completed before it is considered to have failed.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;default&#34;</span>: <span style="color:#a5d6ff">&#34;3600&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#7ee787">&#34;mainSteps&#34;</span>: [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;action&#34;</span>: <span style="color:#a5d6ff">&#34;aws:runShellScript&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;name&#34;</span>: <span style="color:#a5d6ff">&#34;runShellScript&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#7ee787">&#34;inputs&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#7ee787">&#34;timeoutSeconds&#34;</span>: <span style="color:#a5d6ff">&#34;{{ timeoutSeconds }}&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#7ee787">&#34;runCommand&#34;</span>: [
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;#!/bin/bash&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;/usr/local/bin/ansible --version&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;if [ $? -ne 0 ]; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; echo \&#34;Ansible is not installed. Please install Ansible and rerun the command\&#34; &gt;&amp;2&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; exit 1&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;fi&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;execdir=$(dirname $0)&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;cd $execdir&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;if [ -z &#39;{{playbook}}&#39; ] ; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; if [[ \&#34;{{playbookurl}}\&#34; == http* ]]; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   wget &#39;{{playbookurl}}&#39; -O playbook.yml&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   if [ $? -ne 0 ]; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;       echo \&#34;There was a problem downloading the playbook. Make sure the URL is correct and that the playbook exists.\&#34; &gt;&amp;2&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;       exit 1&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   fi&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; elif [[ \&#34;{{playbookurl}}\&#34; == s3* ]] ; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   aws --version&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   if [ $? -ne 0 ]; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;       echo \&#34;The AWS CLI is not installed. The CLI is required to process Amazon S3 URLs. Install the AWS CLI and run the command again.\&#34; &gt;&amp;2&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;       exit 1&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   fi&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   aws s3 cp &#39;{{playbookurl}}&#39; playbook.yml&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   if [ $? -ne 0 ]; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;       echo \&#34;Error while downloading the document from S3\&#34; &gt;&amp;2&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;       exit 1&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   fi&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; else&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   echo \&#34;The playbook URL is not valid. Verify the URL and try again.\&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; fi&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;else&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34; echo &#39;{{playbook}}&#39; &gt; playbook.yml&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;fi&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;if  [[ \&#34;{{check}}\&#34; == True ]] ; then&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   /usr/local/bin/ansible-playbook -i \&#34;localhost,\&#34; --check -c local -e \&#34;{{extravars}}\&#34; playbook.yml&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;else&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;   /usr/local/bin/ansible-playbook -i \&#34;localhost,\&#34; -c local -e \&#34;{{extravars}}\&#34; playbook.yml&#34;</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a5d6ff">&#34;fi&#34;</span>
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
</details>
</div>
<h2 id="applying-ansible-playbook-to-the-fleet-of-mac1metal">Applying Ansible playbook to the fleet of mac1.metal</h2>
<p>Let’s give our new SSM Document a try! (I suppose you have at least one mac1 instance running, right?)</p>
<p>In AWS SSM, go to the Run Command feature, then click on the Run Command button.</p>
<p>On the new panel, type the name of your Document (<code>macos-arbitrary-ansible-playbook</code> in this example) in the search field and press enter.</p>
<p>Select the Document, and you’ll see its parameters and settings.</p>
<p>The rest is self-explanatory. Enter either a playbook code or a link to the source file, add extra variables if needed, and select the target host or a filtered bunch (I like that feature with tags filtering!). Finally, click on the “Run” orange button to apply your playbook.</p>
<p>That’s it! Now you can make all your ansible-playbook dreams come true! 😁</p>
]]></content:encoded>
    </item>
    <item>
      <title>Configure HTTP Security headers with CloudFront Functions</title>
      <link>https://devdosvid.blog/2021/05/21/configure-http-security-headers-with-cloudfront-functions/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      <guid>https://devdosvid.blog/2021/05/21/configure-http-security-headers-with-cloudfront-functions/</guid>
      <description>Modifying response headers to enforce the security of the web application</description>
      <content:encoded><![CDATA[<div class="updatenotice">
    <p>In November 2021, AWS has added this functionality as a native CloudFront feature.</p>
<p>I suggest switching to the native implementation. I have described how to configure Security Response Headers for CloudFront in the following article:</p>
<p><a href="/2021/11/05/apply-cloudfront-security-headers-with-terraform/">Apply Cloudfront Security Headers With Terraform</a></p>

</div>
<p>A couple of weeks ago, AWS released CloudFront Functions — a “true edge” compute capability for the CloudFront.</p>
<p>It is “true edge” because Functions work on 200+ edge locations (<a href="https://aws.amazon.com/cloudfront/features/?whats-new-cloudfront.sort-by=item.additionalFields.postDateTime&amp;whats-new-cloudfront.sort-order=desc#Edge_Computing">link to doc</a>) while its predecessor, the Lambda@Edge, runs on a small number of regional edge caches.</p>
<p>One of the use cases for Lambda@Edge was adding security HTTP headers (it’s even listed on the <a href="https://aws.amazon.com/lambda/edge/">product page</a>), and now there is one more way to make it using CloudFront Functions.</p>
<div class="beehiiv-subscribe-container">
    <h3>Subscribe to blog updates!</h3>
    <iframe src="https://embeds.beehiiv.com/60009a3f-3202-4ac0-85f8-0d3db1ea781b?slim=true" data-test-id="beehiiv-embed"
        height="52" frameborder="0" scrolling="no"
        style="margin: 0; border-radius: 0px !important; background-color: transparent;"></iframe>
</div>
<h2 id="what-are-security-headers-and-why-it-matters">What are security headers, and why it matters</h2>
<p>Security Headers are one of the web security pillars.</p>
<p>They specify security-related information of communication between a web application (i.e., website) and a client (i.e., browser) and protect the web app from different types of attacks. Also, HIPAA and PCI, and other security standard certifications generally include these headers in their rankings.</p>
<p>We will use CloudFront Functions to set the following headers:</p>
<ul>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#content-security-policy">Content Security Policy</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#http-strict-transport-security">Strict Transport Security</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#x-content-type-options">X-Content-Type-Options</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#x-xss-protection">X-XSS-Protection</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#x-frame-options">X-Frame-Options</a></li>
<li><a href="https://infosec.mozilla.org/guidelines/web_security#referrer-policy">Referrer Policy</a></li>
</ul>
<p>You can find a short and detailed explanation for each security header on <a href="https://infosec.mozilla.org/guidelines/web_security">Web Security cheatsheet made by Mozilla</a></p>
<h2 id="cloudfront-functions-overview">CloudFront Functions overview</h2>
<p>In a nutshell, CloudFront Functions allow performing simple actions against HTTP(s) request (from the client) and response (from the CloudFront cache at the edge). Functions take less than one millisecond to execute, support JavaScript (ECMAScript 5.1 compliant), and cost $0.10 per 1 million invocations.</p>
<p>Every CloudFront distribution has one (default) or more Cache behaviors, and Functions can be associated with these behaviors to execute upon a specific event.</p>
<p>That is how the request flow looks like in general, and here is where CloudFront Functions execution happens:</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/request_flow_hu_43cf1ab5a9c11148.webp"width="800"height="171.67" />
        
    
</figure>

<p>CloudFront Functions support Viewer Request (after CloudFront receives a request from a client) and Viewer Response (before CloudFront forwards the response to the client) events.</p>
<p>You can read more about the events types and their properties here — <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-cloudfront-trigger-events.html">CloudFront Events That Can Trigger a Lambda Function - Amazon CloudFront</a>.</p>
<p>Also, the CloudFront Functions allow you to manage and operate the code and lifecycle of the functions directly from the CloudFront web interface.</p>
<h2 id="solution-overview">Solution overview</h2>
<p>CloudFront distribution should exist before Function creation so you could associate the Function with the distribution.</p>
<p>Creation and configuration of the CloudFront Function consist of the following steps:</p>
<h3 id="create-function">Create Function</h3>
<p>In the AWS Console, open CloudFront service and lick on the Functions on the left navigation bar, then click Create function button.
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/create_function_hu_ee88251566b369ea.webp"width="800"height="255.83" />
        
    
</figure>

Enter the name of your Function (e.g., “security-headers”) and click Continue.</p>
<h3 id="build-function">Build Function</h3>
<p>On the function settings page, you will see four tabs with the four lifecycle steps: Build, Test, Publish, Associate.</p>
<p>Paste the function code into the editor and click “Save.”</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/function_editor_hu_40a83a96f9ed0cce.webp"width="800"height="467.84" />
        
    
</figure>

<p>Here is the source code of the function:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-javascript" data-lang="javascript"><span style="display:flex;"><span><span style="color:#ff7b72">function</span> handler(event) {
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">var</span> response <span style="color:#ff7b72;font-weight:bold">=</span> event.response;
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">var</span> headers <span style="color:#ff7b72;font-weight:bold">=</span> response.headers;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>headers[<span style="color:#a5d6ff">&#39;strict-transport-security&#39;</span>] <span style="color:#ff7b72;font-weight:bold">=</span> { value<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#39;max-age=63072000; includeSubdomains; preload&#39;</span>}; 
</span></span><span style="display:flex;"><span>headers[<span style="color:#a5d6ff">&#39;content-security-policy&#39;</span>] <span style="color:#ff7b72;font-weight:bold">=</span> { value<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#34;default-src &#39;none&#39;; img-src &#39;self&#39;; script-src &#39;self&#39;; style-src &#39;self&#39;; object-src &#39;none&#39;; frame-ancestors &#39;none&#39;&#34;</span>}; 
</span></span><span style="display:flex;"><span>headers[<span style="color:#a5d6ff">&#39;x-content-type-options&#39;</span>] <span style="color:#ff7b72;font-weight:bold">=</span> { value<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#39;nosniff&#39;</span>}; 
</span></span><span style="display:flex;"><span>headers[<span style="color:#a5d6ff">&#39;x-xss-protection&#39;</span>] <span style="color:#ff7b72;font-weight:bold">=</span> {value<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#39;1; mode=block&#39;</span>};
</span></span><span style="display:flex;"><span>headers[<span style="color:#a5d6ff">&#39;referrer-policy&#39;</span>] <span style="color:#ff7b72;font-weight:bold">=</span> {value<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#39;same-origin&#39;</span>};
</span></span><span style="display:flex;"><span>headers[<span style="color:#a5d6ff">&#39;x-frame-options&#39;</span>] <span style="color:#ff7b72;font-weight:bold">=</span> {value<span style="color:#ff7b72;font-weight:bold">:</span> <span style="color:#a5d6ff">&#39;DENY&#39;</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">return</span> response;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="test-function">Test Function</h3>
<p>Open the “Test” tab — let’s try our function first before it becomes live!</p>
<p>Select Viewer Response event type and Development Stage, then select “Viewer response with headers” as a Sample test event (you will get a simple set of headers automatically).</p>
<p>Now click the blue “Test” button and observe the output results:</p>
<ul>
<li>Compute utilization represents the relative amount of time (on a scale between 0 and 100) your function took to run</li>
<li>Check the Response headers tab and take a look at how the function added custom headers.</li>
</ul>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/function_test_hu_306411e918e14934.webp"width="800"height="624.03" />
        
    
</figure>

<h3 id="publish-function">Publish Function</h3>
<p>Let’s publish our function. To do that, open the Publish tab and click on the blue button “Publish and update.”
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/function_publish_hu_fb5339ed1832c607.webp"width="800"height="257.24" />
        
    
</figure>
</p>
<h3 id="associate-your-function-with-cloudfront-distribution">Associate your Function with CloudFront distribution</h3>
<p>Now, you can associate the function with the CloudFront distribution.</p>
<p>To do so, open the Associate tab, select the distribution and event type (Viewer Response), and select the Cache behavior of your distribution which you want to use for the association.</p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/function_associate_hu_98f37d7aa4670bc6.webp"width="800"height="366.08" />
        
    
</figure>

<p>Once you associate the function with the CloudFront distribution, you can test it in live mode.</p>
<p>I will use curl here to demonstrate it:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>&gt; curl -i https://d30i87a4ss9ifz.cloudfront.net
</span></span><span style="display:flex;"><span>HTTP/2 <span style="color:#a5d6ff">200</span>
</span></span><span style="display:flex;"><span>content-type: text/html
</span></span><span style="display:flex;"><span>content-length: <span style="color:#a5d6ff">140</span>
</span></span><span style="display:flex;"><span>date: Sat, <span style="color:#a5d6ff">22</span> May <span style="color:#a5d6ff">2021</span> 00:22:18 GMT
</span></span><span style="display:flex;"><span>last-modified: Tue, <span style="color:#a5d6ff">27</span> Apr <span style="color:#a5d6ff">2021</span> 23:07:14 GMT
</span></span><span style="display:flex;"><span>etag: <span style="color:#a5d6ff">&#34;a855a3189f8223db53df8a0ca362dd62&#34;</span>
</span></span><span style="display:flex;"><span>accept-ranges: bytes
</span></span><span style="display:flex;"><span>server: AmazonS3
</span></span><span style="display:flex;"><span>via: 1.1 50f21cb925e6471490e080147e252d7d.cloudfront.net <span style="color:#ff7b72;font-weight:bold">(</span>CloudFront<span style="color:#ff7b72;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>content-security-policy: default-src <span style="color:#a5d6ff">&#39;none&#39;</span>; img-src <span style="color:#a5d6ff">&#39;self&#39;</span>; script-src <span style="color:#a5d6ff">&#39;self&#39;</span>; style-src <span style="color:#a5d6ff">&#39;self&#39;</span>; object-src <span style="color:#a5d6ff">&#39;none&#39;</span>; frame-ancestors <span style="color:#a5d6ff">&#39;none&#39;</span>
</span></span><span style="display:flex;"><span>strict-transport-security: max-age<span style="color:#ff7b72;font-weight:bold">=</span>63072000; includeSubdomains; preload
</span></span><span style="display:flex;"><span>x-xss-protection: 1; <span style="color:#79c0ff">mode</span><span style="color:#ff7b72;font-weight:bold">=</span>block
</span></span><span style="display:flex;"><span>x-frame-options: DENY
</span></span><span style="display:flex;"><span>referrer-policy: same-origin
</span></span><span style="display:flex;"><span>x-content-type-options: nosniff
</span></span><span style="display:flex;"><span>x-cache: Miss from cloudfront
</span></span><span style="display:flex;"><span>x-amz-cf-pop: WAW50-C1
</span></span><span style="display:flex;"><span>x-amz-cf-id: ud3qH8rLs7QmbhUZ-DeupGwFhWLpKDSD59vr7uWC65Hui5m2U8o2mw<span style="color:#ff7b72;font-weight:bold">==</span>
</span></span></code></pre></div><p>You can also test your results here — <a href="https://observatory.mozilla.org/">Mozilla Observatory</a></p>
<p><figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/scan_result-1_hu_61d50af533207c47.webp"width="800"height="345.58" />
        
    
</figure>

<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/05/21/configure-http-security-headers-with-cloudfront-functions/scan_result-2_hu_ca4fc1a66c94e7.webp"width="800"height="626.15" />
        
    
</figure>
</p>
<h2 id="read-more">Read more</h2>
<p>That was a simplified overview of the CloudFront Functions capabilities.</p>
<p>But if you want to get deeper, here is a couple of useful links to start:</p>
<ul>
<li>Another overview from AWS — <a href="https://aws.amazon.com/blogs/aws/introducing-cloudfront-functions-run-your-code-at-the-edge-with-low-latency-at-any-scale">CloudFront Functions Launch Blog</a></li>
<li>More about creating, testing, updating and publishing of CloudFront Functions — <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/managing-functions.html">Managing functions in CloudFront Functions - Amazon CloudFront</a></li>
</ul>
<h2 id="so-what-to-choose">So what to choose?</h2>
<p>CloudFront Functions are simpler than Lambda@Edge and run faster with minimal latency and minimal time penalty for your web clients.</p>
<p>Lambda@Edge takes more time to invoke, but it can run upon Origin Response event so that CloudFront can cache the processed response (including headers) and return it faster afterward.</p>
<p>But again, the CloudFront Functions invocations are much cheaper (6x times) than Lambda@Edge, and you do not pay for the function execution duration.</p>
<p>The final decision would also depend on the dynamic/static nature of the content you have at your origin.</p>
<p>To make a wise and deliberate decision, try to analyze your use case using these two documentation articles:</p>
<ul>
<li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/edge-functions.html">Choosing between CloudFront Functions and Lambda@Edge</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-how-to-choose-event.html">How to Decide Which CloudFront Event to Use to Trigger a Lambda Function</a></li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Using TinyPNG Image Compression From MacOS Finder Contextual Menu</title>
      <link>https://devdosvid.blog/2021/02/14/using-tinypng-image-compression-from-macos-finder-contextual-menu/</link>
      <pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://devdosvid.blog/2021/02/14/using-tinypng-image-compression-from-macos-finder-contextual-menu/</guid>
      <description>How to add TinyPNG image compression to your macOS Finder contextual menu</description>
      <content:encoded><![CDATA[<p>I just wanted to compress one image, but went to far&hellip;</p>
<p>or &ldquo;How to add TinyPNG image compression to your macOS Finder contextual menu.&rdquo;</p>
<h1 id="what-is-it-and-how-it-works">What is it and how it works</h1>
<p>You select needed files or folders, then right-click on them, click on the Services menu item and choose TinyPNG.</p>
<p>After a moment, the new optimized versions of images will appear near to original files.</p>
<p>If you selected a folder along with the files, the script would process all <code>png</code> and <code>jpeg</code> files in it.</p>
<video class="animation" autoplay loop muted playsinline>
    <source src="context_menu_full_compressed.webm" type="video/webm">
</video>


<h1 id="prerequisites">Prerequisites</h1>
<p>You need to register at TinyPNG and get your API key here — <a href="https://tinypng.com/developers">Developer API</a>.</p>
<p>They sometimes block some countries (for example, Ukraine) from registration; in that case, try to use a web-proxy or VPN.</p>
<h1 id="how-to-create-quick-action-workflow">How to create Quick Action Workflow</h1>
<p>Open Automator application. If you never used this app before, please read about it on the official <a href="https://support.apple.com/guide/automator/create-a-workflow-aut7cac58839/2.10/mac/11.0">user guide website</a>.</p>
<p>On the New Action screen, chose <strong>Quick Action</strong></p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/02/14/using-tinypng-image-compression-from-macos-finder-contextual-menu/quick_action_compressed_hu_d549db512e665eee.webp"width="800"height="695.62" />
        
    
</figure>

<p>After you click the &ldquo;Choose&rdquo; button, you&rsquo;ll see the workflow configuration window.</p>
<h1 id="workflow-configuration">Workflow configuration</h1>
<p>Find the <strong>Run Shell Script</strong> action on the Utilities list in Library on the left, and drag it onto the right side of the panel.</p>
<p>Set the following workflow configuration options as described below:</p>
<p><strong>Workflow receives current</strong> <code>files and folders</code> <strong>in</strong> <code>Finder</code></p>
<p><strong>Shell</strong> <code>/bin/zsh</code></p>
<p><strong>Pass input</strong> <code>as arguments</code></p>
<p>Click the <strong>Option</strong> button at the bottom of the Action window and <strong>Uncheck</strong> <code>Show this action when the workflow runs.</code></p>
<figure>
    
    
        
        
        
        
        
        
        <img loading="lazy"
             src="/2021/02/14/using-tinypng-image-compression-from-macos-finder-contextual-menu/run_shell_script_compressed_hu_903fc6746a0e59fa.webp"width="800"height="702.36" />
        
    
</figure>

<p>Put the following script into the <strong>Run Shell Script</strong> window, replacing the <em>YOUR_API_KEY_HERE</em> string with your API key obtained from TinyPNG.</p>
<script src="https://gist.github.com/vasylenko/13cb423aa83265e79ac5ad900195603f.js"></script>
<h2 id="utilities-used-in-the-script--explained">Utilities used in the script — explained</h2>
<p><code>curl</code> — used to make web requests (like your browser does)</p>
<p><code>grep</code> — used to parse the response for the needed header (i.e., field) with the file download link</p>
<p><code>cut</code> — used to extract the URL from the parsed result</p>
<p><code>sed</code> — used to remove the trailing &ldquo;carriage return&rdquo; symbol at the end of extracted string</p>
<p>The response body also contains a JSON object that includes the download URL; you can parse it with <code>jq</code>, for example. But I intentionally refused to use the <code>jq</code> tool because it is not pre-installed in MacOS.</p>
<h1 id="conclusion">Conclusion</h1>
<p>It is simple, and it does its job fine. And you don&rsquo;t need to install anything to make it work.</p>
<p>To make this a bit fancier, you might also like to add a &ldquo;Display Notification&rdquo; (from the Utilities library on the left) after the &ldquo;Run Shell Script&rdquo;. The action will display a notification once image processing is completed.</p>
<p>Thank you for reading!</p>
]]></content:encoded>
    </item>
    <item>
      <title>Customizing mac1.metal EC2 AMI — new guts, more glory</title>
      <link>https://devdosvid.blog/2021/02/01/customizing-mac1.metal-ec2-ami-new-guts-more-glory/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://devdosvid.blog/2021/02/01/customizing-mac1.metal-ec2-ami-new-guts-more-glory/</guid>
      <description>How to build macOS EC2 Instance AMI for CI/CD using Ansible and Packer</description>
      <content:encoded><![CDATA[<p>I guess macOS was designed for a user, not for the ops or engineers, so this is why its customization and usage for CI/CD are not trivial (compared to something Linux-based). A smart guess, huh?</p>
<h1 id="configuration-management">Configuration Management</h1>
<p>Native Apple&rsquo;s Mobile device management (a.k.a MDM) and Jamf is probably the most potent combination for macOS configuration. But as much as it&rsquo;s mighty, it is a cumbersome combination, and Jamf is not free.</p>
<p>Then we have Ansible, Chef, Puppet, SaltStack — they all are good with Linux, but what about macOS?</p>
<p>I tried to search for use cases of mentioned CM tools for macOS. However, I concluded that they wrap the execution of native macOS command-line utilities most of the time.</p>
<p>And if you search for the &lsquo;macos&rsquo; word in Chef Supermarket or Puppet Forge, you won&rsquo;t be impressed by the number of actively maintained packages. Although, here is a motivating article about using Chef <a href="https://pspdfkit.com/blog/2016/chef-on-macos/">automating-macos-provisioning-with-chef</a> if you prefer it. I could not find something similar and fresh for Puppet, so I am sorry, Puppet fans.</p>
<p>That is why I decided to follow the KISS principle and chose Ansible.</p>
<p>It&rsquo;s easy to write and read the configuration, it allows to group tasks and to add execution logic <del>, and it feels more DevOps executing shell commands inside Ansible tasks instead of shell scripts; I know you know that 😂</del></p>
<p>By the way, Ansible Galaxy does not have many management packages for macOS, either. But thankfully, it has the basics:</p>
<ul>
<li><a href="https://docs.ansible.com/ansible/latest/collections/community/general/homebrew_module.html#ansible-collections-community-general-homebrew-module">homebrew</a> with <a href="https://docs.ansible.com/ansible/latest/collections/community/general/homebrew_cask_module.html#ansible-collections-community-general-homebrew-cask-module">homebrew_cask</a> and <a href="https://docs.ansible.com/ansible/latest/collections/community/general/homebrew_tap_module.html#ansible-collections-community-general-homebrew-tap-module">homebrew_tap</a> — to install software</li>
<li><a href="https://docs.ansible.com/ansible/latest/collections/community/general/launchd_module.html#ansible-collections-community-general-launchd-module">launchd</a> — to manage services</li>
<li><a href="https://docs.ansible.com/ansible/latest/collections/community/general/osx_defaults_module.html#ansible-collections-community-general-osx-defaults-module">osx_defaults</a> — to manage some user settings (not all!)</li>
</ul>
<p>I used Ansible to build the macOS AMI for CI/CD, so here are some tips for such a case.</p>
<p><em>Some values are hardcoded intentionally in the code examples for the sake of simplicity and easy reading. You would probably want to parametrize them.</em></p>
<h2 id="xcode-installation-example">Xcode installation example</h2>
<p>The following tasks will help you to automate the basics.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Install Xcode</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">      </span><span style="color:#7ee787">shell</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;xip --expand Xcode.xip&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">      </span><span style="color:#7ee787">args</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">        </span><span style="color:#7ee787">chdir</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">/Applications</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"></span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Accept License Agreement</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">shell</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -license accept&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"></span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Accept License Agreement</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">shell</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -runFirstLaunch&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"></span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Switch into newly installed Xcode context</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">shell</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;xcode-select --switch /Applications/Xcode.app/Contents/Developer&#34;</span><span style="color:#6e7681">
</span></span></span></code></pre></div><h2 id="example-of-software-installation-with-brew">Example of software installation with Brew</h2>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Install common build software</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">community.general.homebrew</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span><span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;{{ item }}&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span><span style="color:#7ee787">state</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">latest</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">loop</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span>- <span style="color:#a5d6ff">swiftlint</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span>- <span style="color:#a5d6ff">swiftformat</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span>- <span style="color:#a5d6ff">wget</span><span style="color:#6e7681">
</span></span></span></code></pre></div><h2 id="screensharing-remote-desktop-configuration-example">ScreenSharing (remote desktop) configuration example</h2>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Turn On Remote Management</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">shell</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;./kickstart -activate -configure -allowAccessFor -specifiedUsers&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">args</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span><span style="color:#7ee787">chdir</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">/System/Library/CoreServices/RemoteManagement/ARDAgent.app/Contents/Resources/</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681"></span>- <span style="color:#7ee787">name</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">Enable Remote Management for CI user</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">shell</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">&#34;./kickstart -configure -users ec2-user -access -on -privs -all&#34;</span><span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">  </span><span style="color:#7ee787">args</span>:<span style="color:#6e7681">
</span></span></span><span style="display:flex;"><span><span style="color:#6e7681">    </span><span style="color:#7ee787">chdir</span>:<span style="color:#6e7681"> </span><span style="color:#a5d6ff">/System/Library/CoreServices/RemoteManagement/ARDAgent.app/Contents/Resources/</span><span style="color:#6e7681">
</span></span></span></code></pre></div><p>Shell rulez, yes.</p>
<h1 id="building-the-ami">Building the AMI</h1>
<video class="animation" autoplay loop muted playsinline>
    <source src="ami-build.webm" type="video/webm">
</video>


<p><a href="https://www.packer.io/docs/builders/amazon/ebs">Packer by HashiCorp</a>, of course.</p>
<p>I would love to compare Packer with EC2 Image Builder, but it <a href="https://docs.aws.amazon.com/imagebuilder/latest/userguide/what-is-image-builder.html#image-builder-os">does not support macOS</a> yet (as of Feb'21).</p>
<p>Packer configuration is straightforward, so I want to highlight only the things specific to the &ldquo;mac1.metal&rdquo; use case.</p>
<h2 id="timeouts">Timeouts</h2>
<p>As I mentioned in the <a href="/2021/01/19/mac1-metal-EC2-Instance-user-experience.html">previous article</a>, the creation and deletion time of the &ldquo;mac1.metal&rdquo; Instance is significantly bigger than Linux. That is why you should raise the polling parameters for the builder.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#a5d6ff">&#34;aws_polling&#34;</span><span style="color:#f85149">:</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#7ee787">&#34;delay_seconds&#34;</span>: <span style="color:#a5d6ff">30</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#7ee787">&#34;max_attempts&#34;</span>: <span style="color:#a5d6ff">60</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And it would be best if you also increased the SSH timeout:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;ssh_timeout&#34;</span><span style="color:#f85149">:</span> <span style="color:#a5d6ff">&#34;1h&#34;</span>
</span></span></code></pre></div><p>Fortunately, Packer&rsquo;s AMI builder does not require an explicit declaration of the Dedicated Host ID. So you can just reference the same subnet where you allocated the Host, assuming you did it with the enabled &ldquo;Auto placement&rdquo; parameter during the host creation.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;tenancy&#34;</span><span style="color:#f85149">:</span> <span style="color:#a5d6ff">&#34;host&#34;</span><span style="color:#f85149">,</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;subnet_id&#34;</span><span style="color:#f85149">:</span> <span style="color:#a5d6ff">&#34;your-subnet-id&#34;</span>
</span></span></code></pre></div><h2 id="provisioning">Provisioning</h2>
<p>Packer has <a href="https://www.packer.io/docs/provisioners/ansible">Ansible Provisioner</a> that I used for the AMI. Its documentation is also very clean and straightforward.</p>
<p>But it is still worth mentioning that if you want to parametrize the Ansible playbook, then the following configuration example will be handy:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;extra_arguments&#34;</span><span style="color:#f85149">:</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;--extra-vars&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;your-variable-foo=your-value-bar]&#34;</span>
</span></span><span style="display:flex;"><span>  ]<span style="color:#f85149">,</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a5d6ff">&#34;ansible_env_vars&#34;</span><span style="color:#f85149">:</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;ANSIBLE_PYTHON_INTERPRETER=auto_legacy_silent&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#34;ANSIBLE_OTHER_ENV_VARIABLE=other_value&#34;</span>
</span></span><span style="display:flex;"><span>  ]
</span></span></code></pre></div><h1 id="configuration-at-launch">Configuration at launch</h1>
<p>If you&rsquo;re familiar with AWS EC2, you probably know what the Instance <code>user data</code> is.</p>
<p>A group of AWS developers made something similar for the macOS: <a href="https://github.com/aws/ec2-macos-init">EC2 macOS Init</a>.</p>
<p>It does not support <code>cloud-init</code> as on Linux-based Instances, but it can run shell scripts, which is quite enough.</p>
<p>EC2 macOS Init utility is a Launch Daemon (macOS terminology) that runs on behalf of the <code>root</code> user at system boot. It executes the commands according to the so-called Priority Groups, or the sequence in other words.</p>
<p>The number of the group corresponds to the execution order. You can put several tasks into a single Priority Group, and the tool will execute them simultaneously.</p>
<p>EC2 macOS Init uses a human-readable configuration file in <code>toml</code> format.</p>
<p>Example:</p>
<pre tabindex="0"><code>[[Module]]
  Name = &#34;Create-some-folder&#34;
  PriorityGroup = 3
  FatalOnError = false 
  RunPerInstance = true 
  [Module.Command]
    Cmd = [&#34;mkdir&#34;, &#34;/Users/ec2-user/my-directory&#34;] 
    RunAsUser = &#34;ec2-user&#34;
    EnvironmentVars = [&#34;MY_VAR_FOO=myValueBar&#34;]
</code></pre><p>I should clarify some things here.</p>
<p>Modules — a set of pre-defined modules for different purposes. It is something similar to the Ansible modules.</p>
<p>You can find the list of available modules here <a href="https://github.com/aws/ec2-macos-init/tree/master/lib/ec2macosinit">ec2-macos-init/lib/ec2macosinit</a></p>
<p>The <code>RunPerInstance</code> directive controls whether a module should run. There are three of such directives, and here is what they mean:</p>
<ul>
<li><code>RunPerBoot</code> — module will run at every system boot</li>
<li><code>RunPerInstance</code> — module will run once for the Instance. Each Instance has a unique ID; the init tool fetches it from the AWS API before the execution and keeps its execution history per Instance ID. When you create a new Instance from the AMI, it will have a unique ID, and the module will run again.</li>
<li><code>RunOnce</code> — module will run only once, despite the instance ID change</li>
</ul>
<p>I mentioned the execution history above. When EC2 macOS Init runs on the Instance first time, it creates a unique directory with the name per Instance ID to store the execution history and user data copy.</p>
<p><code>RunPerInstance</code> and <code>RunOnce</code> directives depend on the execution history, and modules with those directives will run again on the next boot if the previous execution failed. It was not obvious to me why RunOnce keeps repeating itself every boot until I dug into <a href="https://github.com/aws/ec2-macos-init/blob/master/lib/ec2macosinit/module.go#L110">the source code</a>.</p>
<p>Finally, there is a module for user data. It runs at the end by default (priority group #4) and pulls the user data script from AWS API before script execution.</p>
<p>I suggest looking into the default <a href="https://github.com/aws/ec2-macos-init/blob/master/configuration/init.toml">init.toml</a> configuration file to get yourself more familiar with the capabilities of the tool.</p>
<p>The init tool can also clear its history, which is useful for the new AMI creation.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>ec2-macos-init clean -all
</span></span></code></pre></div><p>And you can run the init manually for debugging purposes.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>ec2-macos-init run
</span></span></code></pre></div><p>You can also combine the EC2 macOS Init actions (made by modules) with your script in user data for more accurate nontrivial configurations.</p>
<h1 id="wrapping-up">Wrapping up</h1>
<p>As a whole, building and operating macOS-based AMI does not differ from AMI management for other platforms.</p>
<p>There are the same principle stages: prepare, clear, build, execute deployment script (if necessary). Though, the particular implementation of each step has its nuances and constraints.</p>
<p>So the whole process may look as follows:</p>
<ul>
<li>Provision and configure needed software with Ansible playbook</li>
<li>Clean-up system logs and EC2 macOS Init history (again, with Ansible task)</li>
<li>Create the AMI</li>
<li>Add more customizations at launch with EC2 macOS Init modules and user data (that also executes your Ansible playbook or shell commands)</li>
</ul>
<p>Getting into all this was both fun and interesting. Sometimes painful, though. 😆</p>
<p>I sincerely hope this article was helpful to you. Thank you for reading!</p>
]]></content:encoded>
    </item>
    <item>
      <title>Terraforming mac1.metal at AWS</title>
      <link>https://devdosvid.blog/2021/01/20/terraforming-mac1.metal-at-aws/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://devdosvid.blog/2021/01/20/terraforming-mac1.metal-at-aws/</guid>
      <description>How to manage MacOS EC2 Instances with Terraform</description>
      <content:encoded><![CDATA[<div class="updatenotice">
    Updated on the 23rd of October, 2021: Terraform AWS provider now <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/ec2_host">supports</a> Dedicated Hosts natively
</div>
<p>In November 2021, AWS <a href="https://aws.amazon.com/blogs/aws/new-use-mac-instances-to-build-test-macos-ios-ipados-tvos-and-watchos-apps/">announced</a> the support for Mac mini instances.</p>
<p>I believe this is huge, even despite the number of constraints this solution has. This offering opens the door to seamless macOS CI/CD integration into existing AWS infrastructure.</p>
<p>So here is a quick-start example of creating the dedicated host and the instance altogether using Terraform.</p>
<p>I intentionally used some hardcoded values for the sake of simplicity in the example.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-hcl" data-lang="hcl"><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_ec2_host&#34; &#34;example_host&#34;</span> {
</span></span><span style="display:flex;"><span>  instance_type     <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;mac1.metal&#34;</span>
</span></span><span style="display:flex;"><span>  availability_zone <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;us-east-1a&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">resource</span> <span style="color:#a5d6ff">&#34;aws_instance&#34; &#34;example_instance&#34;</span> {
</span></span><span style="display:flex;"><span>  ami           <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">data</span>.<span style="color:#ff7b72">aws_ami</span>.<span style="color:#ff7b72">mac1metal</span>.<span style="color:#ff7b72">id</span>
</span></span><span style="display:flex;"><span>  host_id       <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">aws_ec2_host</span>.<span style="color:#ff7b72">example_host</span>.<span style="color:#ff7b72">id</span>
</span></span><span style="display:flex;"><span>  instance_type <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;mac1.metal&#34;</span>
</span></span><span style="display:flex;"><span>  subnet_id     <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">data</span>.<span style="color:#ff7b72">aws_subnet</span>.<span style="color:#ff7b72">example_subnet</span>.<span style="color:#ff7b72">id</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">data</span> <span style="color:#a5d6ff">&#34;aws_subnet&#34; &#34;example_subnet&#34;</span> {
</span></span><span style="display:flex;"><span>  availability_zone <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;us-east-1a&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ff7b72">filter</span> {
</span></span><span style="display:flex;"><span>    name   <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;tag:Tier&#34;</span><span style="color:#8b949e;font-style:italic"> # you should omit this filter if you don&#39;t distinguish your subnets on private and public 
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"></span>    values <span style="color:#ff7b72;font-weight:bold">=</span> [<span style="color:#a5d6ff">&#34;private&#34;</span>]
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff7b72">data</span> <span style="color:#a5d6ff">&#34;aws_ami&#34; &#34;mac1metal&#34;</span> {
</span></span><span style="display:flex;"><span>  owners      <span style="color:#ff7b72;font-weight:bold">=</span> [<span style="color:#a5d6ff">&#34;amazon&#34;</span>]
</span></span><span style="display:flex;"><span>  most_recent <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#ff7b72">true</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ff7b72">filter</span> {
</span></span><span style="display:flex;"><span>    name   <span style="color:#ff7b72;font-weight:bold">=</span> <span style="color:#a5d6ff">&#34;name&#34;</span>
</span></span><span style="display:flex;"><span>    values <span style="color:#ff7b72;font-weight:bold">=</span> [<span style="color:#a5d6ff">&#34;amzn-ec2-macos-11*&#34;</span>]<span style="color:#8b949e;font-style:italic"> # get latest BigSur AMI
</span></span></span><span style="display:flex;"><span><span style="color:#8b949e;font-style:italic"></span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Simple as that, yes. Now, you can integrate it into your CI system and have the Mac instance with the underlying host in a bundle.
<div class="attention">
    Pro tip: you can leverage the <code>aws_ec2_instance_type_offerings</code> <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ec2_instance_type_offerings">Data Source</a> and use its output with <code>aws_subnet</code> source to avoid availability zone hardcoding.
</div></p>
<p>To make the code more uniform and reusable, you can wrap it into a <a href="/2020/09/09/terraform-modules-explained.html">Terraform module</a> that accepts specific parameters (such as <code>instance_type</code> or <code>availability_zone</code>) as input variables.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
